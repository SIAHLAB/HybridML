{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1_WR6RvQpSeBw3JIE78DwJEbtzAFq0lte","timestamp":1682539662359},{"file_id":"1UeAwX0jGFbCRbfDoeN3AyQKP8LIaO0sa","timestamp":1682372831051}],"gpuType":"T4","mount_file_id":"1_WR6RvQpSeBw3JIE78DwJEbtzAFq0lte","authorship_tag":"ABX9TyMyXYm9qfzGJD19HP/j0fqB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import math\n","\n","##LSTM\n","import pandas as pd\n","import numpy as np\n","import math\n","\n","import sklearn\n","import keras\n","import keras.backend as K\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import LSTM, CuDNNLSTM, MaxPooling1D, Conv1D, Flatten, BatchNormalization, Dropout, Input\n","from keras.models import Model\n","from keras.layers import RepeatVector\n","from keras.layers import TimeDistributed\n","from keras.layers.convolutional import Conv1D, MaxPooling1D\n","from keras.optimizers import SGD\n","from keras.callbacks import EarlyStopping\n","\n","\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from math import sqrt\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from sklearn.preprocessing import MinMaxScaler\n","from multiprocessing import cpu_count \n","from joblib import Parallel \n","from joblib import delayed \n","from datetime import datetime\n","\n","#import optuna \n","\n","from sklearn.preprocessing import StandardScaler\n","\n","from keras.utils import custom_object_scope\n","from keras.utils import get_custom_objects\n","from keras.models import load_model\n","\n","from keras.layers import LSTM, RepeatVector, TimeDistributed, BatchNormalization, Dropout\n","from keras.initializers import GlorotUniform\n","from keras.activations import relu\n","from joblib import Parallel, delayed\n","\n","import cProfile"],"metadata":{"id":"N13XmUTvQYOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_vwc = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_vwc_.npy', allow_pickle=True)\n","df_stemp = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_stemp_.npy', allow_pickle=True)\n","\n","df_vwc7 = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd7_vwc.npy', allow_pickle=True)\n","df_stemp7 = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd7_stemp.npy', allow_pickle=True)\n","\n","df_vwc11 = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd11_vwc.npy', allow_pickle=True)\n","df_stemp11 = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd11_stemp.npy', allow_pickle=True)\n","\n","df_T = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_T.npy', allow_pickle=True)\n","df_RH = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_RH.npy', allow_pickle=True)\n","#df_DP = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_DP.npy', allow_pickle=True)\n","df_Rain = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_Rain.npy', allow_pickle=True)\n","df_WS = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_WS.npy', allow_pickle=True)\n","#df_WD = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_WD.npy', allow_pickle=True)\n","df_S = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_S.npy', allow_pickle=True)\n","\n","#Scores_IMF = []\n","dataset = pd.read_csv('/content/drive/Shareddrives/1st Paper/2nd.csv', header = 0, infer_datetime_format=True, index_col=['Date Time'])\n","df = dataset[[\n","       'S2_Top_Temp_Avg', 'S2_Top_VWC_Avg'\n","       \n","       ]]\n","#'Temp', 'Relative Humidity', 'Dew Point', 'Rain', 'Wind Speed', 'Wind Direction', 'Solar Radiation',\n"],"metadata":{"id":"ENZTqB7pQcWd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the training data\n","train_data = np.array(df.head(100))\n","\n","\n","# Split the training data into input and output sequences\n","train_input = train_data[:, :]\n","print('train_input shape', train_input.shape)\n","train_output = train_data[:, -1:]\n","print('train_output shape', train_output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BYm1803qe6GU","executionInfo":{"status":"ok","timestamp":1682460909395,"user_tz":240,"elapsed":8,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"6f840146-1415-4439-fa33-003e3a9e2609"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_input shape (100, 2)\n","train_output shape (100, 1)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout\n","from keras.optimizers import Adam\n","import tensorflow_probability as tfp\n","\n","\n","# Define the input and output dimensions\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 3\n","\n","# Define the sizes of the hidden layers for each expert\n","expert_hidden_sizes = [16, 32, 64]\n","\n","# Define the sizes of the output layers for each expert\n","expert_output_sizes = [144,144,144]\n","\n","# Define the sizes of the gating network hidden layers\n","gating_hidden_sizes = [16, 8]\n","\n","# Define the size of the output layer of the gating network\n","gating_output_size = num_experts\n","\n","# Define the number of training iterations for the EM algorithm\n","num_iterations = 100\n","\n","# Define the learning rate for the optimization algorithm\n","learning_rate = 0.00009\n","\n","# Load the training data\n","train_data = np.array(df.head(100))\n","\n","\n","# Split the training data into input and output sequences\n","train_input = train_data[:, :]\n","print('train_input shape', train_input.shape)\n","train_output = train_data[:, -1:]\n","print('train_output shape', train_output.shape)\n","\n","# Define the experts\n","experts = []\n","for i in range(num_experts):\n","    expert_input = Input(shape=(input_dim,))\n","    expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","    expert_hidden = Dropout(0.2)(expert_hidden)\n","    expert_output = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","    expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_output)  # Add this line\n","    experts.append(Model(inputs=expert_input, outputs=expert_output))\n","\n","# Define the gating network\n","gating_input = Input(shape=(input_dim,))\n","gating_hidden = gating_input\n","for i in range(len(gating_hidden_sizes)):\n","    gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","gating_output = Dense(num_experts + num_experts * 2, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","logits = gating_output[:, :num_experts]\n","params = gating_output[:, num_experts:]\n","params = tf.reshape(params, [-1, num_experts, 2])\n","\n","gating_distribution = tfp.distributions.MixtureSameFamily(\n","    mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","    components_distribution=tfp.distributions.Normal(\n","        loc=params[..., 0],\n","        scale=tf.math.softplus(params[..., 1])\n","    )\n",")\n","\n","gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","# Define the MoE model\n","inputs = Input(shape=(input_dim,))\n","outputs = []\n","for i in range(num_experts):\n","    expert_output = experts[i](inputs)\n","    outputs.append(expert_output)\n","\n","gating_output = gating_model(inputs)\n","weighted_outputs = [tf.expand_dims(gating_output[:, i], axis=-1) * expert_output for i, expert_output in enumerate(outputs)]\n","\n","outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","# Define the loss function\n","def moe_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","    expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","    \n","    # Apply softmax to the logits to get probabilities\n","    gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","    \n","    # Multiply expert_losses with the gating probabilities instead of logits\n","    gating_losses = tf.reduce_sum(tf.multiply(expert_losses, gating_probabilities), axis=-1)\n","    return tf.reduce_mean(gating_losses)\n","\n","# Define the optimization algorithm\n","optimizer = Adam(lr=learning_rate)\n","\n","# Train the MoE model with the EM algorithm\n","for iteration in range(num_iterations):\n","\n","    # E step: Compute the responsibilities of each expert for each data point\n","    gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","    gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","\n","    # M step: Update the parameters of each expert and the gating network\n","    for i in range(num_experts):\n","        expert_input = train_input\n","        expert_output = experts[i](expert_input)\n","        expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","        \n","        with tf.GradientTape() as tape:\n","            # Watch the trainable variables of the expert model\n","            tape.watch(experts[i].trainable_variables)\n","\n","            # Define the expert model and calculate the expert_loss\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        # Compute the gradients\n","        expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","        # Clip gradients for expert models\n","        expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","        # Update the variables\n","        optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","\n","\n","    gating_input = train_input\n","    \n","    with tf.GradientTape() as tape:\n","      # Watch the trainable variables of the gating model\n","      tape.watch(gating_model.trainable_variables)\n","\n","      # Define the gating model and calculate the gating_loss\n","      gating_output = gating_model(gating_input)\n","      gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(gating_input))\n","\n","    # Compute the gradients\n","    gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","    # Clip gradients for the gating model\n","    gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","    \n","    # Update the variables\n","    optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","\n","    # Evaluate the performance of the MoE model on the training set\n","    train_loss = moe_loss(train_output, moe_model.predict(train_input))\n","    print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","\n","# Make predictions on the test set using the MoE model\n","test_data = np.array(df[-100:])\n","test_input = test_data[:, :]\n","test_output = test_data[:, -1:]\n","test_predictions = moe_model.predict(test_input)\n","\n","test_loss = moe_loss(test_output, test_predictions)\n","print('Test loss = %.6f' % test_loss)\n"],"metadata":{"id":"5D37prgPMv4c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout\n","from keras.optimizers import Adam\n","import tensorflow_probability as tfp\n","from keras.callbacks import EarlyStopping\n","\n","\n","# Define the input and output dimensions\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 3\n","\n","# Define the sizes of the hidden layers for each expert\n","expert_hidden_sizes = [16, 32, 64]\n","\n","# Define the sizes of the output layers for each expert\n","expert_output_sizes = [144,144,144]\n","\n","# Define the sizes of the gating network hidden layers\n","gating_hidden_sizes = [16, 8]\n","\n","# Define the size of the output layer of the gating network\n","gating_output_size = num_experts\n","\n","# Define the number of training iterations for the EM algorithm\n","num_iterations = 100\n","\n","# Define the learning rate for the optimization algorithm\n","learning_rate = 0.0001\n","\n","# Load the training data\n","train_data = np.array(df.head(144))\n","\n","\n","# Split the training data into input and output sequences\n","train_input = train_data[:, :]\n","print('train_input shape', train_input.shape)\n","train_output = train_data[:, -1:]\n","print('train_output shape', train_output.shape)\n","\n","# Define the experts\n","experts = []\n","for i in range(num_experts):\n","    expert_input = Input(shape=(input_dim,))\n","    expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","    expert_hidden = Dropout(0.2)(expert_hidden)\n","    expert_output = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","    expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_output)  # Add this line\n","    experts.append(Model(inputs=expert_input, outputs=expert_output))\n","\n","# Define the gating network\n","gating_input = Input(shape=(input_dim,))\n","gating_hidden = gating_input\n","for i in range(len(gating_hidden_sizes)):\n","    gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","gating_output = Dense(num_experts + num_experts * 2, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","logits = gating_output[:, :num_experts]\n","params = gating_output[:, num_experts:]\n","params = tf.reshape(params, [-1, num_experts, 2])\n","\n","gating_distribution = tfp.distributions.MixtureSameFamily(\n","    mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","    components_distribution=tfp.distributions.Normal(\n","        loc=params[..., 0],\n","        scale=tf.math.softplus(params[..., 1])\n","    )\n",")\n","\n","gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","# Define the MoE model\n","inputs = Input(shape=(input_dim,))\n","outputs = []\n","for i in range(num_experts):\n","    expert_output = experts[i](inputs)\n","    outputs.append(expert_output)\n","\n","gating_output = gating_model(inputs)\n","weighted_outputs = [tf.expand_dims(gating_output[:, i], axis=-1) * expert_output for i, expert_output in enumerate(outputs)]\n","\n","outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","# Define the loss function\n","def moe_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","    expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","    \n","    # Apply softmax to the logits to get probabilities\n","    gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","    \n","    # Multiply expert_losses with the gating probabilities instead of logits\n","    gating_losses = tf.reduce_sum(tf.multiply(expert_losses, gating_probabilities), axis=-1)\n","    return tf.reduce_mean(gating_losses)\n","\n","# Define the optimization algorithm\n","optimizer = Adam(lr=learning_rate)\n","\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, min_delta=0, baseline=None)\n","early_stopping.set_model(moe_model)  # Add this line\n","early_stopping.best = float('inf')  # Add this line\n","\n","# Train the MoE model with the EM algorithm\n","iteration = 0\n","while iteration < num_iterations:\n","\n","    # E step: Compute the responsibilities of each expert for each data point\n","    gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","    gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","\n","    # M step: Update the parameters of each expert and the gating network\n","    for i in range(num_experts):\n","        expert_input = train_input\n","        expert_output = experts[i](expert_input)\n","        expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","        \n","        with tf.GradientTape() as tape:\n","            # Watch the trainable variables of the expert model\n","            tape.watch(experts[i].trainable_variables)\n","\n","            # Define the expert model and calculate the expert_loss\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        # Compute the gradients\n","        expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","        # Clip gradients for expert models\n","        expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","        # Update the variables\n","        optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","\n","    gating_input = train_input\n","    \n","    with tf.GradientTape() as tape:\n","      # Watch the trainable variables of the gating model\n","      tape.watch(gating_model.trainable_variables)\n","\n","      # Define the gating model and calculate the gating_loss\n","      gating_output = gating_model(gating_input)\n","      gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(gating_input))\n","\n","    # Compute the gradients\n","    gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","    # Clip gradients for the gating model\n","    gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","    \n","    # Update the variables\n","    optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","\n","    # Evaluate the performance of the MoE model on the training set\n","    train_loss = moe_loss(train_output, moe_model.predict(train_input))\n","    print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","    early_stopping.on_epoch_end(iteration, logs={'val_loss': train_loss})\n","\n","\n","    if early_stopping.stopped_epoch > 0:\n","      print('Early stopping triggered after iteration %d' % early_stopping.stopped_epoch)\n","      break\n","    \n","    iteration += 1\n","\n","\n","# Make predictions on the test set using the MoE model\n","test_data = np.array(df[-144:])\n","test_input = test_data[:, :]\n","test_output = test_data[:, -1:]\n","test_predictions = moe_model.predict(test_input)\n","\n","test_loss = moe_loss(test_output, test_predictions)\n","print('Test loss = %.6f' % test_loss)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oh2AmkzsvnJO","executionInfo":{"status":"ok","timestamp":1682281600484,"user_tz":240,"elapsed":36441,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"cc527344-094c-46dd-fb1f-71832313f7dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_input shape (144, 2)\n","train_output shape (144, 1)\n","5/5 [==============================] - 0s 5ms/step\n","5/5 [==============================] - 0s 5ms/step\n","Iteration 1: Training loss = 9622792.000000\n","5/5 [==============================] - 0s 6ms/step\n","5/5 [==============================] - 0s 4ms/step\n","Iteration 2: Training loss = 9477563.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 3: Training loss = 9321474.000000\n","5/5 [==============================] - 0s 4ms/step\n","5/5 [==============================] - 0s 5ms/step\n","Iteration 4: Training loss = 9151894.000000\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 4ms/step\n","Iteration 5: Training loss = 8968573.000000\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 6: Training loss = 8772125.000000\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 2ms/step\n","Iteration 7: Training loss = 8563696.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 8: Training loss = 8344747.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 9: Training loss = 8116824.000000\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 10: Training loss = 7881578.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 11: Training loss = 7640504.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 2ms/step\n","Iteration 12: Training loss = 7395212.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 13: Training loss = 7147013.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 14: Training loss = 6897170.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 15: Training loss = 6646945.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 2ms/step\n","Iteration 16: Training loss = 6397350.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 17: Training loss = 6149163.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 18: Training loss = 5903274.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 19: Training loss = 5660381.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 20: Training loss = 5421078.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 21: Training loss = 5185888.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 22: Training loss = 4955285.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 23: Training loss = 4729669.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 24: Training loss = 4509344.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 25: Training loss = 4294452.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 26: Training loss = 4085200.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 27: Training loss = 3881824.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 28: Training loss = 3684529.500000\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 29: Training loss = 3493410.250000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 30: Training loss = 3308537.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 31: Training loss = 3129869.750000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 32: Training loss = 2957352.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 33: Training loss = 2791005.750000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 34: Training loss = 2630798.750000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 35: Training loss = 2476635.750000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 36: Training loss = 2328381.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 37: Training loss = 2186079.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 38: Training loss = 2049672.625000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 2ms/step\n","Iteration 39: Training loss = 1919094.625000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 40: Training loss = 1799226.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 41: Training loss = 1690367.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 42: Training loss = 1591073.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 43: Training loss = 1500076.375000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 44: Training loss = 1416416.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 45: Training loss = 1343859.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 4ms/step\n","Iteration 46: Training loss = 1280898.250000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 47: Training loss = 1226118.875000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 48: Training loss = 1178316.375000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 4ms/step\n","Iteration 49: Training loss = 1136473.000000\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 50: Training loss = 1099725.750000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 4ms/step\n","Iteration 51: Training loss = 1067342.500000\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 52: Training loss = 1038669.125000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 53: Training loss = 1013156.000000\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 4ms/step\n","Iteration 54: Training loss = 989966.875000\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 4ms/step\n","Iteration 55: Training loss = 965330.000000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 56: Training loss = 939527.125000\n","5/5 [==============================] - 0s 4ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 57: Training loss = 912843.812500\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 58: Training loss = 885573.875000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 4ms/step\n","Iteration 59: Training loss = 857632.125000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 60: Training loss = 826107.812500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 61: Training loss = 791516.312500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 62: Training loss = 754541.250000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 63: Training loss = 715877.750000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 64: Training loss = 676521.937500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 65: Training loss = 638910.687500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 66: Training loss = 603015.687500\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 67: Training loss = 568686.937500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 68: Training loss = 535841.312500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 4ms/step\n","Iteration 69: Training loss = 504744.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 70: Training loss = 477294.562500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 71: Training loss = 453029.343750\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 72: Training loss = 430823.500000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 73: Training loss = 409397.812500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 74: Training loss = 388763.312500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 75: Training loss = 368900.625000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 76: Training loss = 349676.937500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 77: Training loss = 329562.625000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 78: Training loss = 308635.125000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 79: Training loss = 288221.625000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 80: Training loss = 268402.062500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 81: Training loss = 249256.890625\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 82: Training loss = 230851.875000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 83: Training loss = 214291.140625\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 84: Training loss = 199407.437500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 85: Training loss = 185390.093750\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 86: Training loss = 172145.312500\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 87: Training loss = 159513.156250\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 88: Training loss = 146486.984375\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 89: Training loss = 133324.531250\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 90: Training loss = 120700.406250\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 91: Training loss = 108690.015625\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 92: Training loss = 98008.750000\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 93: Training loss = 88626.218750\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 94: Training loss = 80290.781250\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 95: Training loss = 72442.617188\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 96: Training loss = 64449.402344\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 97: Training loss = 56469.265625\n","5/5 [==============================] - 0s 3ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 98: Training loss = 48693.269531\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 99: Training loss = 41903.410156\n","5/5 [==============================] - 0s 2ms/step\n","5/5 [==============================] - 0s 3ms/step\n","Iteration 100: Training loss = 36102.890625\n","5/5 [==============================] - 0s 6ms/step\n","Test loss = 6050.879883\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, TimeDistributed\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow_probability as tfp\n","\n","def split_dataset(data):\n","  # split into standard weeks\n","  train, test = data[0:-6047], data[-6048:]\n","  #train, test = data[:-5817], data[-5817:-57]\n","  # restructure into windows of weekly data\n","  train = np.array(np.split(train, len(train)/144))\n","  test = np.array(np.split( test , len(test )/144))\n","  return train, test\n","\n","def to_supervised(train, n_input):\n","    # Flatten data\n","    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n","    X, y = list(), list()\n","    in_start = 0\n","    # Step over the entire history one time step at a time\n","    for _ in range(len(data)):\n","        # Define the end of the input sequence\n","        in_end = in_start + n_input\n","        out_end = in_end + 1\n","        # Ensure we have enough data for this instance\n","        if out_end < len(data):\n","            X.append(data[in_start:in_end, :])\n","            y.append(data[in_end, 0])  # Modify this line to only include the first future time step\n","        # Move along one time step\n","        in_start += 1\n","    return np.array(X), np.array(y)\n","\n","\n","def build_moe_model(input_dim, output_dim, expert_hidden_sizes, expert_output_sizes,\n","                    gating_hidden_sizes, num_experts=3, learning_rate=0.0001,\n","                    num_iterations=100):\n","\n","    # Define the experts\n","    experts = []\n","    for i in range(num_experts):\n","        expert_input = Input(shape=(input_dim,))\n","        expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal', input_shape=(input_dim,))(expert_input)\n","        expert_hidden = Dropout(0.2)(expert_hidden)\n","        expert_output = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","        expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_output)\n","        experts.append(Model(inputs=expert_input, outputs=expert_output))\n","\n","\n","    # Define the gating network\n","    gating_input = Input(shape=(input_dim,))\n","    gating_hidden = gating_input\n","    for i in range(len(gating_hidden_sizes)):\n","        gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","    gating_output = Dense(num_experts + num_experts * 2, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","    logits = gating_output[:, :num_experts]\n","    params = gating_output[:, num_experts:]\n","    params = tf.reshape(params, [-1, num_experts, 2])\n","\n","    gating_distribution = tfp.distributions.MixtureSameFamily(\n","        mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","        components_distribution=tfp.distributions.Normal(\n","            loc=params[..., 0],\n","            scale=tf.math.softplus(params[..., 1])\n","        )\n","    )\n","\n","    gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","    # Define the MoE model\n","    inputs = Input(shape=(input_dim,))\n","    outputs = []\n","    for i in range(num_experts):\n","        expert_output = experts[i](inputs)\n","        outputs.append(expert_output)\n","\n","    gating_output = gating_model(inputs)\n","    weighted_outputs = [tf.expand_dims(gating_output[:, i], axis=-1) * expert_output for i, expert_output in enumerate(outputs)]\n","\n","    outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","    moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","    return moe_model, experts, gating_model\n","\n","\n","# Define the loss function\n","def moe_loss(y_true, y_pred, gating_output):\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","    expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","    \n","    # Apply softmax to the logits to get probabilities\n","    gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","    \n","    # Multiply expert_losses with the gating probabilities instead of logits\n","    gating_losses = tf.reduce_sum(tf.multiply(expert_losses, gating_probabilities), axis=-1)\n","    return tf.reduce_mean(gating_losses)\n","\n","def scheduler(epoch, lr):\n","    if epoch < 10:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","\n","\n","train, test = split_dataset(df.values)\n","\n","\n","# Define the input and output dimensions\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 3\n","\n","# Define the sizes of the hidden layers for each expert\n","expert_hidden_sizes = [16, 32, 64]\n","\n","# Define the sizes of the output layers for each expert\n","expert_output_sizes = [144,144,144]\n","\n","# Define the sizes of the gating network hidden layers\n","gating_hidden_sizes = [16, 8]\n","\n","# Define the size of the output layer of the gating network\n","gating_output_size = num_experts\n","\n","# Define the number of training iterations for the EM algorithm\n","num_iterations = 100\n","\n","# Define the learning rate for the optimization algorithm\n","learning_rate = 0.0001\n","\n","#Train test split\n","train, test = split_dataset(df.values)\n","\n","# Input output\n","out, _ = to_supervised(train, 144)\n","\n","# Load the training data\n","#train_data = np.array(df.head(17199))\n","\n","# Reshape train_data so that the last column represents the output sequence\n","train_input = train.reshape(train.shape[0]*train.shape[1], train.shape[2])[:-145,:]\n","train_output = out[:,:,1]\n","\n","\n","# Normalize input data\n","train_input = (train_input - np.mean(train_input, axis=0)) / np.std(train_input, axis=0)\n","\n","\n","moe_model, experts, gating_model = build_moe_model(input_dim, output_dim, expert_hidden_sizes,\n","                                                   expert_output_sizes, gating_hidden_sizes)\n","\n","# Define the optimization algorithm\n","optimizer = Adam(learning_rate=learning_rate)\n","\n","# Learning rate scheduler\n","lr_scheduler = LearningRateScheduler(scheduler)\n","\n","# Train the MoE model with the EM algorithm\n","# Train the MoE model with the EM algorithm\n","iteration = 0\n","while iteration < num_iterations:\n","\n","    # E step: Compute the responsibilities of each expert for each data point\n","    gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","    gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","    # M step: Update the parameters of each expert and the gating network\n","    for i in range(num_experts):\n","        expert_input = train_input\n","        expert_output = experts[i](expert_input)\n","        expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        with tf.GradientTape() as tape:\n","            # Watch the trainable variables of the expert model\n","            tape.watch(experts[i].trainable_variables)\n","\n","            # Define the expert model and calculate the expert_loss\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        # Compute the gradients\n","        expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","        # Clip gradients for expert models\n","        expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","        # Update the variables\n","        optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","    \n","    current_learning_rate = scheduler(iteration, optimizer.learning_rate.numpy())\n","    optimizer.learning_rate.assign(current_learning_rate)\n","\n","    gating_input = train_input\n","\n","    with tf.GradientTape() as tape:\n","        # Watch the trainable variables of the gating model\n","        tape.watch(gating_model.trainable_variables)\n","\n","        # Define the gating model and calculate the gating_loss\n","        gating_output = gating_model(gating_input)\n","        gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(train_input), gating_output)\n","\n","\n","\n","\n","\n","    # Compute the gradients\n","    gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","    # Clip gradients for the gating model\n","    gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","\n","    # Update the variables\n","    optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","    # Evaluate the performance of the MoE model on the training set\n","    train_loss = moe_loss(train_output, moe_model.predict(train_input), gating_model.predict(train_input))\n","\n","\n","    print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","\n","    # Stop training if the learning rate becomes too small\n","    if current_learning_rate < 1e-6:\n","        print('Learning rate dropped below 1e-6 after iteration %d' % iteration)\n","        break\n","\n","    iteration += 1\n","\n","# Make predictions on the test set using the MoE model\n","\n","# Input output\n","out_test, _ = to_supervised(test, 144)\n","\n","# Load the training data\n","#train_data = np.array(df.head(17199))\n","\n","# Reshape train_data so that the last column represents the output sequence\n","test_input = test.reshape(test.shape[0]*test.shape[1], test.shape[2])[:-145,:]\n","test_output = out_test[:,:,1]\n","\n","# Normalize test input data\n","test_input = (test_input - np.mean(test_input, axis=0)) / np.std(test_input, axis=0)\n","\n","\n","# Make predictions on the test set using the MoE model\n","test_predictions = moe_model.predict(test_input)\n","\n","test_loss = moe_loss(test_output, test_predictions, gating_model.predict(test_input))\n","\n","print('Test loss = %.6f' % test_loss)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDDn0TYM17mG","executionInfo":{"status":"ok","timestamp":1682430206145,"user_tz":240,"elapsed":229600,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"3e84bda1-ed2f-4e5f-a12e-ba9d8c5e7847"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["563/563 [==============================] - 5s 3ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 1: Training loss = 177.191025\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 2: Training loss = 175.817245\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 3: Training loss = 174.281967\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 4: Training loss = 172.588318\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 5: Training loss = 170.742737\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 6: Training loss = 168.755371\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 7: Training loss = 166.635422\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 8: Training loss = 164.398880\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 9: Training loss = 162.063416\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 10: Training loss = 159.645340\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 11: Training loss = 157.203049\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 12: Training loss = 154.944595\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 13: Training loss = 152.864212\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 14: Training loss = 150.954269\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 15: Training loss = 149.205490\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 16: Training loss = 147.607971\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 17: Training loss = 146.151672\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 18: Training loss = 144.826401\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 19: Training loss = 143.625031\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 20: Training loss = 142.532928\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 21: Training loss = 141.539703\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 22: Training loss = 140.639374\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 23: Training loss = 139.823669\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 24: Training loss = 139.085068\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 25: Training loss = 138.416397\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 26: Training loss = 137.811371\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 27: Training loss = 137.263992\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 28: Training loss = 136.768814\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 29: Training loss = 136.321045\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 30: Training loss = 135.916107\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 31: Training loss = 135.549957\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 32: Training loss = 135.218918\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 33: Training loss = 134.919556\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 34: Training loss = 134.648911\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 35: Training loss = 134.404251\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 36: Training loss = 134.183075\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 37: Training loss = 133.983063\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 38: Training loss = 133.802261\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 39: Training loss = 133.638840\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 40: Training loss = 133.491119\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 41: Training loss = 133.357513\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 42: Training loss = 133.236801\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 43: Training loss = 133.127731\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 44: Training loss = 133.029068\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 45: Training loss = 132.939896\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 46: Training loss = 132.859253\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 47: Training loss = 132.786392\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 48: Training loss = 132.720459\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 49: Training loss = 132.660873\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 50: Training loss = 132.607040\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 51: Training loss = 132.558365\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 52: Training loss = 132.514389\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 53: Training loss = 132.474686\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 54: Training loss = 132.438705\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 55: Training loss = 132.406189\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 56: Training loss = 132.376801\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 57: Training loss = 132.350235\n","Learning rate dropped below 1e-6 after iteration 56\n","185/185 [==============================] - 0s 2ms/step\n","185/185 [==============================] - 0s 1ms/step\n","Test loss = 54.582584\n"]}]},{"cell_type":"code","source":["test_predictions_denormalized = test_predictions * np.std(train_output, axis=0) + np.mean(train_output, axis=0)"],"metadata":{"id":"HrvGTzpHbLHV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Create a new figure object with a larger size\n","fig = plt.figure(figsize=(12, 8))\n","\n","# Create your plot within the new figure object\n","plt.plot(test_predictions_denormalized , color = 'red')\n","plt.plot(test_output, color = 'blue')\n","\n","# Display the plot\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"5Trc0qVK8s4R","executionInfo":{"status":"ok","timestamp":1682345658793,"user_tz":240,"elapsed":2463,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"57065ae3-15a9-412c-a35f-1ba8ad6c2c33"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x800 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"_BjWWYixo1-c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, TimeDistributed\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow_probability as tfp\n","\n","def split_dataset(data):\n","  # split into standard weeks\n","  train, test = data[0:-6047], data[-6048:]\n","  #train, test = data[:-5817], data[-5817:-57] 6048\n","  # restructure into windows of weekly data\n","  train = np.array(np.split(train, len(train)/144))\n","  test = np.array(np.split( test , len(test )/144))\n","  return train, test\n","\n","def to_supervised(train, n_input):\n","    # Flatten data\n","    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n","    X, y = list(), list()\n","    in_start = 0\n","    # Step over the entire history one time step at a time\n","    for _ in range(len(data)):\n","        # Define the end of the input sequence\n","        in_end = in_start + n_input\n","        out_end = in_end + 1\n","        # Ensure we have enough data for this instance\n","        if out_end < len(data):\n","            X.append(data[in_start:in_end, :])\n","            y.append(data[in_end, 0])  # Modify this line to only include the first future time step\n","        # Move along one time step\n","        in_start += 1\n","    return np.array(X), np.array(y)\n","\n","\n","def build_moe_model_with_autoencoder(input_dim, output_dim, expert_hidden_sizes, expert_output_sizes,\n","                                     gating_hidden_sizes, num_experts=3, learning_rate=0.0001,\n","                                     num_iterations=100):\n","    \n","    # Define the experts\n","    experts = []\n","    for i in range(num_experts):\n","        if i == 0:  # Replace first expert with an autoencoder\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            encoded = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(encoded)\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=encoded))  # Return encoded representation\n","        else:\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            expert_hidden = Dropout(0.2)(expert_hidden)\n","            expert_output = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_output)\n","            experts.append(Model(inputs=expert_input, outputs=expert_output))\n","\n","    # Define the gating network\n","    gating_input = Input(shape=(input_dim,))\n","    gating_hidden = gating_input\n","    for i in range(len(gating_hidden_sizes)):\n","        gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","    gating_output = Dense(num_experts + num_experts * 2, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","    logits = gating_output[:, :num_experts]\n","    params = gating_output[:, num_experts:]\n","    params = tf.reshape(params, [-1, num_experts, 2])\n","\n","    gating_distribution = tfp.distributions.MixtureSameFamily(\n","        mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","        components_distribution=tfp.distributions.Normal(\n","            loc=params[..., 0],\n","            scale=tf.math.softplus(params[..., 1])\n","        )\n","    )\n","\n","    gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","    # Define the MoE model\n","    inputs = Input(shape=(input_dim,))\n","    outputs = []\n","    for i in range(num_experts):\n","        expert_output = experts[i](inputs)\n","        if i == 0:  # For the autoencoder expert, append encoded representation to outputs list\n","            outputs.append(expert_output)\n","        else:\n","            outputs.append(experts[i](inputs))\n","\n","    gating_output = gating_model(inputs)\n","    weighted_outputs = [tf.expand_dims(gating_output[:, i], axis=-1) * expert_output[:, :1] for i, expert_output in enumerate(outputs)]\n","\n","    outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","    moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","    return moe_model, experts, gating_model\n","\n","# Define the loss function\n","def moe_loss(y_true, y_pred, gating_output):\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","    expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","    \n","    # Apply softmax to the logits to get probabilities\n","    gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","    \n","    # Multiply expert_losses with the gating probabilities instead of logits\n","    gating_losses = tf.reduce_sum(tf.multiply(expert_losses, gating_probabilities), axis=-1)\n","    return tf.reduce_mean(gating_losses)\n","\n","def scheduler(epoch, lr):\n","    if epoch < 10:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","#Data Split\n","train, test = split_dataset(df.values)\n","\n","# Define the input and output dimensions\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 3\n","\n","# Define the sizes of the hidden layers for each expert\n","expert_hidden_sizes = [16, 32, 64]\n","\n","# Define the sizes of the output layers for each expert\n","expert_output_sizes = [144,144,144]\n","\n","# Define the sizes of the gating network hidden layers\n","gating_hidden_sizes = [16, 8]\n","\n","# Define the size of the output layer of the gating network\n","gating_output_size = num_experts\n","\n","# Define the number of training iterations for the EM algorithm\n","num_iterations = 100\n","\n","# Define the learning rate for the optimization algorithm\n","learning_rate = 0.0001\n","\n","#Train test split\n","train, test = split_dataset(df.values)\n","\n","# Input output\n","out, _ = to_supervised(train, 144)\n","\n","# Load the training data\n","#train_data = np.array(df.head(17199))\n","\n","# Reshape train_data so that the last column represents the output sequence\n","train_input = train.reshape(train.shape[0]*train.shape[1], train.shape[2])[:-145,:]\n","train_output = out[:,:,1]\n","\n","# Normalize input data\n","train_input = (train_input - np.mean(train_input, axis=0)) / np.std(train_input, axis=0)\n","\n","\n","#Build model\n","moe_model, experts, gating_model = build_moe_model_with_autoencoder(input_dim, output_dim, expert_hidden_sizes,\n","                                                   expert_output_sizes, gating_hidden_sizes)\n","\n","# Define the optimization algorithm\n","optimizer = Adam(learning_rate=learning_rate)\n","\n","# Learning rate scheduler\n","lr_scheduler = LearningRateScheduler(scheduler)\n","\n","\n","# Train the MoE model with the EM algorithm\n","iteration = 0\n","while iteration < num_iterations:\n","\n","    # E step: Compute the responsibilities of each expert for each data point\n","    gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","    gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","    # M step: Update the parameters of each expert and the gating network\n","    for i in range(num_experts):\n","        expert_input = train_input\n","        expert_output = experts[i](expert_input)\n","        expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        with tf.GradientTape() as tape:\n","            # Watch the trainable variables of the expert model\n","            tape.watch(experts[i].trainable_variables)\n","\n","            # Define the expert model and calculate the expert_loss\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        # Compute the gradients\n","        expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","        # Clip gradients for expert models\n","        expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","        # Update the variables\n","        optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","    \n","    current_learning_rate = scheduler(iteration, optimizer.learning_rate.numpy())\n","    optimizer.learning_rate.assign(current_learning_rate)\n","\n","    gating_input = train_input\n","\n","    with tf.GradientTape() as tape:\n","        # Watch the trainable variables of the gating model\n","        tape.watch(gating_model.trainable_variables)\n","\n","        # Define the gating model and calculate the gating_loss\n","        gating_output = gating_model(gating_input)\n","        gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(train_input), gating_output)\n","\n","    # Compute the gradients\n","    gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","    # Clip gradients for the gating model\n","    gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","\n","    # Update the variables\n","    optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","    # Evaluate the performance of the MoE model on the training set\n","    train_loss = moe_loss(train_output, moe_model.predict(train_input), gating_model.predict(train_input))\n","\n","\n","    print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","\n","    # Stop training if the learning rate becomes too small\n","    if current_learning_rate < 1e-6:\n","        print('Learning rate dropped below 1e-6 after iteration %d' % iteration)\n","        break\n","\n","    iteration += 1\n","\n","# Make predictions on the test set using the MoE model\n","\n","# Input output\n","out_test, _ = to_supervised(test, 144)\n","\n","# Load the training data\n","#train_data = np.array(df.head(17199))\n","\n","# Reshape train_data so that the last column represents the output sequence\n","test_input = test.reshape(test.shape[0]*test.shape[1], test.shape[2])[:-145,:]\n","test_output = out_test[:,:,1]\n","\n","# Normalize test input data\n","test_input = (test_input - np.mean(test_input, axis=0)) / np.std(test_input, axis=0)\n","\n","\n","# Make predictions on the test set using the MoE model\n","test_predictions = moe_model.predict(test_input)\n","\n","test_loss = moe_loss(test_output, test_predictions, gating_model.predict(test_input))\n","\n","print('Test loss = %.6f' % test_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_vpvGConFto","executionInfo":{"status":"ok","timestamp":1682432890035,"user_tz":240,"elapsed":260431,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"6463d0b1-ee64-4d49-da84-2b37fc0789b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 2s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 1: Training loss = 118.955734\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 2: Training loss = 119.635368\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 3: Training loss = 120.383629\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 4: Training loss = 121.215286\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 5: Training loss = 122.136284\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 6: Training loss = 123.149979\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 7: Training loss = 124.255905\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 8: Training loss = 125.452637\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 9: Training loss = 126.737984\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 10: Training loss = 128.103134\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 11: Training loss = 129.573639\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 12: Training loss = 130.977478\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 13: Training loss = 132.310287\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 14: Training loss = 133.567108\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 15: Training loss = 134.746490\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 2s 3ms/step\n","Iteration 16: Training loss = 135.848083\n","563/563 [==============================] - 3s 5ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 17: Training loss = 136.873077\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 3ms/step\n","Iteration 18: Training loss = 137.823273\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 19: Training loss = 138.701401\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 20: Training loss = 139.511063\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 3s 5ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 21: Training loss = 140.256149\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 3ms/step\n","Iteration 22: Training loss = 140.941086\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 23: Training loss = 141.568863\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 24: Training loss = 142.143051\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 25: Training loss = 142.667160\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 26: Training loss = 143.144806\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 27: Training loss = 143.579834\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 28: Training loss = 143.975723\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 29: Training loss = 144.336151\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 30: Training loss = 144.664017\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 31: Training loss = 144.962158\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 32: Training loss = 145.233154\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 33: Training loss = 145.479324\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 34: Training loss = 145.702805\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 35: Training loss = 145.905609\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 36: Training loss = 146.089615\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 37: Training loss = 146.256424\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 38: Training loss = 146.407639\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 39: Training loss = 146.544632\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 40: Training loss = 146.668701\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 41: Training loss = 146.781128\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 42: Training loss = 146.882996\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 43: Training loss = 146.975220\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 44: Training loss = 147.058762\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 45: Training loss = 147.134369\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 46: Training loss = 147.202820\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 47: Training loss = 147.264771\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 48: Training loss = 147.320877\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 49: Training loss = 147.371628\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 50: Training loss = 147.417557\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 51: Training loss = 147.459137\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 52: Training loss = 147.496735\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 53: Training loss = 147.530716\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 54: Training loss = 147.561493\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 55: Training loss = 147.589310\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 56: Training loss = 147.614471\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 57: Training loss = 147.637268\n","Learning rate dropped below 1e-6 after iteration 56\n","185/185 [==============================] - 0s 2ms/step\n","185/185 [==============================] - 0s 1ms/step\n","Test loss = 81.001694\n"]}]},{"cell_type":"code","source":["test_predictions_denormalized = test_predictions * np.std(train_output, axis=0) + np.mean(train_output, axis=0)"],"metadata":{"id":"CNphDN5VolTe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Create a new figure object with a larger size\n","fig = plt.figure(figsize=(12, 8))\n","\n","# Create your plot within the new figure object\n","plt.plot(test_predictions_denormalized , color = 'red')\n","plt.plot(test_output, color = 'blue')\n","\n","# Display the plot\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"9eEW0_-oome7","executionInfo":{"status":"ok","timestamp":1682432894307,"user_tz":240,"elapsed":2693,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"ac8155ce-6707-46cf-9e87-b40ed4f8e772"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x800 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, LSTM, Multiply, Add\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow_probability as tfp\n","\n","def split_dataset(data):\n","  # split into standard weeks\n","  train, test = data[0:-6047], data[-6048:]\n","  #train, test = data[:-5817], data[-5817:-57] 6048\n","  # restructure into windows of weekly data\n","  train = np.array(np.split(train, len(train)/144))\n","  test = np.array(np.split( test , len(test )/144))\n","  return train, test\n","\n","def to_supervised(train, n_input):\n","    # Flatten data\n","    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n","    X, y = list(), list()\n","    in_start = 0\n","    # Step over the entire history one time step at a time\n","    for _ in range(len(data)):\n","        # Define the end of the input sequence\n","        in_end = in_start + n_input\n","        out_end = in_end + 1\n","        # Ensure we have enough data for this instance\n","        if out_end < len(data):\n","            X.append(data[in_start:in_end, :])\n","            y.append(data[in_end, 0])  # Modify this line to only include the first future time step\n","        # Move along one time step\n","        in_start += 1\n","    return np.array(X), np.array(y)\n","\n","def build_moe_model_with_autoencoder_cnn_attention(input_dim, output_dim, expert_hidden_sizes, expert_output_sizes,\n","                                     gating_hidden_sizes, num_experts=3, learning_rate=0.0001,\n","                                     num_iterations=100):\n","    \n","    # Define the experts\n","    experts = []\n","    for i in range(num_experts):\n","        if i == 0:  # Replace first expert with an autoencoder\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            encoded = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(encoded)\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=encoded))  # Return encoded representation\n","        elif i == 1:  # Replace second expert with a CNN expert\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            expert_hidden = Dropout(0.2)(expert_hidden)\n","            expert_hidden = tf.expand_dims(expert_hidden, axis=1)  # Expand dimensions for CNN input\n","            expert_hidden = Conv1D(filters=32, kernel_size=1, activation='relu', kernel_initializer='he_normal')(expert_hidden)  # Change kernel_size to 1\n","            expert_hidden = MaxPooling1D(pool_size=1)(expert_hidden)\n","            expert_hidden = Flatten()(expert_hidden)\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=expert_output))\n","        else:  # Replace third expert with an attention-based model\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            expert_hidden = Dropout(0.2)(expert_hidden)\n","            expert_hidden = tf.expand_dims(expert_hidden, axis=1)  # Expand dimensions for LSTM input\n","            expert_hidden, _, _ = LSTM(expert_hidden_sizes[i], return_state=True, kernel_initializer='he_normal')(expert_hidden)\n","            attention = Dense(expert_hidden_sizes[i], activation='tanh', kernel_initializer='he_normal')(expert_hidden)\n","            attention = Dense(1, activation='softmax', kernel_initializer='he_normal')(attention)\n","            expert_hidden = Multiply()([expert_hidden, attention])\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=expert_output))\n","\n","\n","    # Define the gating network\n","    gating_input = Input(shape=(input_dim,))\n","    gating_hidden = gating_input\n","    for i in range(len(gating_hidden_sizes)):\n","        gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","    gating_output = Dense(num_experts + num_experts * 2, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","    logits = gating_output[:, :num_experts]\n","    params = gating_output[:, num_experts:]\n","    params = tf.reshape(params, [-1, num_experts, 2])\n","\n","    gating_distribution = tfp.distributions.MixtureSameFamily(\n","        mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","        components_distribution=tfp.distributions.Normal(\n","            loc=params[..., 0],\n","            scale=tf.math.softplus(params[..., 1])\n","        )\n","    )\n","\n","    gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","    # Define the MoE model\n","    inputs = Input(shape=(input_dim,))\n","    outputs = []\n","    for i in range(num_experts):\n","        expert_output = experts[i](inputs)\n","        if i == 0:  # For the autoencoder expert, append encoded representation to outputs list\n","            outputs.append(expert_output)\n","        else:\n","            outputs.append(experts[i](inputs))\n","\n","    gating_output = gating_model(inputs)\n","    weighted_outputs = [tf.expand_dims(gating_output[:, i], axis=-1) * expert_output[:, :1] for i, expert_output in enumerate(outputs)]\n","\n","    outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","    moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","    return moe_model, experts, gating_model\n","\n","\n","# Define the loss function\n","def moe_loss(y_true, y_pred, gating_output):\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","    expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","    \n","    # Apply softmax to the logits to get probabilities\n","    gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","    \n","    # Multiply expert_losses with the gating probabilities instead of logits\n","    gating_losses = tf.reduce_sum(tf.multiply(expert_losses, gating_probabilities), axis=-1)\n","    return tf.reduce_mean(gating_losses)\n","\n","def scheduler(epoch, lr):\n","    if epoch < 10:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","train, test = split_dataset(df.values)\n","\n","\n","# Define the input and output dimensions\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 3\n","\n","# Define the sizes of the hidden layers for each expert\n","expert_hidden_sizes = [16, 32, 64]\n","\n","# Define the sizes of the output layers for each expert\n","expert_output_sizes = [144,144,144]\n","\n","# Define the sizes of the gating network hidden layers\n","gating_hidden_sizes = [16, 8]\n","\n","# Define the size of the output layer of the gating network\n","gating_output_size = num_experts\n","\n","# Define the number of training iterations for the EM algorithm\n","num_iterations = 100\n","\n","# Define the learning rate for the optimization algorithm\n","learning_rate = 0.0001\n","\n","#Train test split\n","train, test = split_dataset(df.values)\n","\n","# Input output\n","out, _ = to_supervised(train, 144)\n","\n","# Load the training data\n","#train_data = np.array(df.head(17199))\n","\n","# Reshape train_data so that the last column represents the output sequence\n","train_input = train.reshape(train.shape[0]*train.shape[1], train.shape[2])[:-145,:]\n","train_output = out[:,:,1]\n","\n","# Normalize input data\n","train_input = (train_input - np.mean(train_input, axis=0)) / np.std(train_input, axis=0)\n","\n","#Build model\n","moe_model, experts, gating_model = build_moe_model_with_autoencoder_cnn_attention(input_dim, output_dim, expert_hidden_sizes,\n","                                                   expert_output_sizes, gating_hidden_sizes)\n","\n","# Define the optimization algorithm\n","optimizer = Adam(learning_rate=learning_rate)\n","\n","# Learning rate scheduler\n","lr_scheduler = LearningRateScheduler(scheduler)\n","\n","# Train the MoE model with the EM algorithm\n","# Train the MoE model with the EM algorithm\n","iteration = 0\n","while iteration < num_iterations:\n","\n","    # E step: Compute the responsibilities of each expert for each data point\n","    gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","    gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","    # M step: Update the parameters of each expert and the gating network\n","    for i in range(num_experts):\n","        expert_input = train_input\n","        expert_output = experts[i](expert_input)\n","        expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        with tf.GradientTape() as tape:\n","            # Watch the trainable variables of the expert model\n","            tape.watch(experts[i].trainable_variables)\n","\n","            # Define the expert model and calculate the expert_loss\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        # Compute the gradients\n","        expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","        # Clip gradients for expert models\n","        expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","        # Update the variables\n","        optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","    \n","    current_learning_rate = scheduler(iteration, optimizer.learning_rate.numpy())\n","    optimizer.learning_rate.assign(current_learning_rate)\n","\n","    gating_input = train_input\n","\n","    with tf.GradientTape() as tape:\n","        # Watch the trainable variables of the gating model\n","        tape.watch(gating_model.trainable_variables)\n","\n","        # Define the gating model and calculate the gating_loss\n","        gating_output = gating_model(gating_input)\n","        gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(train_input), gating_output)\n","\n","\n","\n","\n","\n","    # Compute the gradients\n","    gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","    # Clip gradients for the gating model\n","    gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","\n","    # Update the variables\n","    optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","    # Evaluate the performance of the MoE model on the training set\n","    train_loss = moe_loss(train_output, moe_model.predict(train_input), gating_model.predict(train_input))\n","\n","\n","    print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","\n","    # Stop training if the learning rate becomes too small\n","    if current_learning_rate < 1e-6:\n","        print('Learning rate dropped below 1e-6 after iteration %d' % iteration)\n","        break\n","\n","    iteration += 1\n","\n","# Input output\n","out_test, _ = to_supervised(test, 144)\n","\n","\n","# Reshape train_data so that the last column represents the output sequence\n","test_input = test.reshape(test.shape[0]*test.shape[1], test.shape[2])[:-145,:]\n","test_output = out_test[:,:,1]\n","\n","# Normalize test input data\n","test_input = (test_input - np.mean(test_input, axis=0)) / np.std(test_input, axis=0)\n","\n","# Make predictions on the test set using the MoE model\n","test_predictions = moe_model.predict(test_input)\n","\n","test_loss = moe_loss(test_output, test_predictions, gating_model.predict(test_input))\n","\n","print('Test loss = %.6f' % test_loss)\n","test_predictions_denormalized = test_predictions * np.std(train_output, axis=0) + np.mean(train_output, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a76b387-1c59-47d7-96d7-5659a68c1dd8","id":"njqXoSKtqxp4","executionInfo":{"status":"ok","timestamp":1682434066262,"user_tz":240,"elapsed":285275,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 7s 3ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 1: Training loss = 174.313156\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 2: Training loss = 174.512222\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 3: Training loss = 174.717560\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 4: Training loss = 174.938583\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 5: Training loss = 175.178558\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 6: Training loss = 175.438614\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 7: Training loss = 175.718964\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 8: Training loss = 176.019226\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 9: Training loss = 176.338547\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 10: Training loss = 176.675919\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 11: Training loss = 177.067322\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 12: Training loss = 177.437454\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 13: Training loss = 177.785431\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 14: Training loss = 178.111176\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 15: Training loss = 178.414993\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 16: Training loss = 178.697144\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 17: Training loss = 178.958221\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 18: Training loss = 179.199051\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 19: Training loss = 179.420746\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 20: Training loss = 179.624359\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 21: Training loss = 179.811050\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 22: Training loss = 179.981964\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 23: Training loss = 180.138138\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 24: Training loss = 180.280685\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 25: Training loss = 180.410675\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 26: Training loss = 180.529083\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 27: Training loss = 180.636932\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 28: Training loss = 180.735062\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 29: Training loss = 180.824265\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 30: Training loss = 180.905334\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 31: Training loss = 180.978943\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 32: Training loss = 181.045761\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 33: Training loss = 181.106400\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 34: Training loss = 181.161377\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 35: Training loss = 181.211288\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 36: Training loss = 181.256516\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 37: Training loss = 181.297455\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 38: Training loss = 181.334610\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 39: Training loss = 181.368271\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 40: Training loss = 181.398712\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 41: Training loss = 181.426315\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 42: Training loss = 181.451309\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 43: Training loss = 181.473923\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 44: Training loss = 181.494400\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 45: Training loss = 181.512939\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 46: Training loss = 181.529663\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 47: Training loss = 181.544830\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 48: Training loss = 181.558578\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 49: Training loss = 181.570999\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 50: Training loss = 181.582245\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 51: Training loss = 181.592407\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 2s 3ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 52: Training loss = 181.601639\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 53: Training loss = 181.609955\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 54: Training loss = 181.617477\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 55: Training loss = 181.624313\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 56: Training loss = 181.630478\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 57: Training loss = 181.636047\n","Learning rate dropped below 1e-6 after iteration 56\n","185/185 [==============================] - 1s 3ms/step\n","185/185 [==============================] - 0s 2ms/step\n","Test loss = 93.884247\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Create a new figure object with a larger size\n","fig = plt.figure(figsize=(12, 8))\n","\n","# Create your plot within the new figure object\n","plt.plot(test_predictions_denormalized , color = 'red')\n","plt.plot(test_output, color = 'blue')\n","\n","# Display the plot\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"-k9w5byfrMlX","executionInfo":{"status":"ok","timestamp":1682434070011,"user_tz":240,"elapsed":3779,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"1acaca7a-6495-4cad-92b2-85cb5f128102"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x800 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"lericn38pkLc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, LSTM, Multiply, Add\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow_probability as tfp\n","\n","def split_dataset(data):\n","  # split into standard weeks\n","  train, test = data[0:-6047], data[-432:]\n","  #train, test = data[:-5817], data[-5817:-57] 6048\n","  # restructure into windows of weekly data\n","  train = np.array(np.split(train, len(train)/144))\n","  test = np.array(np.split( test , len(test )/144))\n","  return train, test\n","\n","def to_supervised(train, n_input):\n","    # Flatten data\n","    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n","    X, y = list(), list()\n","    in_start = 0\n","    # Step over the entire history one time step at a time\n","    for _ in range(len(data)):\n","        # Define the end of the input sequence\n","        in_end = in_start + n_input\n","        out_end = in_end + 1\n","        # Ensure we have enough data for this instance\n","        if out_end < len(data):\n","            X.append(data[in_start:in_end, :])\n","            y.append(data[in_end, 0])  # Modify this line to only include the first future time step\n","        # Move along one time step\n","        in_start += 1\n","    return np.array(X), np.array(y)\n","\n","def build_moe_model_with_autoencoder(input_dim, output_dim, expert_hidden_sizes, expert_output_sizes,\n","                                     gating_hidden_sizes, num_experts=3, learning_rate=0.0001,\n","                                     num_iterations=100):\n","    \n","    # Define the experts\n","    experts = []\n","    for i in range(num_experts):\n","        if i == 0:  # Replace first expert with an autoencoder\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            encoded = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(encoded)\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=encoded))  # Return encoded representation\n","        elif i == 1:  # Replace second expert with a CNN expert\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            expert_hidden = Dropout(0.2)(expert_hidden)\n","            expert_hidden = tf.expand_dims(expert_hidden, axis=1)  # Expand dimensions for CNN input\n","            expert_hidden = Conv1D(filters=32, kernel_size=1, activation='relu', kernel_initializer='he_normal')(expert_hidden)  # Change kernel_size to 1\n","            expert_hidden = MaxPooling1D(pool_size=1)(expert_hidden)\n","            expert_hidden = Flatten()(expert_hidden)\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=expert_output))\n","        else:  # Replace third expert with an attention-based model\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            expert_hidden = Dropout(0.2)(expert_hidden)\n","            expert_hidden = tf.expand_dims(expert_hidden, axis=1)  # Expand dimensions for LSTM input\n","            expert_hidden, _, _ = LSTM(expert_hidden_sizes[i], return_state=True, kernel_initializer='he_normal')(expert_hidden)\n","            attention = Dense(expert_hidden_sizes[i], activation='tanh', kernel_initializer='he_normal')(expert_hidden)\n","            attention = Dense(1, activation='softmax', kernel_initializer='he_normal')(attention)\n","            expert_hidden = Multiply()([expert_hidden, attention])\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=expert_output))\n","\n","\n","    # Define the gating network\n","    gating_input = Input(shape=(input_dim,))\n","    gating_hidden = gating_input\n","    for i in range(len(gating_hidden_sizes)):\n","        gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","    gating_output = Dense(num_experts + num_experts * 3, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","    logits = gating_output[:, :num_experts]\n","    params = gating_output[:, num_experts:]\n","    params = tf.reshape(params, [-1, num_experts, 3])\n","\n","    gating_distribution = tfp.distributions.MixtureSameFamily(\n","        mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","        components_distribution=tfp.distributions.Normal(\n","            loc=params[..., 0],\n","            scale=tf.math.softplus(params[..., 1])\n","        )\n","    )\n","\n","    gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","    # Define the MoE model\n","    inputs = Input(shape=(input_dim,))\n","    outputs = []\n","    for i in range(num_experts):\n","        expert_output = experts[i](inputs)\n","        if i == 0:  # For the autoencoder expert, append encoded representation to outputs list\n","            outputs.append(expert_output)\n","        else:\n","            outputs.append(experts[i](inputs))\n","\n","    gating_output = gating_model(inputs)\n","    weighted_outputs = [gating_distribution.components_distribution[i].prob(expert_output) * gating_distribution.mixture_distribution.probs_parameter()[..., i, tf.newaxis] * expert_output for i, expert_output in enumerate(outputs)]\n","\n","\n","    outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","    moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","    return moe_model, experts, gating_model\n","\n","# Define the loss function\n","def moe_loss(y_true, y_pred, gating_output):\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","    expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","    \n","    # Apply softmax to the logits to get probabilities\n","    gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","    \n","    # Multiply expert_losses with the gating probabilities instead of logits\n","    gating_losses = tf.reduce_sum(tf.multiply(expert_losses, gating_probabilities), axis=-1)\n","    return tf.reduce_mean(gating_losses)\n","\n","def scheduler(epoch, lr):\n","    if epoch < 10:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","\n","train, test = split_dataset(df.values)\n","\n","\n","# Define the input and output dimensions\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 3\n","\n","# Define the sizes of the hidden layers for each expert\n","expert_hidden_sizes = [16, 32, 64]\n","\n","# Define the sizes of the output layers for each expert\n","expert_output_sizes = [144,144,144]\n","\n","# Define the sizes of the gating network hidden layers\n","gating_hidden_sizes = [16, 8]\n","\n","# Define the size of the output layer of the gating network\n","gating_output_size = num_experts\n","\n","# Define the number of training iterations for the EM algorithm\n","num_iterations = 100\n","\n","# Define the learning rate for the optimization algorithm\n","learning_rate = 0.0001\n","\n","#Train test split\n","train, test = split_dataset(df.values)\n","\n","# Input output\n","out, _ = to_supervised(train, 144)\n","\n","# Reshape train_data so that the last column represents the output sequence\n","train_input = train.reshape(train.shape[0]*train.shape[1], train.shape[2])[:-145,:]\n","train_output = out[:,:,1]\n","\n","\n","\n","# Normalize input data\n","train_input = (train_input - np.mean(train_input, axis=0)) / np.std(train_input, axis=0)\n","\n","#Build model\n","moe_model, experts, gating_model = build_moe_model(input_dim, output_dim, expert_hidden_sizes,\n","                                                   expert_output_sizes, gating_hidden_sizes)\n","\n","# Define the optimization algorithm\n","optimizer = Adam(learning_rate=learning_rate)\n","\n","# Learning rate scheduler\n","lr_scheduler = LearningRateScheduler(scheduler)\n","\n","\n","# Train the MoE model with the EM algorithm\n","iteration = 0\n","while iteration < num_iterations:\n","\n","    # E step: Compute the responsibilities of each expert for each data point\n","    gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","    gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","    # M step: Update the parameters of each expert and the gating network\n","    for i in range(num_experts):\n","        expert_input = train_input\n","        expert_output = experts[i](expert_input)\n","        expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        with tf.GradientTape() as tape:\n","            # Watch the trainable variables of the expert model\n","            tape.watch(experts[i].trainable_variables)\n","\n","            # Define the expert model and calculate the expert_loss\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        # Compute the gradients\n","        expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","        # Clip gradients for expert models\n","        expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","        # Update the variables\n","        optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","    \n","    current_learning_rate = scheduler(iteration, optimizer.learning_rate.numpy())\n","    optimizer.learning_rate.assign(current_learning_rate)\n","\n","    gating_input = train_input\n","\n","    with tf.GradientTape() as tape:\n","        # Watch the trainable variables of the gating model\n","        tape.watch(gating_model.trainable_variables)\n","\n","        # Define the gating model and calculate the gating_loss\n","        gating_output = gating_model(gating_input)\n","        gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(train_input), gating_output)\n","\n","\n","    # Compute the gradients\n","    gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","    # Clip gradients for the gating model\n","    gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","\n","    # Update the variables\n","    optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","    # Evaluate the performance of the MoE model on the training set\n","    train_loss = moe_loss(train_output, moe_model.predict(train_input), gating_model.predict(train_input))\n","\n","\n","    print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","\n","    # Stop training if the learning rate becomes too small\n","    if current_learning_rate < 1e-6:\n","        print('Learning rate dropped below 1e-6 after iteration %d' % iteration)\n","        break\n","\n","    iteration += 1\n","\n","# Make predictions on the test set using the MoE model\n","# Input output\n","out_test, _ = to_supervised(test, 144)\n","\n","\n","# Reshape train_data so that the last column represents the output sequence\n","test_input = test.reshape(test.shape[0]*test.shape[1], test.shape[2])[:-145,:]\n","test_output = out_test[:,:,1]\n","\n","# Normalize test input data\n","test_input = (test_input - np.mean(test_input, axis=0)) / np.std(test_input, axis=0)\n","\n","# Make predictions on the test set using the MoE model\n","test_predictions = moe_model.predict(test_input)\n","\n","test_loss = moe_loss(test_output, test_predictions, gating_model.predict(test_input))\n","\n","print('Test loss = %.6f' % test_loss)\n","test_predictions_denormalized = test_predictions * np.std(train_output, axis=0) + np.mean(train_output, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBr_oP0A82GD","executionInfo":{"status":"ok","timestamp":1682435923977,"user_tz":240,"elapsed":241560,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"535834eb-9c59-4bdb-973a-b8a1a61b3b48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 1: Training loss = 313.652832\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 2: Training loss = 305.381012\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 3: Training loss = 296.560028\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 4: Training loss = 287.114502\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 5: Training loss = 277.090149\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 6: Training loss = 266.586304\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 7: Training loss = 255.715256\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 8: Training loss = 244.612640\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 9: Training loss = 233.419739\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 10: Training loss = 222.282501\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 11: Training loss = 211.413406\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 12: Training loss = 201.823929\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 13: Training loss = 193.406143\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 14: Training loss = 186.048996\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 15: Training loss = 179.637421\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 16: Training loss = 174.064072\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 17: Training loss = 169.228546\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 18: Training loss = 165.039444\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 19: Training loss = 161.428345\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 20: Training loss = 158.306808\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 21: Training loss = 155.603836\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 22: Training loss = 153.262543\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 23: Training loss = 151.232986\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 24: Training loss = 149.472061\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 25: Training loss = 147.942551\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 26: Training loss = 146.612335\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 27: Training loss = 145.453918\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 28: Training loss = 144.444504\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 29: Training loss = 143.563782\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 30: Training loss = 142.793045\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 31: Training loss = 142.117615\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 32: Training loss = 141.524643\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 33: Training loss = 141.003494\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 34: Training loss = 140.546875\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 35: Training loss = 140.144485\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 36: Training loss = 139.789124\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 37: Training loss = 139.474457\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 38: Training loss = 139.195099\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 39: Training loss = 138.946640\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 40: Training loss = 138.727249\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 41: Training loss = 138.532089\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 42: Training loss = 138.358276\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 43: Training loss = 138.203491\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 44: Training loss = 138.065155\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 45: Training loss = 137.942108\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 46: Training loss = 137.832077\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 3ms/step\n","Iteration 47: Training loss = 137.733475\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 48: Training loss = 137.644974\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 49: Training loss = 137.565582\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 50: Training loss = 137.494278\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 51: Training loss = 137.430557\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 52: Training loss = 137.373306\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 53: Training loss = 137.321762\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 54: Training loss = 137.275345\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 55: Training loss = 137.233536\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 56: Training loss = 137.195984\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 57: Training loss = 137.162094\n","Learning rate dropped below 1e-6 after iteration 56\n","9/9 [==============================] - 0s 2ms/step\n","9/9 [==============================] - 0s 2ms/step\n","Test loss = 33.844173\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Create a new figure object with a larger size\n","fig = plt.figure(figsize=(12, 8))\n","\n","# Create your plot within the new figure object\n","plt.plot(test_predictions_denormalized , color = 'red')\n","plt.plot(test_output, color = 'blue')\n","\n","# Display the plot\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"owDS4s9H-f5M","executionInfo":{"status":"ok","timestamp":1682435927619,"user_tz":240,"elapsed":2120,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"63f64540-0269-41ec-b080-8a999dfa1261"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x800 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAA90AAAKTCAYAAAAE62suAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABi40lEQVR4nO3deZwcdZ0//vfkGo4wEwIhCRIOBTlE0EWNEcGDKLDqouCFfAUBcYGAHIKKunj82A3rCSqCByLriiiuiLjCiihBNKAgIIcgYDRgSLhkJgnk/vz+KGd6ZjJH90xXVx/P5+PRj6npo+pd1dVVn1edbSmlFAAAAEDVjSu6AAAAAGhWQjcAAADkROgGAACAnAjdAAAAkBOhGwAAAHIidAMAAEBOhG4AAADIyYSiCxhow4YNsWTJkthiiy2ira2t6HIAAABocimlWL58eWy77bYxblx1903XXehesmRJzJo1q+gyAAAAaDEPP/xwbLfddlXtZ92F7i222CIispHt6OgouBoAAACaXXd3d8yaNas3j1ZT3YXunkPKOzo6hG4AAABqJo9TnF1IDQAAAHIidAMAAEBOhG4AAADIidANAAAAORG6AQAAICdCNwAAAORE6AYAAICcCN0AAACQE6EbAAAAciJ0AwAAQE6EbgAAAMiJ0A0AAAA5EboBAAAgJ0I3AAAA5EToBgAAgJwI3QAAAJAToRsAAAByInQDAABAToRuAAAAyInQDQAAADkRugEAACAnQjcAAADkROgGAACAnAjdAAAAkJMJRRcAAACMoK2t1J1ScXUAFbOnGwAAAHIidAMAAEBOhG4AAADIidANAAAAORG6AQAAICdCNwAAAORE6AYAgHrW93ZhQMMRugEAACAnQjcAAADkROgGAACAnAjdAADQSK64ougKgAoI3QAA0Eje/vaiKwAqIHQDAABAToRuAAAAyInQDQAAADkRugEAoF79+tdFVwCMkdANAAD16pWvLLoCYIyEbgAAAMiJ0A0AAAA5EboBAAAgJ0I3AAAA5EToBgAAgJwI3QAAAJAToRsAAAByInQDAABAToRuAACoR3vtVXQFQBUI3QAAUI/uuqvoCoAqELoBAKDe/exnRVcAjJLQDQAA9e51ryu6AmCUhG4AAADIidANAAAAORG6AQAAICdCNwAAAORE6AYAAICcCN0AAACQE6EbAAAAciJ0AwAAQE6EbgAAAMiJ0A0AAAA5EboBAAAgJ0I3AAAA5EToBgAAgJwI3QAAAJAToRsAAAByInQDAABAToRuAABoNHvtVXQFQJmEbgAAaDR33VV0BUCZhG4AAADIidANAACNYL/9iq4AGAWhGwAAGsG11xZdATAKQjcAADSCzTYrugJgFIRuAAAAyInQDQAAADkRugEAoN6ceWbRFQBVInQDAEC9+exni64AqBKhGwAAAHIidAMAAEBOhG4AAKhnd99ddAXAGAjdAABQz17wgqIrAMZA6AYAAICcVBS6P/GJT0RbW1u/x2677db7+qpVq2LevHmx1VZbxeTJk+Owww6LZcuWVb1oAAAAaAQV7+l+wQteEI8++mjv46abbup97bTTTourr746rrjiiliwYEEsWbIkDj300KoWDAAAAI1iQsUfmDAhZsyYsdHzXV1dcfHFF8dll10Wr33tayMi4pJLLondd989br755nj5y18+9moBAACggVS8p/uBBx6IbbfdNp773OfGEUccEYsXL46IiNtuuy3Wrl0bc+fO7X3vbrvtFttvv30sXLhwyP6tXr06uru7+z0AAACgGVQUumfPnh3f+ta34tprr40LL7wwFi1aFPvtt18sX748li5dGpMmTYopU6b0+8z06dNj6dKlQ/Zz/vz50dnZ2fuYNWvWqEYEAAAA6k1Fh5cffPDBvd177bVXzJ49O3bYYYf4/ve/H5tuuumoCjjrrLPi9NNP7/2/u7tb8AYAAKApjOmWYVOmTInnP//58eCDD8aMGTNizZo18fTTT/d7z7JlywY9B7xHe3t7dHR09HsAAABAMxhT6F6xYkU89NBDMXPmzNhnn31i4sSJcf311/e+fv/998fixYtjzpw5Yy4UAAAAGk1Fh5efccYZ8aY3vSl22GGHWLJkSXz84x+P8ePHx+GHHx6dnZ1x7LHHxumnnx5Tp06Njo6OOPnkk2POnDmuXA4AAEBLqih0P/LII3H44YfHk08+GdOmTYtXvvKVcfPNN8e0adMiIuILX/hCjBs3Lg477LBYvXp1HHjggfGVr3wll8IBAACg3rWllFLRRfTV3d0dnZ2d0dXV5fxuAABaU1tbqbtvc32o54ExyTOHjumcbgAAAGBoQjcAAADkROgGAACAnAjdAAAAkBOhGwAAAHIidAMAAEBOhG4AAADIidANAAAAORG6AQCgEf33fxddAVAGoRsAABrRu99ddAVAGYRuAAAAyInQDQAAADkRugEAoFHcc0/RFQAVEroBAKBR7LFH0RUAFRK6AQAAICdCNwAAAORE6AYAAICcCN0AAACQE6EbAAAAciJ0AwBAPbniiqIrAKpI6AYAgHry9rcXXQFQRUI3AAAA5EToBgAAgJwI3QAAUK9++MOiKwDGSOgGAIB69eY3F10BMEZCNwAA1Ku2tqIroJFdfHE2D73znUVX0tLaUkqp6CL66u7ujs7Ozujq6oqOjo6iywEAgNrqG7QHa6qP9Dr0MK+ULc8cak83AAAA5EToBgAAgJwI3QAAAJAToRsAAAByInQDAABAToRuAAAAyInQDQAAjeqGG4quABiB0A0AAI3qNa8pugJgBEI3AAA0knPPLboCoAJCNwAANJIPfajoCoAKCN0AAACQE6EbAACg2R1wQNEVtCyhGwAAoNn94hdFV9CyhG4AAADIidANAACNrK2t6AqAYQjdAAAAzeZrXyu6Av5B6AYAgEazenXRFVDv/vVfi66AfxC6AQCg0UyaVHQFQJmEbgAAAMiJ0A0AAAA5EboBAAAgJ0I3AAA0uiOOKLoCYAhCNwAANLrLLiu6AmAIQjcAADSie+8d/vVHHqlNHcCwJhRdAAAAMAq77z70a21tpe6U8q8FGJI93QAAAJAToRsAAAByInQDAABAToRuAAAAyInQDQAA9eKhh4quAKgyoRsAAOrFi15UdAVAlQndAABQL1asKLoCoMqEbgAAAMiJ0A0AAPXomGOKrgCoAqEbAADq0de/Xp3+OE8cCiV0AwBAPRpXYVP9xhsHf/7OO8deCzBqQjcAADSDV70q+7vvvsXWAfQjdAMAQDP5zW+KrgDoQ+gGAIBG9cY3Fl0BMAKhGwAAGtVVVxVdAY0kpaIraElCNwAANKpKL7ZGa9tii6IraEl+pQAAAK1g5cqiK2hJQjcAAADkROgGAACAnAjdAAAAkBOhGwAAAHIidAMAQD04+uiiK6BZnHxy0RXQR1tK9XWztu7u7ujs7Iyurq7o6OgouhwAAKiNtrb+/5fbTO/7uZQ27k8l/aI5DDYP9DAvDCrPHGpPNwAA1Jt77im6AqBKhG4AAKg3e+xRdAU0iw9/uOgKWp7QDQAA0Kz+4z+KrqDlCd0AAADNarjzu6kJoRsAAAByInQDAECzW7686AqgZQndAABQtCefzLf/bsXbuE4+OTtEvK0t4qGHiq6GURC6AQCgaFtvXXQF1Ksvf7nUvfPOztFuQEI3AADUk2OPLboC6p3g3VCEbgAAqCff+EbRFQBVJHQDAABAToRuAAAAyMmYQve5554bbW1tceqpp/Y+t2rVqpg3b15stdVWMXny5DjssMNi2bJlY60TAAAYyZ//XHQFwACjDt2/+93v4qtf/Wrstdde/Z4/7bTT4uqrr44rrrgiFixYEEuWLIlDDz10zIUCAAAjeN7ziq4AGGBUoXvFihVxxBFHxNe//vXYcsste5/v6uqKiy++OD7/+c/Ha1/72thnn33ikksuid/85jdx8803V61oAACAlva5zxVdAWUaVeieN29evOENb4i5c+f2e/62226LtWvX9nt+t912i+233z4WLlw4aL9Wr14d3d3d/R4AANAyxnr7p+c/vzp10FjOOKPoCihTxaH78ssvj9///vcxf/78jV5bunRpTJo0KaZMmdLv+enTp8fSpUsH7d/8+fOjs7Oz9zFr1qxKSwIAgNb1xz8O/vzZZ9e2DmBQFYXuhx9+OE455ZT4zne+E5tssklVCjjrrLOiq6ur9/Hwww9Xpb8AANBwVq2q/DPjhmjSf/KTY6uF+vPb3xZdAaNQUei+7bbb4rHHHot/+qd/igkTJsSECRNiwYIF8cUvfjEmTJgQ06dPjzVr1sTTTz/d73PLli2LGTNmDNrP9vb26Ojo6PcAAICW1N5edAXUs5e+tOgKGIUJlbz5gAMOiLvuuqvfc0cffXTstttu8aEPfShmzZoVEydOjOuvvz4OO+ywiIi4//77Y/HixTFnzpzqVQ0AAAANoKLQvcUWW8See+7Z77nNN988ttpqq97njz322Dj99NNj6tSp0dHRESeffHLMmTMnXv7yl1evagAAACr37W9HvPvdRVfRUkZ9n+6hfOELX4g3vvGNcdhhh8X+++8fM2bMiB/+8IfVHgwAAACVOvLIoitoOW0ppVR0EX11d3dHZ2dndHV1Ob8bAIDm1/eWYaNtmg9227GUqtNvijXwOyznOx3uM8N9roXlmUOrvqcbAACAOnLIIUVX0NKEbgAAgGZ25ZVFV9DShG4AAKiF5z8/O8x3sEPBa+HrXy9muBSvqHmOiBC6AQCgNh54oNjhv+99xQ4fWpTQDQBQDyZOLHYvKLX17W8XXQFQI0I3AEA9WLeu6AqopVrdtmnFitoMBxiS0A0AAM1q882LroCxGM0pCfvtV/06GBOhGwCg3vz850VXANSD5z+/8s/cdFP162BMhG4AgHrzutcVXQEAVSJ0AwAANCNHzdQFoRsAAKDePfVU5Z854IDq10HFhG4AgKIdf3zRFQD1bssti66AURK6AQCK9tWvFl0BRZkypegKgJwJ3QAAUJSurqIrAHImdAMAQD0Yze2hgLondAMAQD24776iK6DR/OAHRVdAGYRuAIB65OJqraetregKaDRve9voPmdeqymhGwCgHrm4GpXYdtuiK6DezZ1bdAUtS+gGAIBGt3hx0RVQK1ddNbrPXXdddeugbEI3AAA0uvHj+/+/fHkxdZC/f/mXoiugQkI3AAA0m8mTi64A+AehGwCgSDvtVHQF1MIJJxRdAVAQoRsAoEh/+UvRFVALF11UdAXQnyuY14zQDQBQL7q7i64AaGSCdF0SugEA6sUWWxRdAdAsDj984+c2bKh9HQjdAAB163nPK7oC8rTLLkVXQDO77LKNn7MnvBBCNwBAvfrzn4uugDw9+GDRFQA1IHQDANSTlSuLrgCAKhK6AQDqyWabFV0B0CpmzCi6gpYgdAMAQKt473uLroC8jOZ87WXLql8HGxG6AQCgVVx8cdEVUAsf+tDQr61bV7s6iAihGwCg9traIo45xpWEqa5VqyLe8x7XBSDi3HOHfm38+NrVQUQI3QAAtdUTtC+5pNg6aD7t7dl8NfC6AK94RTH1ABEhdAMA1AeHfJKXm24qugJoaUI3AEA9cMgneXEaAxRK6AYAAGhkNqzUNaEbAKAoTzwRsfXWEV/+ctGVAM3ioouKroABJhRdAABAy9hhh/7/b7VVxOOPF1MLUN8++9nRfe5f/7Wy90+cGLF27eiGRVns6QYAqJXFi4uugHr15z8XXQH15swzazMcF3HMndANAFCEchu67rncGnbaqegKaFT331/5Z555pvp1MCShGwCgCOVerXzy5HzrAOrfu9419Gu77VZ5/zbddPS1UDGhGwAAoJ595ztFV8AYCN0AAPVm772LrgCoZ2efXXQFVEDoBgCoN7ffXnQFVNNHPlJ0BTSbT35y8OddFK0uCd0AALXQ1pbPe6l/8+cXXQGtotxrRVBTQjcAQK1dcEHRFQBQI0I3AECtnXhi0RVQlL//vegKgBoTugEAoFamTCm6AqDGhG4AAKilP/2p6Aqgv69+tegKmprQDQAAtbTLLkVXQDOaNm30nz3++OrVwUaEbgCAvO2zT9EVAM3usccqe//3v59PHWxE6AYAyNvvf190BQD9ve1tRVfQMoRuAIBaWrOm6AoAqCGhGwCgliZOLLoCAGpI6AYAAICcCN0AAACQE6EbAACgkV18cdEVMAyhGwAgT1OnFl0B0OyOOaboChiG0A0AkKe//73oCgAokNANAFBNbW3ZYzAbNtS2FqB5PftsxJZbOrS8AUwougAAgKbRN2xPnBixdu3QrwOMxSabRDz1VPX619YWkVL1+kcve7oBAPKwbl3RFdAo9tij6AqAHAndAABQpHvuqe3wvve92g6P+uWUl5oQugEAoJW8851FV0C9cMpLTQjdAAB5mTSp6AoAKJjQDQCQl4EXUqP1XHTR4M/fe29t69h889oOj/K1tUVMm1Z0FeRI6AYAqIauruFfH8u5kzNnjv6zFOuEEwZ/fvfdsytF1+pq0Y8+WpvhUJmew7ufeKLYOsiV0A0AUA1Tpgz/+ljOnVy6dPSfhYiILbYougJGctttRVdAToRuAIB6NGNG0RVQbd3dRVdAPXvJS0rdu+5aXB1UndANAFCPHn646AqoNnubKdef/lR0BVSR0A0AUG1//vPY+zFhwtj7AUDhhG4AgGrbaaeiKwCaxZIlRVfAGAndAAAA9aqWdy946qnaDauFCN0AAHkby+3CAGplq62KrqApCd0AAGP1ta9t/NzataXusdwuDCBPkyYVXUHTE7oBAMbqX/914+cmTIhIKXsA1KtVq4quoOkJ3QAA1eScSKCROBInd0I3AEA1bbll0RUAUEeEbgAAAMiJ0A0AAAA5EboBAAAgJ0I3AAAA5EToBgAYixe8oOgKAKhjQjcAwFjce2/RFVCv3IoJCKEbAKB6NmwougIA6ozQDQBQLfZsMpSnniq6AqAgQjcAAORtyy2LrgDK89hjRVfQdCoK3RdeeGHstdde0dHRER0dHTFnzpy45pprel9ftWpVzJs3L7baaquYPHlyHHbYYbFs2bKqFw0AAEAOpk8vuoKmU1Ho3m677eLcc8+N2267LW699dZ47WtfG4ccckjcc889ERFx2mmnxdVXXx1XXHFFLFiwIJYsWRKHHnpoLoUDAAA0lR//uJjhbrVVMcNtEW0ppTSWHkydOjU+85nPxFvf+taYNm1aXHbZZfHWt741IiLuu+++2H333WPhwoXx8pe/vKz+dXd3R2dnZ3R1dUVHR8dYSgMAyF/f87jH1qyqbb/JX719f/VWD+VdB6JW31WLzx955tBRn9O9fv36uPzyy2PlypUxZ86cuO2222Lt2rUxd+7c3vfstttusf3228fChQuH7M/q1auju7u73wMAAACaQcWh+6677orJkydHe3t7HH/88XHllVfGHnvsEUuXLo1JkybFlClT+r1/+vTpsXTp0iH7N3/+/Ojs7Ox9zJo1q+KRAAAAaCinnjrye558MvcyyF/FoXvXXXeNO+64I2655ZY44YQT4qijjop777131AWcddZZ0dXV1ft4+OGHR90vAICaquUtwvocTQg0gfPPH/k9U6fmXwe5m1DpByZNmhQ777xzRETss88+8bvf/S7OP//8eMc73hFr1qyJp59+ut/e7mXLlsWMGTOG7F97e3u0t7dXXjkAQD2ZNi3f/l9/fb79ByAXY75P94YNG2L16tWxzz77xMSJE+P6PiuE+++/PxYvXhxz5swZ62AAAOqbe9sCMIiK9nSfddZZcfDBB8f2228fy5cvj8suuyxuuOGG+L//+7/o7OyMY489Nk4//fSYOnVqdHR0xMknnxxz5swp+8rlAAD0sWJFxOTJRVcBwBhUFLofe+yxOPLII+PRRx+Nzs7O2GuvveL//u//4nWve11ERHzhC1+IcePGxWGHHRarV6+OAw88ML7yla/kUjgAQNPbfPOiK6BZTZsW8fjjRVcBLWHM9+muNvfpBgAaRi3ua9vi985taPX23Q288F891NTK6uke3RH1N7/WWF3epxsAAAAYntANAACt4Pbbi64AWpLQDQAA1VbLe7iX60UvKroCGsXf/lZ0BU1F6AYAAKBku+2KrqCpCN0AAKNRj3syqU+rVhVdAYxs+vSiK2haQjcAwFidfHLRFVDP2tuLrgBGtnRp0RU0LaEbAGCsvvjFoisAoE4J3QAAAJAToRsAAAByInQDAADQ3w47FF1B0xC6AQAA6G/x4qIraBpCNwAAQL35059qP8x16/r/79aIVSF0AwAA1Jtddqn9MMePr/0wW4DQDQBQqZtuKroCgHyk1P9/e7vHTOgGAKjUfvsVM9xrry1muEC+Vq0qugJyJHQDAIzFrbfWblgHH1y7YdH87MGsH+3tRVfQ38C93YyJ0A0AMBb77JNv///3f/PtP62l3sIdtAChGwCgnv3zPxddAc3EYcxQc0I3AABU0/33F10BUEeEbgCA4bS1ZY+5c4uuhEax225FVwDUEaEbAGAofS80df31Gz8HPRtlGlUj1w4NQugGABityZOLroAivfKVpe6hwms9XgV6zpyiK4CWInQDAIzW8uVFV0CRfv3roisYnd/8pugKWlPfoyI226zYWqgpoRsAoFy33FJ0BUAjmjGj1L3zzhHPPltcLdSc0A0AUK6Xv7zoCoBGtGxZqfuhh/q/1jeQ05SEbgCARvKudxVdAc3GxdSK9cgjRVdAzoRuAIBG8t3vFl0BzeDYY4uugB7jxxddATkTugEA6l1XV9EVUI6f/rRx9hp/4xtFVwAtQ+gGABjMT386/OsbNtSmjoiIjo7aDYvRe8Mb+v9/wgnF1AHV9va3F11BQxO6AQAGMzBADdQoezQpzle+UnQFNKrvfa/oCvq74oqiK2hoQjcAwEhc6AiopXrYszxlStEVNA2hGwBgJM95TtEVANTWU08VXUHTmFB0AQAAAC0vpYg994w4/PCiK8k4haZqhG4AAKiUQEIe7r676ArIgcPLAQDKkVKpe/364uoAoKHY0w0AUK6+wRugHNtsU3QFFMyebgCARrPppkVXQF//+78bP7d8ee3roD49/njRFVAwoRsAYKD29qIrGN6qVUVXQF///M8bPzd5cu3rGIvTTy+6AmhaQjcAwEBr1hRdwcYc2k6evvCFoiuApiV0AwAMR9ilWf3LvxRdAbQEoRsAAFrRVVcVXQG0BKEbAAAAciJ0AwA0ora2oisAoAxCNwBAoxK860ffK5jPmFFcHUDdEboBABrFr3+98XOCd+396U8bP/e//xsxc2bElltGPPpo7WsC6pbQDQDQKF7xioiHHiq6CnbddfDnlyyJeOqp2tZCY3E3hJYkdAMA9PWZzxRdwfCe+1zBrp7Mm1d0BUCdE7oBAPr64AeLrmBkW25ZdAX0+PKXi66Aenb00UVXQB0QugEAhjJ7dtEVAI3sW98qugLqgNANADCUm28uugKgWSxbVnQFFEToBgBodK5gDvVvm22KroCCCN0AAI3ooIOKrgBoJVtvXXQFDUvoBgBoRNdcU3QFQCt58smiK2hYQjcAAEARzjmn6AqGd9hhRVfQFIRuAAAg4v3vL7qC1rBmTan7ox8tro5y/OAHRVfQFIRuAAAg4ktfKrqC1jBxYkRK2YOWIHQDAEC5zj236Aqq6+1vL7oCaHptKdXXJpbu7u7o7OyMrq6u6OjoKLocAKDV9L39Vn01kzbWSLU2i4G3Z2uG6W4+yk8zTNtmGIcy5JlD7ekGAIDRuPnmoisAGoDQDQAAozF7dtEVUM+uvLLoCqgTQjcAQDMYeNgzUKxDDy26AuqE0A0A0KgOPLDoCgAYgdANANCorr226AqAcjTxBcgYmdANAAAAORG6AQB67Lhj0RUA0GSEbgCAHn/9a9EVANBkhG4AgME8+GDRFQDQBIRuAIDBPO95RVdA0R5/POLf/73oKoAGJ3QDAMBgttkm4mMfcw90YEyEbgAAKMf++xddAdCAhG4AgGZhj2y+fvWroisAGpDQDQDQyObOLbqC1vT000VXkI8TTii6Amg6QjcAQCO77rqiK2hNnZ1FV5CPiy4qugJoOkI3AAC0siOPLLoCGsWDD2ansbS1RXzgA0VX0zDaUkqp6CL66u7ujs7Ozujq6oqOjo6iywEAWknfc6Lrq4k0vEatu94NnK7NPJ2bedyK0izTdLhrRTTyeA2QZw61pxsAAEbiInXAKAndAAAADG7RoqIraHhCNwAAAIPbcceiK2h4QjcAAADkROgGAACoJtcAoA+hGwAABtpvv6IrAJqE0A0AAAPddFPRFdAsVq0qugIKJnQDAEQ4HBR6jBMRqqq9vegKKJhfFAAAtLqOjlJ3SsXVQX1KqfSgYkI3AMBAjdywfP3ri66g+TXy/DGUrq6iK4CmJXQDADST664rugIA+hC6AQAa3XHHFV0BAEOoKHTPnz8/XvrSl8YWW2wR22yzTbz5zW+O+++/v997Vq1aFfPmzYutttoqJk+eHIcddlgsW7asqkUDANDH175WdAUADKGi0L1gwYKYN29e3HzzzXHdddfF2rVr4/Wvf32sXLmy9z2nnXZaXH311XHFFVfEggULYsmSJXHooYdWvXAAAACod20pjf5KEI8//nhss802sWDBgth///2jq6srpk2bFpdddlm89a1vjYiI++67L3bfffdYuHBhvPzlLx+xn93d3dHZ2RldXV3R0fcqigAAeep7y7BGvFBWo9dfb4a7hVyzTl/zUPU087Rs0nHLM4eO6Zzurn9c5XDq1KkREXHbbbfF2rVrY+7cub3v2W233WL77bePhQsXDtqP1atXR3d3d78HAABQIPeth6oZdejesGFDnHrqqbHvvvvGnnvuGRERS5cujUmTJsWUKVP6vXf69OmxdOnSQfszf/786Ozs7H3MmjVrtCUBAACjNUR7HRibUYfuefPmxd133x2XX375mAo466yzoqurq/fx8MMPj6l/AADAKEyfXnQF0JQmjOZDJ510UvzkJz+JG2+8Mbbbbrve52fMmBFr1qyJp59+ut/e7mXLlsWMGTMG7Vd7e3u0t7ePpgwAAMjftttGLFlSdBVAg6poT3dKKU466aS48sor4xe/+EXstNNO/V7fZ599YuLEiXH99df3Pnf//ffH4sWLY86cOdWpGAAAaulvfyu6AqCBVbSne968eXHZZZfFVVddFVtssUXvedqdnZ2x6aabRmdnZxx77LFx+umnx9SpU6OjoyNOPvnkmDNnTllXLgcAgLrWRFdrBmqjoluGtQ1xFcNLLrkk3vOe90RExKpVq+IDH/hAfPe7343Vq1fHgQceGF/5yleGPLx8ILcMAwAK0ei3wWn0+utNq07PVh3vamvm6dik45ZnDh3TfbrzIHQDAIVo9IZko9dfb1p1evYd7733jrjjjsJKaWjNPP806bjV7X26AQCagnsSw8buvLPoChqT5QkDCN0AQGtpaxu+Ubz77rWrBepNE+25hHohdAMArWmo4H3vvbWtA2heixcXXQF1QOgGAFqHwz6BWpo1q+gKqANCNwAAAORE6AYAaDb26APUDaEbAGgN++1XdAUAtCChGwDytmyZi+nUg5tu2vi5traI//qv2teShzVriq4AgEFMKLoAAGhqfQ/zdSue+nTUUUVXUB0TJxZdAQCDsKcbAGrFebb1z4YRAKrMnm4AqAZ7tOubDR5AnnqWMSeeWGwd1CV7ugGA1rJiRdEVAM3qK18pugLqkNANANX2yCNDv/aCF9SuDga3+eZFVwA0k0mTiq6AOid0A0C1zZo19Gv33lu7OgDI39q1RVdAnRO6AQAAICdCNwDU2q23Fl0BLnYHQI0I3QBQay99adEVMBjfCwA5ELoBYKzcjqq+Pfe55b3vt7/Ntw4AWpLQDQCVamsTtBvJokVFVwCNa889i64AGp7QDQCV6Bu2p00b/r0zZ5bXH2rn0kuLrgAayz33FF1BY1m1qtT9gx8UVwd1ZULRBQBAw3riieFfX7q0//9bbz3yZ8jXkUcWXQHUvxe8QNgerfZ2F2pkI0I3ANRCTyPMHu76sXJlxOabF10F1J+777asgipyeDkA0Jo226zoCgAa2+zZRVfQEIRuAKB1pRSxbFlzHg76wQ8WXQHQ7Nz1oSxCNwCMxVgOwXT4Zn3YZpuiK8jHZz5TdAUAhNANAOWrRkhuxj2q1I/ddiu6AmgtNp5SBqEbAKBZ/PGPRVcArevQQ4uugDoldANAHuz9AGgt//M/RVdQG3vvXXQFDUfoBoBqGT++8s9suWUW0HseAFDP7rij6AoajtANANWybl3ln3n66f7/X3hhVUoBAOqD0E1zsscIyFt39+g/O9zF1E48cfT9BQDqjtBN8+kbtgVvIC9bbFF0BQBAAxC6AaActdyI19FRu2EBALkSumku9mwDtXDLLRs/d+SRlfUjpYi99opYvnzjw82XLx99bQBAXWlLabgTy2qvu7s7Ojs7o6urKzps6adSg4Xu+prFgUbVd/nSs1wZ6bm+ylkWDdY/xq7VpmurjW9eWn06tvr4l6tVp1MTjneeOXRCVfsGRbKXG6i1PBsabW1N05Ap1KmnFl0BAC3O4eUAkLdyw/OMGfnW0YrOP7/oCoplgzRA4YRuAOir55aDRx1V+2E/+mjth9lK3vOeoiuojVe/uugKoDU4koYyOaeb5jBhQsT69YO/Vl+zOFDPBu4V7Lv8KPf8tbFeW6Lv5z/72YgPfKD8z7KxJjzvsCytOt7V1OrTsNXHvxzDrTOaXRPOH3nmUHu6aQ5DBW6AaijqEN0zzihmuABUZsWKoiugjgndNJ8m2doG1IEi7ohgGQbQeDbfvOgKqGNCNwBERDz44ODPuxAVADAGQjcARETsssvI73nqqfzrGOjnP6/9MKHVXHqpDWzDMW1gTIRump8VBVAtW2458nuqfXj4615X3f4BG+u5sr02A5ADoRsABhosOK9bV+zwYbQEyeGZPoP7/veLrgCahtBNc9JgBSpx5JEjv2f8+PzrYHR67q0uPJV0dRVdAY3ubW8rugJoGkI3AHz72xs/13fjnQ15NJoq32MWgNETugGgr4Fhux4Ctz24kA+/LaAGhG4AqEf1EPYbgdAEFMGyhwoI3TS+004rugKgkTVKw6lR6gRoZq4fwSgI3dS3tWv7XyBnsIXceefVvCygSW27bdEVALVyyCFFV0CzcGQSIxC6qV9tbRGTJlX2mfXr86kFaE4DN+T97W/VH8ZYGmMDP2vvCqPlqLCN/fjHRVdAo3v0UYGbsgjdNJdxZmmgTA8+2P//Rx8tpo6RXHll//8F7xLTonyOCoOxG7jMmTGjmDpoOBIKres//iNi552LrgIoyi679P+/XhtPb35z0RU0lr6N4s99rrg66oE9cJAfvy8qMKHoAmBQTz2Vb//7Nsra2iw4odUMDNzVXgakVN29sNXuX6s444yiK6Be+T0BNWRPN/Vpq62KrgBoZgMPLc9Dnvf4Fhgqt+OORVdAvVq+vOgKgCYndFP/7r67///HHFN5P0a6gIwGLLSOgb/3RjnSZaediq6gvtxxR2XvX7QolzJoApMnF10B0OTaUqqv1kZ3d3d0dnZGV1dXdHR0FF0ORenbKB7ssMq+s+3A9w72/EivDXwdaF6NGrojhl7etaLhNpb2TBvTyzQYynDtDPNPyVDTyfRo3WnQowmnRZ451J5u8jXc/bUrMZof8y9+Udn77e2G5tfIgZuh+R7LYz2XKWc6vOhFuZfR0MxLUBGhm9qp9QL6Na+p7fCA+lWNjX/1ZtasoiugEbhLx/CGusL9nXfWto5G0GzL0Eq1+vgzJkI3tVXvC6x6rw8oT9+jbIb6XTf63tFHHim6AhrBAw8UXUF9O/30oiugEW3YUHQFNBihm/zUIsAKycBA5SwXGvVImEbfUAC1Uq3T22Aw5isq5D7d1F5e98U++ujyh9+X+99C83jmmaFf22svh4xCq7O+BwpgTzfV09YW8U//NPhrzz6b//C/+c3KP7PDDtWvAyjO5pv3/7/nXtkpNWfgPumkoisohuBENey9d3nvmzYt3zqgGTnSpB+hm+ro+VHdfvvgr2+ySfn9evDBkd9z6qnl9284f/nLxs9ZQEBjasUrk19wQdEVFG/HHYuuoLFMn150BbU31Hq93Hu9f/vbVSsFWkLf35x2dUQI3eThVa8a2+d32WXk95x//tiGMdC7313d/gG1tdlmRVdQO62wMaESixZt/Nwb3lD7OhrFY48VXUHjOfDAoiuAxiFkD0ropvpuvDFip52q06/Fi0vdeTY0/+u/8us3kK9//deNT2ERTFvbT39adAX1xe8hIwwwWuad8phOQxK6ycdgh233Ve6P0n1ogeE89FDE177W/zkBozX53hnOhRf2/9/8Up729qIrqD9LlhRdQeMRxoXuQvRcWOBtbyu6ktroWbE10nl3Fg7QGHbeuf//rdiQtrwanOnSuj7ykY2fO/HE2tfRDFatKrqC+jNzZtEVNIZWXB8PQ+gu0g9+UHQFtTXYeXf1pO+h7EDjWb686ApqR2OmMtdcU3QF1NL8+UVXANCP0M3YFbU3odIjBdrahr/quUPZobFNnlx0BdSrgw4quoL60uoXBrPRqjqqdScZWkOLH33UllJ9LXm6u7ujs7Mzurq6oqOjo+hy8tF3pquvyT86I/2I+o5jOeM+3HuGG9Zg/dt55+ycz3I/04q3HIJG1mzL00oY98xQ65i+Wm36DKaV1m+VtEsG+0xKrf37GqjStlczMj9sbLBpMvC5lSv7bxCv82mXZw61p7toLb7Vp2qG+hEPd8/vOv/hA5StldYlrTSu1dSq67zdduv//zHHFFNHszjllKIroF4NtmzefPPa11GnhG6qa+BKvRYr+Q9/uHr9qmTPOkCRFiwouoLiubIyI/njH/v/f/HFxdTRyFatirjssqyNdN55RVdTPe9/f3nv0xasnhaelkJ3rc2eXXQF9e3Xvx7+9cFCfLUvmPLXv/b/v4UXEFDXWv23uf/+RVdQPFdWphIzZhRdQWNqb484/PCiq6iutraIL32p8vVIqx4xMhb77Vd0BXVhQtEFtJzf/rboCurbK19Z2fvLWfgNPDdrJNtvX1kNANQvjWTMA1BbfX9zN95Yaoe38G/Rnu568Ic/FF1B+XruMT7SRTV6HsPZd9/hX+/qGvz5desijj463x/uwH7vskt+wwLGroVX5L2e85yiK6iutraIqVOLrgKAsSonFzQ5obse7L130RUU4ze/Gf71oa4aOH58xDe/Wdmwdt65svcPNNwF2Wh+a9cWXUFr6ruRz6HUI1uypOgKqqdnw+7f/15sHc2s1U/PAKghoZvRG83GgqK2cj3wQOWfafEtci1jpCM32toiJk3SQC3ar36VfQef/WzRldSXZlxO+a3lp1nnl5GW49DXBGfXUntCN6PXSIfF09x6Glxbbln55wbrHuo5jbrinXlm0RWQp7H+xubNq04dtLa+9xWm+axfX/57rfepEqGb8p166sbPNdLCqO+hl824tb9V9Z0Hn346n/5CozjkkKIrKNaXv9z//4H3aIZyrFxZdAXUI/d4ZwyE7nqx7baDP7/LLvVz6NT55w//+p571qaO0Zo5c2wXcvjTn6pbT6V65oEttii2jlZQ9G8NRuvHPy66gtEr53e39daV9XPgPZppLpbV1JJ7vDMGQne9ePTRUqiaNSt7rq1t4wt4/fCHta+tXHfdVXQF+dp116IryKxYUXQF9eM//qPoCqB4zX7kTt+jrJ58srAyAGC0hO4iDdVQeuSRobfeHnZYfvWwsWZvzG66acQ22xRdxeh99KMbP1funo+Xv7y89w2cB+xZqY3BTmeheEUceTXUUVbNvnyuhby+x/PPL+YIvbEM75RTqlcH1TV1an0c8QljIHTn7cUvrn4/LXSohsmTI1atinj88YiXvrToamrvllvKf+/7359fHXl63vPq5/SUSo10OgtDmz07n/4OdmHBk07KZ1huFZafI4/Mfxh9N5o1SvA+77yqlkEV9V0eNNq6DP5B6M5TW1vEHXcMv4DoOcd4uHONB3t+NAudemx4910xt8KerdEGoKHO+R+LvheKufXW6vc/b/Wwp62etbVF/PnPGz9XrX4ff3x1+tXjn/956Nfs0azMb39bu2FdcEE+/Z0yZfSfHWmd2uouvTTf/pdzJ4i8hjPQjjtWf7gMrh7bmGOV10ZFWpLQXW8GhvCeRsNQwbvcBdxIt0aq5PPV1DfMNGKwicimzec+N/x7OjvHNg0ffXT0nx2relqRDrXRYuDvoxU24Axlm21Gvu/4WPR8/qtfHVt/BvbzmmtGtzwjU2TA9H3QY7h5YeCV5Wth0aLaD7PVjPXWmn3X6/W2Dshro2IzauV2V5kqDt033nhjvOlNb4ptt9022tra4kc/+lG/11NKcfbZZ8fMmTNj0003jblz58YDDzxQrXpb21CNqmotfLq6ylvojfW8p3Iah2vWjG0YeRm48aLn/zPOGHzF0/Po7q5djdVUL43pb3yjslry3oDzilfk2/+B+s5Lv/nN8O95/PHK+ldpHcP9Pxrl9mOTTcY+LIY3sPE70lFaw2nUZR6jN3B++fCH+/9/8smDz2OjCV3Ul2oefdnWFvHXv469pqGccMLoPufImeF94xtFV1D3Kg7dK1eujL333jsuGGLrz6c//en44he/GBdddFHccsstsfnmm8eBBx4Yq1atGnOxDa8aK5M8fvQ9C76+h/MNV2stznuaODH/YZSrksP7m7nhUO44vfrV1b9f9nHHDf36cEeDDNfPsVi4cGyfH4t9962s/pEOs21rizj33OH78fe/5zNPV/I7f/bZ6g+/mc2cWZ3+jHavVWdnvsOhWCOt52bNipg/f3Rtlra2iAkTRl8b+Rvpe33Oc4Z/faTfe9/TAobagzraZcZFF2383Pz5o+sXJe5tP6KKQ/fBBx8c55xzTrzlLW/Z6LWUUpx33nnxsY99LA455JDYa6+94r/+679iyZIlG+0Rb3oDFwYDL1wylvOMqnmuWp6HoTarak2XM8+sTn/qSVtbxIIFEVtuWb3+DbTddsWcsznYVcwHa3jeeGNt9t707edgjZKB0yeloS+gdNZZw9c4dWr5NQ3sz9y5Q0+DdevK6y+VW7q0sve/6EXVr2G0872rSNfWcIeFnnrq8IfYDvUdL15c6h43ijMZ16/XPmlkS5YM/dpg311X18bPbbZZ9rcWpx5+5CP5D4OWV9VzuhctWhRLly6NuXPn9j7X2dkZs2fPjoVD7BlavXp1dHd393s0pW9/u///RZ9nVO4K6+ab862jGYwU/IYKiJ/9bH411YO99x79Z4cKaSlFPPxw+f2o1QXi+tb6qlfl1++hDGyUDDVPXnppaV4crCGz/fYjD/+ZZ0aus2/39df3f37vvYffEFHuBps8QmKjG8tGqDvvHP71l7xk9P2ulKtI19bAZUHfjYXnn59dTGqo33c51q8f/Ho1PfPrHnsMfTpC32Htv//gy45LLqmsHmprpA3QKUV0dGR/29tLzw92dNNIR205bYE6VtXQvfQfW9anT5/e7/np06f3vjbQ/Pnzo7Ozs/cxa9asapbUOkYz3fou3CIGD4Zz5gy9kOxrLAGrUb3oRf0Pbf7LX0qvDRW0a3GEQlEG1vSHP1T++eFWjqOZdi99ae1WuCMNpxo1fP3rI7+n3On0/vdv/N5yNmhsumn//ysd55Hmi3JPTRgpJDJ6g81Dt91W+zoGyuMuDq2q2kcJ3X336Ou4556ILbYY+eilX/1q8Off857RDZt8lbPuHfh953kqaqXrYBcGG9nmmxddQUMp/OrlZ511VnR1dfU+Hi53Lxb9PfJI5Z8Z6mJlo1kZ33FH5Z9pZClF3H57/+d22KGxb1Nz2WX9/588uXbDHm5leMkl5U/Tepr2//mf1a/nve/t//8uu4y9nyPtORjsvYMdaj/SZ0dbQzkuvnhsn29WeTUaq3Uby0oVeReHVjHa7/GFL6xeDQPnr5e/vD43NDM29bS+Hkyj3lGnlga2SRhWVUP3jBkzIiJi2bJl/Z5ftmxZ72sDtbe3R0dHR78HZarmAmtgv449Nv9hNpJy7qfeSAZrjB9xRP//B7soRrUvaDLcZ2fPzqZ1pXsxUhr8/LAe06ZV1r+B/S53XvjgB0c/nHI9+GD+w+jx//7f2D4/2LSq1u/pmGPG3o9mVK1GY7lHn1Sy8WWsR6A0w3K43pU7jYfaOFctt9zS//899miu9XErWLGi//95H/U31Pwx2mWO+WxwTgWqSFVD90477RQzZsyI6/ucw9fd3R233HJLzJkzp5qDIm/f+IaFTDMbbWO80s+NtIIb6tSFlMZ2PYGe88MG88QTQ39upCuuDmaoMJmXvH+XPYeJDvxuBl6XohJ995BrLOerWtM1z+/HXsv6U2+H0g43/91zT2Xvp3aGWh9uvvnolv2DLSsqvSbSUNchgRqrOHSvWLEi7rjjjrjjH4cTL1q0KO64445YvHhxtLW1xamnnhrnnHNO/PjHP4677rorjjzyyNh2223jzW9+c5VLp2wjNZaHWwAO10h+5SvHXluEBlij2223/v+Xs0J9y1vKu1ZArS1ZMrr58dWvLnVXcrh2NVS7n4MdJlrJ9zLwvaO5cjHNa+D8+stfFlMH/TXKobRFryMY2cC7ZlTq+OOHf73Su/8MvA4JFKTi1tCtt94aL37xi+PFL35xREScfvrp8eIXvzjOPvvsiIj44Ac/GCeffHK8733vi5e+9KWxYsWKuPbaa2OTTTapbuVsbKjG91C3CRqrX/1q9Husdt65+vVQjPvvr+z9bW0Rg91CsIjG1J13Dj/ccgPjL3859G9hqFM1ylFpoB7tNBzN5wb7zAc+sPFr69dX3m8b4ppLz17Uwb7X1762vH64WFb1DfwN19vpfQJ24xrL0UwXXjj4867dQYNrS6m+lmrd3d3R2dkZXV1djXt+9/bbj3wV4GpN9nnzIr7yleH727ehk1L+51+Va7i66mu2rK5Kx3PLLQe/ovNYplE552iO5jzOntcGm8eG6t8zz+S3JXqk2oaqd+DredQxls/lUe9wQXeo/lZzWTLU8Pfeu3Shxry/p2Yxmu9ltL+LamwgGWr5P5p5ksoMNY0nTswutlrp99L3fdVQybKzGkdPWcaUL8+j1Ubqd6Xt2nKWU8Mt13z/Q2uy30yeOdRxf9Ww3Xb9LwpTyyuwX3BB5Z8Z66E/eWjVPVvljHe5t1CqpnLP7xuq/kmTyntfSg79Go1a3qKv6GVEq90ZoRqG2vhajeXsKaeMvoahNFmjrSkMdXeTkVT7O3MNCCp16aUbPzeWa6+Y96gSoXus2toi/va3oV+v1x+rlVhxGmG6D3d+35Qpgz/fd7xWrx6+/+ec0xjTIQ+veMXY+1GPQbRVv89G0DfUVhK+v/zljZ8beLXar31t4/eMNC8M97pTj4CxyOuUShgjoXssBmu41NsVQBuRxnt96bnyaI+e23GNZq9Zz8aej360OrU1ooULi65gcBs2VP6ZlLLbdfW9kFyeyt3LysjK+f3Omzfye447rvxhTpw48vL9gQfK7x9jZ31LtVRzXvrc56rXL6gTQvdoDdVgKfoKoNU6hJDWNNS8M/AemwMNFoYGnsbQyo27Woz7WAPpYN99OYexX3xxda5AXc40ck/Q6ur5zvPaWDxwGTDaQ5ZhNFp5ndPoTj+9+v00P1AwobsZDHX+XjUOY6X5jSasDQxoQ4WhVg/bQ+nZODbcRrJKN57lEUjr8TB2yjPYBpOhfot5biy2DGg8o71FoO+ZZmDHFTkRuquh0hVNrQ6RrNfDWKmO0e6dKjcwUzsDQ/i55/Z/fbBljEOtGc7ADSY989BYzreuJgGtediw0ppquQ4abv6qJCS/6EXZ33Lv9V3Li5bS9NwybCy23DLi73/Puoe7+mqtbz3QKLfiauUr1o71Nijlfnak/vXcjqnvcxs29L8/da1uq5WHerllWI+urqEvRDeccm7ZVY1ai75NSjm3oMnzNjXNpmdajXSbv+Hmo/b2/oeFj3RbylNOKX9Dnu+7Pgz3ux9pfVFv38VYa2vE9VyR8pwXTj21dBTOwH5PmVK6vsxAY70tZz3P3/WoyX4zbhlWr3oCd0TDzlzUiZEONe5R7flssMOHxw2xWNh9941rMd9XprOz/y1wtt++Ov2t1vfgUNHmUo3faN87EQzVr77PO3Km8ZQ7j9x5Z7510Ljy2Ot93nlDL8OKuJUqjNGEogsgZ/V8bsoppxR/4bl6UM/fUd+V3b33FldHs/rrXzd+rpL5IY9gLGwzUDnzhPmmOQz8Hgc7Wg96+N1D2ezpzlO559DVSr2dA9rKe0SG+y40cFpb3z3hjiYgb5Y3RJS/rJk8Of9aAJqQ0N2MhlpxtnLIrTeN8F0IezQCF7qpXL1tgKVxrFxZdAUwNMu2+uB7GJQLqVXbUBdgqPWFGRrl4jONUmceyrlA2uTJ/Rs51bgwXjkXEmuW76DeLqTG8EZzYS3f0ejUyzw/0vfZyuuIelEv80ottNK4NrpqLBtcSG3smmwZ7UJq0Ow237z//z0LsVrtVXABLerBwN+BebG1+L4BaFJCd7UNdR5mvZ3fTX1ZsSJi8eLh35P3vOP8YYq2YkXRFQDQqlzjghwJ3bUk0Iyslc4DGbiBZtas/IdphTK4wX6bfq9QPL9DoAgDj7yCMRK6m1WjNlQa4QJjtVJuQC73Ht/QDBp12cbgWmlDK9A4HHlFlQndUE/GchGQSt8rvABFO+88p7YA0PSEbmgmPcG6797vwfaCa+ACAzXCXmfLLmgKN9wQcccdWfd110XcfXfWfc01Effdl3VffXXEgw9mP/srr4z4y1+y7iuuiPjbIyk2RFtcHu+IZbFNrIvxcdllEU8+GbFmTcR//3dEV1fEs89GfPvb2XVpV67Muletyl777zgi1sTEeDKmxnd2+Eisi/GxLLaJy+MdsWFDxN/+lg0rpWzYV16ZdT/4YFZbRFbrNddk3XffHfHzn2fdd9yRjWNExO9+F3HTTVn3woURN9+cdf/qVxG33pp1//KX/afHPfdk3T/9acT992fdP/5xxEMPZTX88IcRf/1rxIYNEd//flbr+vURl18esWxZxLp1Ed/5TsRTT0WsXp1Nj+7u/tNjxYrS9Hj66ew9a9ZEPPFExGWXZf1bujTie9/LhvPIIxE/+EE2/EWL/jE9IuKB2Dl+Em+IiIg/xm5x7bVZvXfdVZoen/tcNqzVq0c/zzS8VGe6urpSRKSurq6iS2l8/c8aLrqawX3kI/VfYxEGfnd9p81gr1X6aBUjTb+h3ttK06gedXQM/7rvqToaZZ5vhBqbWSutR1ppXAt0550ptbVli/qf/zybxFtvndL//m/W/ZznpPQ//5N1P+95Kf33f2fde+2V0te+lnXPmZPSF+KUFJHS3PhZOic+kiJSOuSQlM46K3vPEUek9P73Z93ve19Kxx6bdZ92WkrveEfW/bH4VHpj/DhFpDQ/PpReE9eniJS++MWUXvay7D0XX5zSC16QdX/3uyk997lZ95VXprTttln3T3+a0lZbZd0//3lKW2yRjeMvf5nSJpukNH58SjfemNLEiSlNmpTSggUpjRuX0mabZe9pa0upszOln/0s68e0aSn95CdZ96xZKV1xRdb9/Oen9F//lXW/6EUpXXhh1r3vvil97nNZ9+tfn9KnPpV1H3poSh/6UNb97nenNG9e1n388Sm95z1Z9wc+kNLb3pZ1n312Sv/8z1n3pz+d0qtelXV/+csp7bNP1v3Nb6a0++5Z9+XxtrRj/DlFpHRVvCnNiCUpIqVrrklpyy2z91x/fTaeESndcEORc97I8syhdbckEbqrrBFWGFZsg8srdLcSobs5+Z6qo1Hm+UaosZn9Y9r/e5yVjolvpDUxIf1bfDIdf3xKa9emdMYZKZ1ySkrr1qV08slZA3/dupT+9V9T+vjHU1q9OqWjj05p/vyUnnkmpf/3/1L6whdS6u7Ogs+FF6b097+ndNhhKV1ySUqPPZYFp+9+N6W//S2lN74xpR/9KKW//CWlgw9O6dprU/rTn1I68MCsAX/33VnIuPnmlG67LaXXvS6l229P6de/zrrvvTdr9L/+9Sk99FAW7A4+OKWHH86C3RvekNLSpSl95zspHRJXpidjy/SNOCYdFlekrtgifTlOTO98Z0orV6b02c9mwWXVqpT+v/8vC3Fr16b00Y+mdMIJ2Xh/4AMpnXpq1n3SSSl9+MPZe973vpQ+8Ynss+95T0r/+Z9ZP484IqXzz8+mx9vfntJXv5rSU09lYenSS1NatiybHt/7XkqPPJLVe9VVKS1alI3H//1fSvffn02PBQtS+sMfsvG+5ZaUfve7rPvOO1O66aas+777slB44IEp/fnPWbA7+OCs31dckU3vZctS+va3U3rzm7Navv71lN761qzGL34xpcMPz77LT386pSOPzL7jT34ypfe+NxvXs87Kwt26dVnAPf30rHvevGxfS0/Yi0jpxS8udb/whaXu3XYrdfeE3J4A2tM9/R8BLyKlLeOJFJGF1y22yJ6bMCGlTTfNutvbs8AbkdLmm2eBNyKlKfFUbz+mxbLe7uc8pzScHXcsde+6a6l7zz1L3S96Uan7n/6p1P2Sl5S6X/rSwbt7wuzA/vTtf9/h9p0efevcZptS95Qp2d9x41KaPLk0PdrbS9NjwoSse/LkbLpFlIJyRErTp5e6t9tu8OHvFveWvr+4c9Dx6Bm/zTZL6a67CluSlUXorlNr1mQLHcZIg2pwp51WWUBswID917+mdOKJ2d8HH8y6lyxJ6Z57spXzE09kjaeTT07p6aezRtWpp6a0YkW2xfiMM1J69tmUrrsua9isWZM1IP7t37IV/P/EW9Kn4mNpfbSl7343a/RtiEjfiiPT5+PUlFLWwLnggpRSRPpSzEtfj2PThoj02c9mW5M3bEjpP/4jpcsvz/r5yU9mW7fXrEnpYx/LGnCrVmXD//nPs2XCGWdk9XV3Z1/jLbdkDZf3vz8bn8ceyxpj996bje+8edn4/+Uv2TRYvDhrVJ54YtYYvPvu7P1PPJHS73+f9aerK6WFC7P+r1iRNT7PPDOr5f/+L2v0rFmT0tVXl6bHD36QNRQ3bMgamP/5n1n3N7+ZNYJTSumii1L6yley588/P6VvfCPr/sxnskbY+vUp/fu/p/T972f9/MQnsgbxmjVZw/Oaa0rT4/rrs0blGWdkDb6urqze3/62ND3uvDNr4J10Ukp//GPW8Js3L2scL1qUTYOHH84alfPmZe+9K16QToovpidjy3TrraXp8etfZ/1fuTLbc9AzPa69Npsea9em9OMfZ1vy163LGpjnnJON33//d9aA3LAh26tx/vnZ9LjwwuyxYUNK552XTasNG7L3fuc72fQ455ysX+vWZSHjqqtK0+Paa7N59IMfTOkXv8i+qw98IKu1qyubn3/3u5SefDIbjz/8IfvO583LGscPP5xNg0WLsgbyiSdm0+i++7L3PPZY9pmTTsqm6e9+lwWg5cuzaX766dk8ef31WQ2rV2ff0Uc+ktLaGJ9+FP+SPhFnp/XRlr73vey73bAh+64/85ms+xvfyBraKWW/la9+NXv+85/PQtKGDdm8dNll2fT4//6/bF5buzab1ldfnQ33Ix/J9uL0TI8bbihNj9/8JvuNn3JKFpyeeCL73d91V0qPxvQ0L76U/hQ7p8WLs2nwl79k88iJJ2bB7I9/zKbH44+ndMcd2Wf//vdsXjv11Gx6/OpX2bCeeSb7rX7oQ1ld//u/2W957dqUfvjD7De+fn32m/+P/8jG79JLs8C1YUMWQL70pWx6fPnL2Z63DRuyvUyXXpp1n3tuFhrXr8/2OP3wh1n//+3fsmXU6tXZPHnddVk9Z56ZBably7PvbOHCrP5TTsl+848/no3TPfeUlhkPPDC2ZeiCBaVl6M9+NsQy9H9S+lR8LP0pnte7Wrkgji91X1Ba3XzlK6XuL3+51H3++ak3DH3606XG/znnZN2bbJL9ViKysHT66f8IQNOy4N4TtN71rlIYe/ObS+Fm7tyse7/9sr2fEVmI7Alwb3tbtrc0Igt7U6dm3e96VymMHHdctvcxIqXT4jNpfKxOESl9ND6ZxsXaFFHacxiRBeye7lNOKXX31B6RTdvBnu/72aOPLnW/852l7p7xa2vLgnJEtqf0Fa/IuidOLIWaTTYpBbLJk1PaYYdSeOoJYdOnl0LY9tuX9jo+//mlELbXXqUQNmdOKYQdcECprje9qdT99reXuvuG6Pe9r9R93HGDj2tP4PVotseGEd/zvvfl2qwcM6G7Dl16aUozZ2Yr1j/8IVsQXntt1uCZMydbmf3qV1n3zTdnK/hXvCJb+V19dXYYyL33Zg3X/ffPGg+XXprSa16TNbi/+tVsRbJ0adbQO+igbOU5f3620Ovqyhozb3lL1sA888xsi/Gzz2Yr13e/O1t5HndctuVxzZpsa+S8eVkj9J3vzFYIK1dmW1M/9rEsIPzLv2SNriefzFZan/98VsPrXpc1PB9+OKvxW9/KGoD77581TP74x5Re+cqsQXvnndm4/uxnWdiYMycLIDfemHX/9rfZa694Rfbeq+JN6ZVxY7ovnp8uvzzr55//nA3jNa/JhnnhhVkNS5dmNR18cNbA/Pd/z6ZHd3fWSDj00FLoeec7s3GdNy8b9zVrsq3Sxx2Xdb/73dm0evbZbNqdeWZpenz849k0fuMbs2n+xBPZd3DeeSk9+mj23Xz1q9l39ZrXZN/dgw9mtV9xRfbdvvKV2Xd9++3ZuF53XTYvzJmTzRs33JB133prNu+84hXZvPSjH2Wfvf/+rNH2qh3+nBYtyhr7r31t1sC8IE5Ir49r02Oxdfrsflemf/7nbHqcEx9J/xI/St0xOX30o9meg2eeyVb4hx+eNfROOCGlo47KpsExx2QLwDVrSodhrVqVrUw//OGsYfbmN2fB6umnsy3s//mfWQPwwAOzhvijj2Yr5a9/PWv4vfrVWYB54IGsEfSDH2QNwH33zRq3v/99Nq7XX19amR98cEqzZ2fdb3tbqbF09NGlxtLJJ5cO4/rIR0qHcf37v5e2an/hC1kDJCL7fib+o+F0afy/NK5tfYpI6bvxttQWWfePflRaEVwVb+zt/lH8S4rIGgY9h3S1t2chKyJr2Hzzm1n3tGmlhuf225calbvvnk23iGxL95lnZt2vfnXWMI7IpudRR2Xdb3979n31jPdBB5XGe7/9su4Pf7i0Bf1Tn8oaTBFZGOjZCn3BBdlhehFZjR0dWfd3vlOaNt//fqlx9T//U2pcXXVVaXr0nTY//GH2d/z4bG9Lz/ToOeSvoyMLZhFZI++LX8y6d9wxW0ZGZIfmnX121j17dhZ+IrJ5uqdh/aY3ZXvBIrLf71veknW/973ZXqqIrIG7776l+WDvvbPuc85Jaeeds+7Pf7609f+ii0rzyiWXlBrZl11WamxecUU2bhHZBpXeeaLP9Oh5vq2tdNjjhAml6bHppqVD/iZPzua/iGzYn/981r3ddlkgjcgayT2HQL74xVlojsh++z0N2AMPzPYuRWR/e6bBkUeWGt8nnpg1liOyINvze/nUp1KaMSPr/tznSkHjwguzvTwRKX0r3p0mxTPZ9Ii39zaEe8avnOkx8P2XX16aV3p+I+3tpd9IR0cW5nt+Oz3zxA47ZGEwIgtV731v1r3PPim9I/47RaT0qvh5b8B63etKy4zDDisd+vme95T2Sr3//aVp8LGPlULHueeWQseXv1za+3XxxaUw0PNb75k/BvtdDNX9gx+Uunt+I+PHl34j7e2l38jkydk6pmde6ZknnvOc0mGgO++cra8isqDVE8j23TdbnvTMKz171N72ttKhn8cemy2XIrLpO21a1n322dmhrBHZMqtnb+BXvlKaHpdcUpoeb4ore8dpu/hrb3ffvY5994T13fvW8x1ElJZNEaXh90yHnu6e5VREqZaeadjT3bPM6vvo+1zfUNezrIsoBeuB7+n72bZ/hOyIlMbFmkGH7+HhMbrHzjvXOrFVRuiuQz1b8qZMKTV+tt221AB87nNLh8zsu2+pEfDKV5ZWQK9/fekwjre8pdQQOvzwUmPwmGNKK4wTTiitGPpuWe27NbXnvI2I0so7ImusD9bdEwQiSg2etrZSKJgwoXQOTHt7Fswislp7GsRbbllqDM6YkY1jRDbOPQFh991LW2Jf8pLSlthXvSqlbeLRFJHSQfGT3pXwoYeWpscRR5Smx7HHllZ88+aVpkdP7QOnR99pUM706PvZnmnc1lbaMj1hQmlrbXt79l1FZA2GQw7JuqdOLW15nzmzFBB22qm0ZfoFL0hpl12y7pe9rNRwefWrSw3D1762NA3e9KbSNHj721Ma/4+GwFFxce806Lv1vOccpohSuBk4rh/84MjP993Z3jNPtLWV5olx40p7HyZNKjUGN9ustHW+o6M0DaZNK/0utt229P31bcz0bWT1bXz1TIuI/o21nkAV0f/QqpkzS93P6dNIfH7c19vdc65SREr7xS97u18ZC3q7e/acRPQ/BKzvYXB9D/vqmbcH1tATetra+h/q1dMI3GyzUiOw7/j1Pbyrp/EcUQrcPfNTT3ffQ/X6Hr7Ws5yKKIX4iGxD0aDTo897en7TEaWgE9H/ELq+h8H1zNsDa+47Ln0Pfev5bidNKn3/m21Wmj963jtwmvY95K/v9OhbS98a+9Y+lunR97M95/xFDH3IX9+g0bMRpGcce7r7hoGe30NbW2ka9A0O5QSKvv3uCVQRpQ1UESlNicd7u7fqc5hm35DUdzyG6u6Ztwf2v+9we5ZfEf1/40Xs8eo7zHKmZd/lUN9xGmoa933/UN9b4+3p2zBEt4eHh0f5j/b2QmJb2fLMoW0ppVTURdwG093dHZ2dndHV1RUdHR1FlzOk97434uKL8+l3W1s2a0ZEjBuXXTEwImL8+OxKghEREyZkVyaMiJg4MWLt2qx70qTsyoMREe3tpasE9u3u+56+3X3703dYfWvoW1utDDU9Kp0Gm2ySXaFx4POVTo8ipkE5hppOQ81DQ33HQ41rvY53eVJEtA3S3deGKN3QoW83NKtyfhcAUD313JbMM4dqVY5Sz6X/89B3ZuwJQhGlIBRRCpsRpWAYUQqMEf0vy9+3u+97+nb37U/fYfWtoYgfylDTo9Jp0BO4Bz5f6fSo14XFUNNpqHloqO94qHGt1/EuT9sQ3X2NG6IbmlU5vwsAYKy0LEep5555AAAAMBShe5S22qroCgAAAKh3QvcoPflk0RUAAABQ74RuAAAAclXH18jOndANAABArrq7i66gOEI3AAAAuXrrW4uuoDhCNwAAALm6++6iKyiO0A0AwDDSgEezGjiezT6+RGz4xyNFxPrwfVdqdfT8TtpiVfRMv7a2wd+98861qqv+TCi6gEa1224R992XdU+cGLF2bTaDjR8fsW5dxLhx2f/r12fPRWTdEyZEbNiQPcaPj0ip1L1hQ/b/hAlZPyL6d/cMZ2D3pEkRa9aU393eHrF6dfnvKef9g3WPG5c9RpoeKW08bSZMyJ4bOD0qHe/NNot45pmse9NNI559duPnN988YuXKrHvy5IgVK7J6J0/Ozj2ZMCHrfvrpbPibb551t7dn/Xz66YhNNskeTz+dPTdpUkRXVzacCROy/my2WTbuy5dn/Whry4Y1sDsiq2fy5FL31ltn06C7O2Lq1Gz8VqzInl+9OmLVqqx7+fLsta23zl5fuzZi2rSsrpSyhd2zz0Z0dka87GURf/pTNr132y3ij3/Mxm+XXbJ5e4stIp7znIh77sn6N316toVy+vSIbbaJuPPOiO22i5gyJeKuuyJ23DG7QMYdd2TD2XzziNtvz/q92WYRS5dGvPSl2fjcf3/EPvtk0+jBB7Pnn3oq4q9/jdh//+w9Dz8c8epXR/ztbxF/+UvEq14VsXhxxCOPRLzylRF//nPEsmURc+Zk/XjqqYiXvzziiSey7uc/P3t9+buOjefFong0ZsTqmBQ7xMOxJGbEhku+E9ttF7FkSTb9Z87M+r/JJtn4Ll6cTYMtt8zqmjIlG7+//CV7ffLkrIaZM7Pv/KGHsuk1aVLWveOO2ff94IMRz3teNow//SmbHuvXZ+O+995ZrUuXRuy5Z8Tjj2c177lnxGOPZd/3QQeVfic9K7E8ujdsyOb7lLLHYN0R2fs3bMj+9nSPG9e/HwO786696O6ihz+wu5zvZKjvO6I0TpV0VzpPVNo9cN2RV/dQ8/+GDdn7BuvuO9493evXD73eK6J73bpsOVJpd28bZcK4SJFFk/ERsWF9ipT6t13Gj8+G2daWjXvf7nXrstfb2kZfS02628b1NozXRamRvG5t6j89hmi/9XRHbDwNGnJ6lDt/jHJ69PxGyhlmbr+RCdk/6yObtyMi1q9LFS0z+k6DSpYZ9bacGN3026Tf9EsRkdanjZahP/1p1q55z3uiZbWl1LParA/d3d3R2dkZXV1d0dHKl7gDqmOoza31tegDqF8Dl6PNuvy0vmg9g33nvu/yNdn0yzOHOrwcAAAAciJ0AwDAKacUXQHQpIRuAAA477yiKwCalNANAAAAORG6AQAAICdCNwAAAORE6AYAgMHsvXfRFQBNQOgGAGBoDXzf3TG7446iKwCagNANAEB5Tjut6AqAerX55kVXULcmFF0AAAB1rpX3dgPlWbGi6Arqlj3dAAAAkBOhGwAAaD2nnNL/fxfOIydCNwAA0HrOO6///y6cR06EbgAAAMiJ0A0AAAA5EboBAAAgJ0I3AAAA5EToBgAAgJwI3QAAAJAToRsAAAByInQDAABAToRuAAAAyMmEogsAAAAoREpFV0ALsKcbaG6nnFJ0BQAAzedlLyu6goYhdAPN7bzziq4AAKD53HJL0RU0DKEbAAAAciJ0AwAAQE6EbgAAAMiJ0A0AAAA5EboBAAAgJ0I30Hq23bboCgAAaBFCN9B6/va3oisAAKBFCN0AAACQE6EbAAAAciJ0AwAAQE6EbgAAACq3777Z35SKraPOTSi6AAAAABrQTTcVXUFDsKcbAAAAciJ0AwAAQE6EbgAAAMiJ0A0AAAA5EboBAAAgJ0I3AAAA5EToBgAAgJwI3QAAAJAToRsAAAByInQDAABAToRuAAAAyInQDQAAADkRugEAACAnQjcAAADkROgGAACAnOQWui+44ILYcccdY5NNNonZs2fHb3/727wGBQAAY3fKKUVXADShXEL39773vTj99NPj4x//ePz+97+PvffeOw488MB47LHH8hgcAACM3XnnFV0B0IRyCd2f//zn47jjjoujjz469thjj7joootis802i29+85t5DA4AAADqUtVD95o1a+K2226LuXPnlgYyblzMnTs3Fi5cuNH7V69eHd3d3f0eAAAA0AyqHrqfeOKJWL9+fUyfPr3f89OnT4+lS5du9P758+dHZ2dn72PWrFnVLgkAAAAKUfjVy88666zo6urqfTz88MNFlwQ0m3POKboCAABaVNVD99Zbbx3jx4+PZcuW9Xt+2bJlMWPGjI3e397eHh0dHf0eAFX10Y8WXQEAAC2q6qF70qRJsc8++8T111/f+9yGDRvi+uuvjzlz5lR7cAAAAFC3JuTR09NPPz2OOuqoeMlLXhIve9nL4rzzzouVK1fG0UcfncfgAMqXUtEVAADQQnIJ3e94xzvi8ccfj7PPPjuWLl0aL3rRi+Laa6/d6OJqADUjbAMAUIC2lOqrJdrd3R2dnZ3R1dXl/G4AAGqrra3UXV/NZCBHeebQwq9eDgAAdUfgBqokl8PLAQCgIQnbQJXZ0w0AAAA5EboBAAAgJ0I3AAAA5EToBgAAgJwI3QAAAJAToRsAAAByInQDAABAToRuAAAAyInQDQAAADkRugEAACAnQjcAAADkROgGAACAnAjdAAAAkBOhGwAAAHIidAMAAEBOhG4AAADIidANAAAAORG6AQAAICdCNwAAAORE6AYAAICcCN0AAACQE6EbAAAAciJ0AwAAQE6EbgAAAMjJhKILGCilFBER3d3dBVcCAABAK+jJnz15tJrqLnQvX748IiJmzZpVcCUAAAC0kuXLl0dnZ2dV+9mW8ojyY7Bhw4ZYsmRJbLHFFtHW1lZ0OcPq7u6OWbNmxcMPPxwdHR1Fl0MDMy9RTeYnqsn8RDWZn6gm8xPV0jMv3XvvvbHrrrvGuHHVPQu77vZ0jxs3Lrbbbruiy6hIR0eHHzpVYV6imsxPVJP5iWoyP1FN5ieq5TnPeU7VA3eEC6kBAABAboRuAAAAyInQPQbt7e3x8Y9/PNrb24suhQZnXqKazE9Uk/mJajI/UU3mJ6ol73mp7i6kBgAAAM3Cnm4AAADIidANAAAAORG6AQAAICdCNwAAAORE6AYAAICcCN2jdMEFF8SOO+4Ym2yyScyePTt++9vfFl0SDeATn/hEtLW19Xvstttuva+vWrUq5s2bF1tttVVMnjw5DjvssFi2bFmBFVNPbrzxxnjTm94U2267bbS1tcWPfvSjfq+nlOLss8+OmTNnxqabbhpz586NBx54oN97nnrqqTjiiCOio6MjpkyZEscee2ysWLGihmNBPRhpXnrPe96z0bLqoIMO6vce8xI95s+fHy996Utjiy22iG222Sbe/OY3x/3339/vPeWs3xYvXhxveMMbYrPNNottttkmzjzzzFi3bl0tR4U6UM789OpXv3qjZdTxxx/f7z3mJy688MLYa6+9oqOjIzo6OmLOnDlxzTXX9L5ey+WS0D0K3/ve9+L000+Pj3/84/H73/8+9t577zjwwAPjscceK7o0GsALXvCCePTRR3sfN910U+9rp512Wlx99dVxxRVXxIIFC2LJkiVx6KGHFlgt9WTlypWx9957xwUXXDDo65/+9Kfji1/8Ylx00UVxyy23xOabbx4HHnhgrFq1qvc9RxxxRNxzzz1x3XXXxU9+8pO48cYb433ve1+tRoE6MdK8FBFx0EEH9VtWffe73+33unmJHgsWLIh58+bFzTffHNddd12sXbs2Xv/618fKlSt73zPS+m39+vXxhje8IdasWRO/+c1v4tJLL41vfetbcfbZZxcxShSonPkpIuK4447rt4z69Kc/3fua+YmIiO222y7OPffcuO222+LWW2+N1772tXHIIYfEPffcExE1Xi4lKvayl70szZs3r/f/9evXp2233TbNnz+/wKpoBB//+MfT3nvvPehrTz/9dJo4cWK64oorep/74x//mCIiLVy4sEYV0igiIl155ZW9/2/YsCHNmDEjfeYzn+l97umnn07t7e3pu9/9bkoppXvvvTdFRPrd737X+55rrrkmtbW1pb/97W81q536MnBeSimlo446Kh1yyCFDfsa8xHAee+yxFBFpwYIFKaXy1m8//elP07hx49LSpUt733PhhRemjo6OtHr16tqOAHVl4PyUUkqvetWr0imnnDLkZ8xPDGXLLbdM3/jGN2q+XLKnu0Jr1qyJ2267LebOndv73Lhx42Lu3LmxcOHCAiujUTzwwAOx7bbbxnOf+9w44ogjYvHixRERcdttt8XatWv7zVu77bZbbL/99uYtRrRo0aJYunRpv/mns7MzZs+e3Tv/LFy4MKZMmRIveclLet8zd+7cGDduXNxyyy01r5n6dsMNN8Q222wTu+66a5xwwgnx5JNP9r5mXmI4XV1dERExderUiChv/bZw4cJ44QtfGNOnT+99z4EHHhjd3d29e6VoTQPnpx7f+c53Yuutt44999wzzjrrrHjmmWd6XzM/MdD69evj8ssvj5UrV8acOXNqvlyaUJ3RaB1PPPFErF+/vt/Ej4iYPn163HfffQVVRaOYPXt2fOtb34pdd901Hn300fjkJz8Z++23X9x9992xdOnSmDRpUkyZMqXfZ6ZPnx5Lly4tpmAaRs88Mtiyqee1pUuXxjbbbNPv9QkTJsTUqVPNY/Rz0EEHxaGHHho77bRTPPTQQ/GRj3wkDj744Fi4cGGMHz/evMSQNmzYEKeeemrsu+++seeee0ZElLV+W7p06aDLr57XaE2DzU8REe9617tihx12iG233Tb+8Ic/xIc+9KG4//7744c//GFEmJ8oueuuu2LOnDmxatWqmDx5clx55ZWxxx57xB133FHT5ZLQDTV08MEH93bvtddeMXv27Nhhhx3i+9//fmy66aYFVgZQ8s53vrO3+4UvfGHstdde8bznPS9uuOGGOOCAAwqsjHo3b968uPvuu/tdrwRGa6j5qe/1I174whfGzJkz44ADDoiHHnoonve859W6TOrYrrvuGnfccUd0dXXFD37wgzjqqKNiwYIFNa/D4eUV2nrrrWP8+PEbXdlu2bJlMWPGjIKqolFNmTIlnv/858eDDz4YM2bMiDVr1sTTTz/d7z3mLcrRM48Mt2yaMWPGRhd8XLduXTz11FPmMYb13Oc+N7beeut48MEHI8K8xOBOOumk+MlPfhK//OUvY7vttut9vpz124wZMwZdfvW8RusZan4azOzZsyMi+i2jzE9EREyaNCl23nnn2GeffWL+/Pmx9957x/nnn1/z5ZLQXaFJkybFPvvsE9dff33vcxs2bIjrr78+5syZU2BlNKIVK1bEQw89FDNnzox99tknJk6c2G/euv/++2Px4sXmLUa00047xYwZM/rNP93d3XHLLbf0zj9z5syJp59+Om677bbe9/ziF7+IDRs29DZYYDCPPPJIPPnkkzFz5syIMC/RX0opTjrppLjyyivjF7/4Rey00079Xi9n/TZnzpy46667+m3Mue6666KjoyP22GOP2owIdWGk+Wkwd9xxR0REv2WU+YnBbNiwIVavXl375VI1rgLXai6//PLU3t6evvWtb6V77703ve9970tTpkzpd2U7GMwHPvCBdMMNN6RFixalX//612nu3Llp6623To899lhKKaXjjz8+bb/99ukXv/hFuvXWW9OcOXPSnDlzCq6aerF8+fJ0++23p9tvvz1FRPr85z+fbr/99vTXv/41pZTSueeem6ZMmZKuuuqq9Ic//CEdcsghaaeddkrPPvtsbz8OOuig9OIXvzjdcsst6aabbkq77LJLOvzww4saJQoy3Ly0fPnydMYZZ6SFCxemRYsWpZ///Ofpn/7pn9Iuu+ySVq1a1dsP8xI9TjjhhNTZ2ZluuOGG9Oijj/Y+nnnmmd73jLR+W7duXdpzzz3T61//+nTHHXeka6+9Nk2bNi2dddZZRYwSBRppfnrwwQfTpz71qXTrrbemRYsWpauuuio997nPTfvvv39vP8xPpJTShz/84bRgwYK0aNGi9Ic//CF9+MMfTm1tbelnP/tZSqm2yyWhe5S+9KUvpe233z5NmjQpvexlL0s333xz0SXRAN7xjnekmTNnpkmTJqXnPOc56R3veEd68MEHe19/9tln04knnpi23HLLtNlmm6W3vOUt6dFHHy2wYurJL3/5yxQRGz2OOuqolFJ227B/+7d/S9OnT0/t7e3pgAMOSPfff3+/fjz55JPp8MMPT5MnT04dHR3p6KOPTsuXLy9gbCjScPPSM888k17/+tenadOmpYkTJ6YddtghHXfccRttWDYv0WOweSki0iWXXNL7nnLWb3/5y1/SwQcfnDbddNO09dZbpw984ANp7dq1NR4bijbS/LR48eK0//77p6lTp6b29va08847pzPPPDN1dXX164/5iWOOOSbtsMMOadKkSWnatGnpgAMO6A3cKdV2udSWUkqV7RsHAAAAyuGcbgAAAMiJ0A0AAAA5EboBAAAgJ0I3AAAA5EToBgAAgJwI3QAAAJAToRsAAAByInQDAABAToRuAAAAyInQDQAAADkRugEAACAn/z92CvwrmwDF8QAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"code","source":["pip install optuna"],"metadata":{"id":"4pc5g-QDW_nv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682533015359,"user_tz":240,"elapsed":9297,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"c5d9e57f-86ab-47aa-ea42-1d1cdc8e83db"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting optuna\n","  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorlog\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n","Collecting alembic>=1.5.0\n","  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (2.0.10)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.1)\n","Collecting cmaes>=0.9.1\n","  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n","Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.10.4 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n"]}]},{"cell_type":"code","source":["import optuna"],"metadata":{"id":"QWMNJzE-XDpj","executionInfo":{"status":"ok","timestamp":1682533015743,"user_tz":240,"elapsed":439,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import math\n","\n","##LSTM\n","import pandas as pd\n","import numpy as np\n","import math\n","\n","import sklearn\n","import keras\n","import keras.backend as K\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import LSTM, CuDNNLSTM, MaxPooling1D, Conv1D, Flatten, BatchNormalization, Dropout, Input\n","from keras.models import Model\n","from keras.layers import RepeatVector\n","from keras.layers import TimeDistributed\n","from keras.layers.convolutional import Conv1D, MaxPooling1D\n","from keras.optimizers import SGD\n","from keras.callbacks import EarlyStopping\n","\n","\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from math import sqrt\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from sklearn.preprocessing import MinMaxScaler\n","from multiprocessing import cpu_count \n","from joblib import Parallel \n","from joblib import delayed \n","from datetime import datetime\n","\n","#import optuna \n","\n","from sklearn.preprocessing import StandardScaler\n","\n","from keras.utils import custom_object_scope\n","from keras.utils import get_custom_objects\n","from keras.models import load_model\n","\n","from keras.layers import LSTM, RepeatVector, TimeDistributed, BatchNormalization, Dropout\n","from keras.initializers import GlorotUniform\n","from keras.activations import relu\n","from joblib import Parallel, delayed\n","\n","import cProfile\n","\n","import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, LSTM, Multiply, Add\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow_probability as tfp\n","from tensorflow.keras.layers import GRU\n","from tensorflow.keras.layers import MultiHeadAttention\n","from tensorflow.keras.optimizers import SGD"],"metadata":{"id":"V-OO_rI08Oe0","executionInfo":{"status":"ok","timestamp":1682535566708,"user_tz":240,"elapsed":2,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["df_vwc = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_vwc_.npy', allow_pickle=True)\n","df_stemp = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_stemp_.npy', allow_pickle=True)\n","\n","df_vwc7 = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd7_vwc.npy', allow_pickle=True)\n","df_stemp7 = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd7_stemp.npy', allow_pickle=True)\n","\n","df_vwc11 = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd11_vwc.npy', allow_pickle=True)\n","df_stemp11 = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd11_stemp.npy', allow_pickle=True)\n","\n","df_T = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_T.npy', allow_pickle=True)\n","df_RH = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_RH.npy', allow_pickle=True)\n","#df_DP = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_DP.npy', allow_pickle=True)\n","df_Rain = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_Rain.npy', allow_pickle=True)\n","df_WS = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_WS.npy', allow_pickle=True)\n","#df_WD = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_WD.npy', allow_pickle=True)\n","df_S = np.load('/content/drive/Shareddrives/1st Paper/Array_eemd2_S.npy', allow_pickle=True)\n","\n","#Scores_IMF = []\n","dataset = pd.read_csv('/content/drive/Shareddrives/1st Paper/2nd.csv', header = 0, infer_datetime_format=True, index_col=['Date Time'])\n","df = dataset[[\n","       'S2_Top_Temp_Avg', 'S2_Top_VWC_Avg'\n","       \n","       ]]\n","#'Temp', 'Relative Humidity', 'Dew Point', 'Rain', 'Wind Speed', 'Wind Direction', 'Solar Radiation',"],"metadata":{"id":"MmX_-RME8sxg","executionInfo":{"status":"ok","timestamp":1682533965910,"user_tz":240,"elapsed":8975,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","def split_dataset(data):\n","  # split into standard weeks\n","  train, test = data[0:288], data[288:576]\n","  #train, test = data[:-5817], data[-5817:-57] 6048\n","  # restructure into windows of weekly data\n","  train = np.array(np.split(train, len(train)/144))\n","  test = np.array(np.split( test , len(test )/144))\n","  return train, test\n","\n","def to_supervised(train, n_input):\n","    # Flatten data\n","    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n","    X, y = list(), list()\n","    in_start = 0\n","    # Step over the entire history one time step at a time\n","    for _ in range(len(data)):\n","        # Define the end of the input sequence\n","        in_end = in_start + n_input\n","        out_end = in_end + 1\n","        # Ensure we have enough data for this instance\n","        if out_end < len(data):\n","            X.append(data[in_start:in_end, :])\n","            y.append(data[in_end, 0])  # Modify this line to only include the first future time step\n","        # Move along one time step\n","        in_start += 1\n","    return np.array(X), np.array(y)\n","\n","def build_moe_model_with_autoencoder_cnn_attention(input_dim, output_dim, expert_hidden_sizes, expert_output_sizes,\n","                                     gating_hidden_sizes, num_experts, learning_rate, activation, kernel_initializer, dropout_rate,\n","                                     num_iterations=100):\n","    \n","    experts = []\n","    for i in range(num_experts):\n","        if i == 0:  # Replace first expert with an autoencoder\n","            expert_input = Input(shape=(input_dim))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation=activation, kernel_initializer=kernel_initializer)(expert_input)\n","            expert_hidden = Dropout(dropout_rate)(expert_hidden)\n","            expert_hidden = tf.expand_dims(expert_hidden, axis=1)  # Expand dimensions for LSTM input\n","            expert_hidden, _, _ = LSTM(expert_hidden_sizes[i], return_state=True, kernel_initializer='he_normal')(expert_hidden)\n","            attention = Dense(expert_hidden_sizes[i], activation='tanh', kernel_initializer='he_normal')(expert_hidden)\n","            attention = Dense(1, activation='softmax', kernel_initializer='he_normal')(attention)\n","            expert_hidden = Multiply()([expert_hidden, attention])\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=expert_output))\n","        elif i == 1:  # Replace second expert with a Transformer expert\n","            expert_input = Input(shape=(input_dim))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation=activation, kernel_initializer=kernel_initializer)(expert_input)\n","            expert_hidden = Dropout(dropout_rate)(expert_hidden)\n","            expert_hidden = tf.expand_dims(expert_hidden, axis=1)  # Expand dimensions for Transformer input\n","            expert_hidden = MultiHeadAttention(num_heads=8, key_dim=expert_hidden_sizes[i])(expert_hidden, expert_hidden)\n","            expert_hidden = Flatten()(expert_hidden)\n","            attention = Dense(expert_hidden_sizes[i], activation='tanh', kernel_initializer='he_normal')(expert_hidden)\n","            attention = Dense(1, activation='softmax', kernel_initializer='he_normal')(attention)\n","            expert_hidden = Multiply()([expert_hidden, attention])\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=expert_output))\n","        else:  # Replace third expert with a GRU-based model\n","            expert_input = Input(shape=(input_dim))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation=activation, kernel_initializer=kernel_initializer)(expert_input)\n","            expert_hidden = Dropout(dropout_rate)(expert_hidden)\n","            expert_hidden = tf.expand_dims(expert_hidden, axis=1)  # Expand dimensions for GRU input\n","            expert_hidden, _ = GRU(expert_hidden_sizes[i], return_state=True, kernel_initializer='he_normal')(expert_hidden)\n","            attention = Dense(expert_hidden_sizes[i], activation='tanh', kernel_initializer='he_normal')(expert_hidden)\n","            attention = Dense(1, activation='softmax', kernel_initializer='he_normal')(attention)\n","            expert_hidden = Multiply()([expert_hidden, attention])\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=expert_output))\n","\n","    # Define the gating network\n","    gating_input = Input(shape=(input_dim,))\n","    gating_hidden = gating_input\n","    for i in range(len(gating_hidden_sizes)):\n","        gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","    gating_output = Dense(num_experts + num_experts * 2, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","    logits = gating_output[:, :num_experts]\n","    params = gating_output[:, num_experts:]\n","    params = tf.reshape(params, [-1, num_experts, 2])\n","\n","    gating_distribution = tfp.distributions.MixtureSameFamily(\n","        mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","        components_distribution=tfp.distributions.Normal(\n","            loc=params[..., 0],\n","            scale=tf.math.softplus(params[..., 1])\n","        )\n","    )\n","\n","    gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","    # Define the MoE model\n","    inputs = Input(shape=(input_dim,))\n","    outputs = []\n","    for i in range(num_experts):\n","        expert_output = experts[i](inputs)\n","        if i == 0:  # For the autoencoder expert, append encoded representation to outputs list\n","            outputs.append(expert_output)\n","        else:\n","            outputs.append(experts[i](inputs))\n","\n","    gating_output = gating_model(inputs)\n","    weighted_outputs = [tf.expand_dims(gating_output[:, i], axis=-1) * expert_output[:, :1] for i, expert_output in enumerate(outputs)]\n","\n","    outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","    moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","    return moe_model, experts, gating_model\n","\n","# Define the loss function\n","def moe_loss(y_true, y_pred, gating_output):\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","    expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","    \n","    # Apply softmax to the logits to get probabilities\n","    gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","    \n","    # Multiply expert_losses with the gating probabilities instead of logits\n","    gating_losses = tf.reduce_sum(tf.multiply(expert_losses, gating_probabilities), axis=-1)\n","    return tf.reduce_mean(gating_losses)\n","\n","def scheduler(epoch, lr):\n","    if epoch < 10:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","def sliding_window_split(data, window_size, step_size):\n","    windowed_data = []\n","    for i in range(0, len(data) - window_size, step_size):\n","        windowed_data.append(data[i:i + window_size])\n","    return windowed_data\n"],"metadata":{"id":"b2fgRc1m72v3","executionInfo":{"status":"ok","timestamp":1682534215615,"user_tz":240,"elapsed":289,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def objective(trial, train_input, train_output, input_dim, output_dim):\n","    # Define the hyperparameters to optimize using Optuna\n","    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n","    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n","    activation = trial.suggest_categorical('activation', ['relu', 'sigmoid', 'tanh'])\n","    kernel_initializer = trial.suggest_categorical('kernel_initializer', ['glorot_normal', 'he_normal', None])\n","\n","    window_size = 500\n","    step_size = 50\n","\n","    # Define the sizes of the hidden layers for each expert\n","    expert_hidden_sizes = [16, 32, 64]\n","\n","    # Define the sizes of the output layers for each expert\n","    expert_output_sizes = [144,144,144]\n","\n","    # Define the sizes of the gating network hidden layers\n","    gating_hidden_sizes = [16, 8]\n","\n","    # Define the size of the output layer of the gating network\n","    gating_output_size = num_experts\n","\n","    # Define the number of training iterations for the EM algorithm\n","    num_iterations = 10\n","\n","    # Load the training data\n","    train_data = np.array(df.head(10000))\n","\n","\n","    # Split the training data into input and output sequences\n","    train_input = train_data[:, :]\n","    print('train_input shape', train_input.shape)\n","    train_output = train_data[:, -1:]\n","    print('train_output shape', train_output.shape)\n","\n","\n","    # Normalize input data\n","    train_input = (train_input - np.mean(train_input, axis=0)) / np.std(train_input, axis=0)\n","\n","\n","    train_input_windows = sliding_window_split(train_input, window_size, step_size)\n","    train_output_windows = sliding_window_split(train_output, window_size, step_size)\n","\n","    # Build and train the model using the hyperparameters\n","    moe_model, experts, gating_model = build_moe_model_with_autoencoder_cnn_attention(\n","        input_dim,\n","        output_dim,\n","        expert_hidden_sizes,\n","        expert_output_sizes,\n","        gating_hidden_sizes,\n","        num_experts,\n","        learning_rate,\n","        activation,\n","        kernel_initializer,\n","        dropout_rate)\n","\n","    # Define the optimization algorithm\n","    optimizer = Adam(learning_rate=learning_rate)\n","\n","    # Learning rate scheduler\n","    lr_scheduler = LearningRateScheduler(scheduler)\n","\n","    # Train the MoE model with the EM algorithm\n","    iteration = 0\n","    while iteration < num_iterations:\n","        num_train_windows = int(0.8 * len(train_input_windows))\n","        for window_idx in range(len(train_input_windows)):\n","\n","          # E step: Compute the responsibilities of each expert for each data point\n","          gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","          gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","          # M step: Update the parameters of each expert and the gating network\n","          for i in range(num_experts):\n","              expert_input = train_input\n","              expert_output = experts[i](expert_input)\n","              expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","              with tf.GradientTape() as tape:\n","                  # Watch the trainable variables of the expert model\n","                  tape.watch(experts[i].trainable_variables)\n","\n","                  # Define the expert model and calculate the expert_loss\n","                  expert_output = experts[i](expert_input)\n","                  expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","              # Compute the gradients\n","              expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","              # Clip gradients for expert models\n","              expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","              # Update the variables\n","              optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","          \n","          current_learning_rate = scheduler(iteration, optimizer.learning_rate.numpy())\n","          optimizer.learning_rate.assign(current_learning_rate)\n","\n","          gating_input = train_input\n","\n","          with tf.GradientTape() as tape:\n","              # Watch the trainable variables of the gating model\n","              tape.watch(gating_model.trainable_variables)\n","\n","              # Define the gating model and calculate the gating_loss\n","              gating_output = gating_model(gating_input)\n","              gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(train_input), gating_output)\n","\n","\n","          # Compute the gradients\n","          gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","          # Clip gradients for the gating model\n","          gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","\n","          # Update the variables\n","          optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","          # Evaluate the performance of the MoE model on the training set\n","          if window_idx < num_train_windows:\n","            train_loss = moe_loss(train_output_windows[window_idx], moe_model.predict(train_input_windows[window_idx]), gating_model.predict(train_input_windows[window_idx]))\n","            print(f'Iteration {iteration + 1}, Training window {window_idx + 1}: Training loss = {train_loss:.6f}')\n","          else:\n","            val_loss = moe_loss(train_output_windows[window_idx], moe_model.predict(train_input_windows[window_idx]), gating_model.predict(train_input_windows[window_idx]))\n","            print(f'Iteration {iteration + 1}, Validation window {window_idx - num_train_windows + 1}: Validation loss = {val_loss:.6f}')\n","\n","        # Stop training if the learning rate becomes too small\n","        if current_learning_rate < 1e-6:\n","            print('Learning rate dropped below 1e-6 after iteration %d' % iteration)\n","            break\n","\n","        iteration += 1\n","\n","    return train_loss\n"],"metadata":{"id":"Uewuo6RuKpVM","executionInfo":{"status":"ok","timestamp":1682533036082,"user_tz":240,"elapsed":1383,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from functools import partial\n","\n","# Load the training data\n","train_data = np.array(df.head(10000))\n","\n","\n","# Split the training data into input and output sequences\n","train_input = train_data[:, :]\n","print('train_input shape', train_input.shape)\n","train_output = train_data[:, -1:]\n","print('train_output shape', train_output.shape)\n","\n","\n","# Normalize input data\n","train_input = (train_input - np.mean(train_input, axis=0)) / np.std(train_input, axis=0)\n","\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 3\n","objective_with_args = partial(objective, train_input=train_input, train_output=train_output, input_dim=input_dim, output_dim=output_dim)\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective_with_args, n_trials=5)  # You can change the number of trials as needed\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ogUWir9Jlg9f","outputId":"81a0f4f4-a2a2-4021-e01a-96642a048da6","executionInfo":{"status":"ok","timestamp":1682526206908,"user_tz":240,"elapsed":4987973,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-04-26 12:25:56,383]\u001b[0m A new study created in memory with name: no-name-5709e10e-e849-4658-8289-cc1c5c5a25f0\u001b[0m\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train_input shape (10000, 2)\n","train_output shape (10000, 1)\n","train_input shape (10000, 2)\n","train_output shape (10000, 1)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-9-85972daf6b4c>:3: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n","<ipython-input-9-85972daf6b4c>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Iteration 4, Training window 80: Training loss = 0.051439\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 4, Training window 81: Training loss = 0.057837\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 82: Training loss = 0.075850\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 83: Training loss = 0.071962\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 84: Training loss = 0.075333\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 85: Training loss = 0.076679\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 86: Training loss = 0.078238\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 87: Training loss = 0.065697\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 88: Training loss = 0.063279\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 89: Training loss = 0.061837\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 90: Training loss = 0.071728\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 91: Training loss = 0.066542\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 4, Training window 92: Training loss = 0.064811\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 93: Training loss = 0.070109\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 94: Training loss = 0.065830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 95: Training loss = 0.073197\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 96: Training loss = 0.083323\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 97: Training loss = 0.082587\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 98: Training loss = 0.085442\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 99: Training loss = 0.085042\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 100: Training loss = 0.079165\n","313/313 [==============================] - 0s 1ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 101: Training loss = 0.088956\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 102: Training loss = 0.077270\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 103: Training loss = 0.072112\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 104: Training loss = 0.084233\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 105: Training loss = 0.061720\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 106: Training loss = 0.038523\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 107: Training loss = 0.037754\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 108: Training loss = 0.049749\n","313/313 [==============================] - 0s 1ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 109: Training loss = 0.040246\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 110: Training loss = 0.031042\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 111: Training loss = 0.028467\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 112: Training loss = 0.029712\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 113: Training loss = 0.042663\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 114: Training loss = 0.042662\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 115: Training loss = 0.043817\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 116: Training loss = 0.047607\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 117: Training loss = 0.047110\n","313/313 [==============================] - 0s 1ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 118: Training loss = 0.044876\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 119: Training loss = 0.041899\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 120: Training loss = 0.038338\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 121: Training loss = 0.033663\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 122: Training loss = 0.031441\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 123: Training loss = 0.019032\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 124: Training loss = 0.019710\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 125: Training loss = 0.018717\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 126: Training loss = 0.016410\n","313/313 [==============================] - 0s 1ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 127: Training loss = 0.023400\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 128: Training loss = 0.031738\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 129: Training loss = 0.036557\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 130: Training loss = 0.040138\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 131: Training loss = 0.045596\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 132: Training loss = 0.049606\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 133: Training loss = 0.053837\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 134: Training loss = 0.053492\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 135: Training loss = 0.081172\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 136: Training loss = 0.136887\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 137: Training loss = 0.130641\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 138: Training loss = 0.144745\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 139: Training loss = 0.126738\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 140: Training loss = 0.127124\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 141: Training loss = 0.115150\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 142: Training loss = 0.129595\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 143: Training loss = 0.110086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 144: Training loss = 0.123372\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 145: Training loss = 0.070715\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 146: Training loss = 0.034804\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 147: Training loss = 0.037508\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 148: Training loss = 0.046262\n","313/313 [==============================] - 0s 1ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 149: Training loss = 0.036003\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 150: Training loss = 0.029236\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 151: Training loss = 0.030049\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 152: Training loss = 0.040189\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 1: Validation loss = 0.031719\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 2: Validation loss = 0.027405\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 3: Validation loss = 0.023840\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 4: Validation loss = 0.024202\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 5: Validation loss = 0.016041\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 6: Validation loss = 0.024020\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 7: Validation loss = 0.025661\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 8: Validation loss = 0.017260\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 9: Validation loss = 0.016952\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 10: Validation loss = 0.030543\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 11: Validation loss = 0.025826\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 12: Validation loss = 0.020030\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 13: Validation loss = 0.023081\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 14: Validation loss = 0.032130\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 15: Validation loss = 0.028268\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 16: Validation loss = 0.023888\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 17: Validation loss = 0.022832\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 18: Validation loss = 0.024225\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 19: Validation loss = 0.022882\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 20: Validation loss = 0.020224\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 21: Validation loss = 0.019820\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 22: Validation loss = 0.016198\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 23: Validation loss = 0.012175\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 24: Validation loss = 0.014291\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 25: Validation loss = 0.012518\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 26: Validation loss = 0.007958\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 27: Validation loss = 0.007183\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 28: Validation loss = 0.013886\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 29: Validation loss = 0.014252\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 30: Validation loss = 0.007345\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 31: Validation loss = 0.008838\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 32: Validation loss = 0.019314\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 33: Validation loss = 0.020636\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 34: Validation loss = 0.019102\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 35: Validation loss = 0.024086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 36: Validation loss = 0.034360\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 37: Validation loss = 0.032849\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 38: Validation loss = 0.037084\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 1: Training loss = 0.045322\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 2: Training loss = 0.054853\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 3: Training loss = 0.057470\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 4: Training loss = 0.073172\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 5: Training loss = 0.066773\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 6: Training loss = 0.061787\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 7: Training loss = 0.061352\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 8: Training loss = 0.070541\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 9: Training loss = 0.061675\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 10: Training loss = 0.055517\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 11: Training loss = 0.048958\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 12: Training loss = 0.041700\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 13: Training loss = 0.038977\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 14: Training loss = 0.039024\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 15: Training loss = 0.057331\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 16: Training loss = 0.055119\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 17: Training loss = 0.049609\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 18: Training loss = 0.055715\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 19: Training loss = 0.042772\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 20: Training loss = 0.043590\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 21: Training loss = 0.047880\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 22: Training loss = 0.062923\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 23: Training loss = 0.057168\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 24: Training loss = 0.063378\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 25: Training loss = 0.064954\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 26: Training loss = 0.060234\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 27: Training loss = 0.059552\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 28: Training loss = 0.070687\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 29: Training loss = 0.071123\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 30: Training loss = 0.064043\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 31: Training loss = 0.062607\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 32: Training loss = 0.073516\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 33: Training loss = 0.057998\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 34: Training loss = 0.040992\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 35: Training loss = 0.031879\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 36: Training loss = 0.038707\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 37: Training loss = 0.036251\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 38: Training loss = 0.037458\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 39: Training loss = 0.033009\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 40: Training loss = 0.034899\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 41: Training loss = 0.034026\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 42: Training loss = 0.037688\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 43: Training loss = 0.032639\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 44: Training loss = 0.035720\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 45: Training loss = 0.026897\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 46: Training loss = 0.024148\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 47: Training loss = 0.021347\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 48: Training loss = 0.024496\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 49: Training loss = 0.016635\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 50: Training loss = 0.013120\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 51: Training loss = 0.008624\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 52: Training loss = 0.012621\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 53: Training loss = 0.005077\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 54: Training loss = 0.004095\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 55: Training loss = 0.001329\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 56: Training loss = 0.004437\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 57: Training loss = 0.000994\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 58: Training loss = 0.004317\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 59: Training loss = 0.000841\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 60: Training loss = 0.003656\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 61: Training loss = 0.001440\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 62: Training loss = 0.008249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 63: Training loss = 0.008354\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 64: Training loss = 0.013001\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 65: Training loss = 0.013311\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 66: Training loss = 0.016037\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 67: Training loss = 0.014503\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 68: Training loss = 0.015925\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 69: Training loss = 0.015026\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 70: Training loss = 0.016370\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 71: Training loss = 0.015096\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 72: Training loss = 0.012448\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 73: Training loss = 0.008063\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 74: Training loss = 0.011086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 75: Training loss = 0.009713\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 76: Training loss = 0.019530\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 77: Training loss = 0.022402\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 78: Training loss = 0.030941\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 79: Training loss = 0.029785\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 80: Training loss = 0.033711\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 81: Training loss = 0.038843\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 82: Training loss = 0.048266\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 83: Training loss = 0.049830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 84: Training loss = 0.056686\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 85: Training loss = 0.052236\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 86: Training loss = 0.047503\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 87: Training loss = 0.043524\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 88: Training loss = 0.043176\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 89: Training loss = 0.039517\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 90: Training loss = 0.043493\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 91: Training loss = 0.041085\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 92: Training loss = 0.031641\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 93: Training loss = 0.030798\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 94: Training loss = 0.033719\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 95: Training loss = 0.031193\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 96: Training loss = 0.027813\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 97: Training loss = 0.027872\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 98: Training loss = 0.032748\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 99: Training loss = 0.029868\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 100: Training loss = 0.026118\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 101: Training loss = 0.030443\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 102: Training loss = 0.045661\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 103: Training loss = 0.034942\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 104: Training loss = 0.023004\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 105: Training loss = 0.023345\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 106: Training loss = 0.037468\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 107: Training loss = 0.028017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 108: Training loss = 0.016267\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 109: Training loss = 0.020750\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 110: Training loss = 0.037662\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 111: Training loss = 0.014429\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 112: Training loss = 0.013621\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 113: Training loss = 0.015897\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 114: Training loss = 0.018211\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 115: Training loss = 0.018514\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 116: Training loss = 0.018531\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 117: Training loss = 0.019074\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 118: Training loss = 0.020731\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 119: Training loss = 0.018341\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 120: Training loss = 0.015510\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 121: Training loss = 0.014140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 122: Training loss = 0.014010\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 123: Training loss = 0.011081\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 124: Training loss = 0.009162\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 125: Training loss = 0.008697\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 126: Training loss = 0.009353\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 127: Training loss = 0.010588\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 128: Training loss = 0.011878\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 129: Training loss = 0.013740\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 130: Training loss = 0.016663\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 131: Training loss = 0.018726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 132: Training loss = 0.020102\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 133: Training loss = 0.020837\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 134: Training loss = 0.021651\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 135: Training loss = 0.051702\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 136: Training loss = 0.068367\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 137: Training loss = 0.062885\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 138: Training loss = 0.073982\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 139: Training loss = 0.062878\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 140: Training loss = 0.065683\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 141: Training loss = 0.056022\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 142: Training loss = 0.067110\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 143: Training loss = 0.057197\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 144: Training loss = 0.063359\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 145: Training loss = 0.042082\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 146: Training loss = 0.026307\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 147: Training loss = 0.020783\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 148: Training loss = 0.019221\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 149: Training loss = 0.018798\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 150: Training loss = 0.022195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 151: Training loss = 0.018488\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 152: Training loss = 0.017136\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 1: Validation loss = 0.016153\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 2: Validation loss = 0.015904\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 3: Validation loss = 0.009888\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 4: Validation loss = 0.008828\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 5: Validation loss = 0.006060\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 6: Validation loss = 0.008412\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 7: Validation loss = 0.006899\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 8: Validation loss = 0.006070\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 9: Validation loss = 0.005095\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 10: Validation loss = 0.008831\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 11: Validation loss = 0.006569\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 12: Validation loss = 0.009766\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 13: Validation loss = 0.011556\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 14: Validation loss = 0.013162\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 15: Validation loss = 0.011408\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 16: Validation loss = 0.013637\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 17: Validation loss = 0.013811\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 18: Validation loss = 0.013580\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 19: Validation loss = 0.013455\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 20: Validation loss = 0.015675\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 21: Validation loss = 0.015734\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 22: Validation loss = 0.010926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 23: Validation loss = 0.008215\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Validation window 24: Validation loss = 0.009786\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 25: Validation loss = 0.009156\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 26: Validation loss = 0.008272\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 27: Validation loss = 0.007435\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 28: Validation loss = 0.005764\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 29: Validation loss = 0.005307\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 30: Validation loss = 0.009201\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 31: Validation loss = 0.008616\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 32: Validation loss = 0.005981\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 33: Validation loss = 0.007385\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 34: Validation loss = 0.015324\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 35: Validation loss = 0.020410\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 36: Validation loss = 0.029798\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 37: Validation loss = 0.024602\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 38: Validation loss = 0.020915\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 1: Training loss = 0.027346\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 2: Training loss = 0.036936\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 3: Training loss = 0.040288\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 4: Training loss = 0.042262\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 5: Training loss = 0.040820\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 6: Training loss = 0.043710\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 7: Training loss = 0.039587\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 8: Training loss = 0.038687\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 9: Training loss = 0.039175\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 10: Training loss = 0.039070\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 11: Training loss = 0.035197\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 12: Training loss = 0.027807\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 13: Training loss = 0.025104\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 14: Training loss = 0.029473\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 15: Training loss = 0.036287\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 16: Training loss = 0.040426\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 17: Training loss = 0.035860\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 18: Training loss = 0.036619\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 19: Training loss = 0.028470\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 20: Training loss = 0.034146\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 21: Training loss = 0.035869\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 22: Training loss = 0.046410\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 23: Training loss = 0.043026\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 24: Training loss = 0.053425\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 25: Training loss = 0.056204\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 26: Training loss = 0.061054\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 27: Training loss = 0.057561\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 28: Training loss = 0.054719\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 29: Training loss = 0.058938\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 30: Training loss = 0.068060\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 31: Training loss = 0.058077\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 32: Training loss = 0.050362\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 33: Training loss = 0.045543\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 34: Training loss = 0.045261\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 35: Training loss = 0.019150\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 36: Training loss = 0.022336\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 37: Training loss = 0.021012\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 38: Training loss = 0.028014\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 39: Training loss = 0.020503\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 40: Training loss = 0.023088\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 41: Training loss = 0.021856\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 42: Training loss = 0.018622\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 43: Training loss = 0.018892\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 44: Training loss = 0.024932\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 45: Training loss = 0.020615\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 46: Training loss = 0.021311\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 47: Training loss = 0.016813\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 48: Training loss = 0.018396\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 49: Training loss = 0.013836\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 50: Training loss = 0.013467\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 51: Training loss = 0.008525\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 52: Training loss = 0.008663\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 53: Training loss = 0.004763\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 54: Training loss = 0.002615\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 55: Training loss = 0.000852\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 56: Training loss = 0.003360\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 57: Training loss = 0.001037\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 58: Training loss = 0.002799\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 59: Training loss = 0.000685\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 60: Training loss = 0.003128\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 61: Training loss = 0.000945\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 62: Training loss = 0.006156\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 63: Training loss = 0.005973\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 64: Training loss = 0.010034\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 65: Training loss = 0.010085\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 66: Training loss = 0.010662\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 67: Training loss = 0.009455\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 68: Training loss = 0.010888\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 69: Training loss = 0.010604\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 70: Training loss = 0.012140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 71: Training loss = 0.010055\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 72: Training loss = 0.009399\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 73: Training loss = 0.005259\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 74: Training loss = 0.007026\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 75: Training loss = 0.006952\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 76: Training loss = 0.015661\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 77: Training loss = 0.020218\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 78: Training loss = 0.028729\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 79: Training loss = 0.027324\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 80: Training loss = 0.029974\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 81: Training loss = 0.034795\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 82: Training loss = 0.046292\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 83: Training loss = 0.045228\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 84: Training loss = 0.046639\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 85: Training loss = 0.045349\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 86: Training loss = 0.045341\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 87: Training loss = 0.036866\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 88: Training loss = 0.034396\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 89: Training loss = 0.032296\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 90: Training loss = 0.035273\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 91: Training loss = 0.032302\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 92: Training loss = 0.031835\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 93: Training loss = 0.027486\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 94: Training loss = 0.020347\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 95: Training loss = 0.020140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 96: Training loss = 0.022535\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 97: Training loss = 0.019558\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 98: Training loss = 0.017011\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 99: Training loss = 0.018283\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 100: Training loss = 0.015736\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 101: Training loss = 0.027257\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 102: Training loss = 0.018296\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 103: Training loss = 0.021215\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 104: Training loss = 0.032930\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 105: Training loss = 0.024134\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 106: Training loss = 0.014963\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 107: Training loss = 0.018421\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 108: Training loss = 0.030297\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 109: Training loss = 0.023195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 110: Training loss = 0.015088\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 111: Training loss = 0.008997\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 112: Training loss = 0.010448\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 113: Training loss = 0.010445\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 114: Training loss = 0.010208\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 115: Training loss = 0.011956\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 116: Training loss = 0.015770\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 117: Training loss = 0.015993\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 118: Training loss = 0.014724\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 119: Training loss = 0.014880\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 120: Training loss = 0.015407\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 121: Training loss = 0.013727\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 122: Training loss = 0.011435\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 123: Training loss = 0.011361\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 124: Training loss = 0.012017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 125: Training loss = 0.009251\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 126: Training loss = 0.006130\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 127: Training loss = 0.006159\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 128: Training loss = 0.007192\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 129: Training loss = 0.007224\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 130: Training loss = 0.007802\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 131: Training loss = 0.008103\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 132: Training loss = 0.009063\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 133: Training loss = 0.009830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 134: Training loss = 0.010349\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 135: Training loss = 0.015709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 136: Training loss = 0.036167\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 137: Training loss = 0.031565\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 138: Training loss = 0.035074\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 139: Training loss = 0.028944\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 140: Training loss = 0.036914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 141: Training loss = 0.028723\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 142: Training loss = 0.031761\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 143: Training loss = 0.026821\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 144: Training loss = 0.039917\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 145: Training loss = 0.024008\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 146: Training loss = 0.015097\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 147: Training loss = 0.011426\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 148: Training loss = 0.013899\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 149: Training loss = 0.011796\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 150: Training loss = 0.010974\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 151: Training loss = 0.010271\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 152: Training loss = 0.013260\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 1: Validation loss = 0.009470\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 2: Validation loss = 0.007279\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 3: Validation loss = 0.004808\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 4: Validation loss = 0.004426\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 5: Validation loss = 0.002986\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 6: Validation loss = 0.006127\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 7: Validation loss = 0.004760\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 8: Validation loss = 0.004278\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 9: Validation loss = 0.002880\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 10: Validation loss = 0.008161\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 11: Validation loss = 0.005856\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 12: Validation loss = 0.007368\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 13: Validation loss = 0.008176\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 14: Validation loss = 0.013206\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 15: Validation loss = 0.010516\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 16: Validation loss = 0.008671\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 17: Validation loss = 0.007737\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 18: Validation loss = 0.010679\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 19: Validation loss = 0.010266\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 20: Validation loss = 0.009693\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 21: Validation loss = 0.009434\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 22: Validation loss = 0.007020\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 23: Validation loss = 0.004746\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 24: Validation loss = 0.005223\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 25: Validation loss = 0.004691\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 26: Validation loss = 0.004262\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 27: Validation loss = 0.003727\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 28: Validation loss = 0.005210\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 29: Validation loss = 0.003510\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 30: Validation loss = 0.001993\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 31: Validation loss = 0.002058\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 32: Validation loss = 0.005616\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 33: Validation loss = 0.006812\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 34: Validation loss = 0.014177\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 35: Validation loss = 0.016443\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 36: Validation loss = 0.020126\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 37: Validation loss = 0.020190\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 38: Validation loss = 0.024164\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 1: Training loss = 0.023535\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 2: Training loss = 0.024618\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 3: Training loss = 0.029221\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 4: Training loss = 0.035327\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 5: Training loss = 0.031083\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 6: Training loss = 0.030307\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 7: Training loss = 0.029011\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 8: Training loss = 0.031675\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 9: Training loss = 0.030559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 10: Training loss = 0.030099\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 11: Training loss = 0.025203\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 12: Training loss = 0.022497\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 13: Training loss = 0.018218\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 14: Training loss = 0.019426\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 15: Training loss = 0.022309\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 16: Training loss = 0.024866\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 17: Training loss = 0.020762\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 18: Training loss = 0.021122\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 19: Training loss = 0.015532\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 20: Training loss = 0.019660\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 21: Training loss = 0.020880\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 22: Training loss = 0.026189\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 23: Training loss = 0.027427\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 24: Training loss = 0.032515\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 25: Training loss = 0.038120\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 26: Training loss = 0.035923\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 27: Training loss = 0.034728\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 28: Training loss = 0.038202\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 29: Training loss = 0.039629\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 30: Training loss = 0.037974\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 31: Training loss = 0.033764\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 32: Training loss = 0.036618\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 33: Training loss = 0.027572\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 34: Training loss = 0.017962\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 35: Training loss = 0.008484\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 36: Training loss = 0.015945\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 37: Training loss = 0.013046\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 38: Training loss = 0.011534\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 39: Training loss = 0.011090\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 40: Training loss = 0.016694\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 41: Training loss = 0.015695\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 42: Training loss = 0.017084\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 43: Training loss = 0.015944\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 44: Training loss = 0.020473\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 45: Training loss = 0.017047\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 46: Training loss = 0.015730\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 47: Training loss = 0.014027\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 48: Training loss = 0.014679\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 49: Training loss = 0.010096\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 50: Training loss = 0.008050\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 51: Training loss = 0.004407\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 52: Training loss = 0.006654\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 53: Training loss = 0.002511\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 54: Training loss = 0.001442\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 55: Training loss = 0.000173\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 56: Training loss = 0.002354\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 57: Training loss = 0.000364\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 58: Training loss = 0.001632\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 59: Training loss = 0.000100\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 60: Training loss = 0.002923\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 61: Training loss = 0.000516\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 62: Training loss = 0.003832\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 63: Training loss = 0.004466\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 64: Training loss = 0.007452\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 65: Training loss = 0.006631\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 66: Training loss = 0.008230\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 67: Training loss = 0.007161\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 68: Training loss = 0.007711\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 69: Training loss = 0.007095\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 70: Training loss = 0.008516\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 71: Training loss = 0.007578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 72: Training loss = 0.006215\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 73: Training loss = 0.003207\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 74: Training loss = 0.004577\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 75: Training loss = 0.004805\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 76: Training loss = 0.014091\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 77: Training loss = 0.015301\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 78: Training loss = 0.018227\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 79: Training loss = 0.018791\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 80: Training loss = 0.022869\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 81: Training loss = 0.025429\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 82: Training loss = 0.028393\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 83: Training loss = 0.030641\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 84: Training loss = 0.039515\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 85: Training loss = 0.037019\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 86: Training loss = 0.030968\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 87: Training loss = 0.028726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 88: Training loss = 0.029625\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 89: Training loss = 0.026041\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 90: Training loss = 0.027520\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 91: Training loss = 0.025599\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 92: Training loss = 0.023604\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 93: Training loss = 0.020710\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 94: Training loss = 0.017278\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 95: Training loss = 0.013775\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 96: Training loss = 0.010703\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 97: Training loss = 0.010990\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 98: Training loss = 0.014599\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 99: Training loss = 0.012543\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 100: Training loss = 0.009079\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 101: Training loss = 0.011690\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 102: Training loss = 0.018844\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 103: Training loss = 0.013688\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 104: Training loss = 0.008708\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 105: Training loss = 0.009867\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 106: Training loss = 0.017874\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 107: Training loss = 0.013284\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 108: Training loss = 0.008555\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 109: Training loss = 0.010364\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 110: Training loss = 0.018216\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 111: Training loss = 0.006741\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 112: Training loss = 0.007155\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 113: Training loss = 0.007217\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 114: Training loss = 0.008433\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 115: Training loss = 0.009824\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 116: Training loss = 0.011246\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 117: Training loss = 0.012525\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 118: Training loss = 0.014015\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 119: Training loss = 0.012953\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 120: Training loss = 0.011628\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 121: Training loss = 0.011923\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 122: Training loss = 0.012230\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 123: Training loss = 0.010936\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 124: Training loss = 0.009143\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 125: Training loss = 0.008038\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 126: Training loss = 0.006833\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 127: Training loss = 0.005125\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 128: Training loss = 0.004548\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 129: Training loss = 0.004205\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 130: Training loss = 0.004990\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 131: Training loss = 0.004863\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 132: Training loss = 0.005351\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 133: Training loss = 0.005467\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 134: Training loss = 0.005696\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 135: Training loss = 0.010052\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 136: Training loss = 0.015526\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 137: Training loss = 0.014985\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 138: Training loss = 0.024725\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 139: Training loss = 0.016605\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 140: Training loss = 0.017162\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 141: Training loss = 0.014342\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 142: Training loss = 0.024915\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 143: Training loss = 0.017673\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 144: Training loss = 0.018270\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 145: Training loss = 0.014607\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 146: Training loss = 0.012412\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 147: Training loss = 0.008867\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 148: Training loss = 0.008386\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 149: Training loss = 0.007852\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 150: Training loss = 0.009663\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 151: Training loss = 0.007801\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 152: Training loss = 0.007404\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 1: Validation loss = 0.005711\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 2: Validation loss = 0.005774\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 3: Validation loss = 0.003553\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 4: Validation loss = 0.004242\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 5: Validation loss = 0.003972\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 6: Validation loss = 0.003844\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 7: Validation loss = 0.003119\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 8: Validation loss = 0.008236\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 9: Validation loss = 0.006122\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 10: Validation loss = 0.004510\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 11: Validation loss = 0.003369\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 12: Validation loss = 0.012898\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 13: Validation loss = 0.011407\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 14: Validation loss = 0.007924\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 15: Validation loss = 0.006868\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 16: Validation loss = 0.010203\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 17: Validation loss = 0.007875\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 18: Validation loss = 0.006698\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 19: Validation loss = 0.006980\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 20: Validation loss = 0.008560\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 21: Validation loss = 0.008261\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 22: Validation loss = 0.005405\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 23: Validation loss = 0.003722\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 24: Validation loss = 0.003983\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 25: Validation loss = 0.003854\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 26: Validation loss = 0.004304\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 27: Validation loss = 0.003517\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 28: Validation loss = 0.003135\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 29: Validation loss = 0.002220\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 30: Validation loss = 0.003430\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 31: Validation loss = 0.002825\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 32: Validation loss = 0.003163\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 33: Validation loss = 0.004924\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 34: Validation loss = 0.008653\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 35: Validation loss = 0.009876\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 36: Validation loss = 0.015645\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 37: Validation loss = 0.015180\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 38: Validation loss = 0.015331\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 1: Training loss = 0.015908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 2: Training loss = 0.023293\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 3: Training loss = 0.022311\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 4: Training loss = 0.023182\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 5: Training loss = 0.022539\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 6: Training loss = 0.024923\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 7: Training loss = 0.021589\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 8: Training loss = 0.021885\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 9: Training loss = 0.022556\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 10: Training loss = 0.022576\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 11: Training loss = 0.018514\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 12: Training loss = 0.016383\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 13: Training loss = 0.013458\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 14: Training loss = 0.014860\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 15: Training loss = 0.015249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 16: Training loss = 0.016101\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 17: Training loss = 0.013548\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 18: Training loss = 0.015190\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 19: Training loss = 0.010262\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 20: Training loss = 0.012051\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 21: Training loss = 0.013836\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 22: Training loss = 0.018212\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 23: Training loss = 0.018444\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 24: Training loss = 0.023784\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 25: Training loss = 0.023779\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 26: Training loss = 0.024104\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 27: Training loss = 0.022614\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 28: Training loss = 0.024476\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 29: Training loss = 0.024586\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 30: Training loss = 0.026267\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 31: Training loss = 0.021840\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 32: Training loss = 0.020062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 33: Training loss = 0.015128\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 34: Training loss = 0.014769\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 35: Training loss = 0.005692\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 36: Training loss = 0.008450\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 37: Training loss = 0.007406\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 38: Training loss = 0.011595\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 39: Training loss = 0.009032\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 40: Training loss = 0.012489\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 41: Training loss = 0.012293\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 42: Training loss = 0.012914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 43: Training loss = 0.012077\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 44: Training loss = 0.015315\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 45: Training loss = 0.013445\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 46: Training loss = 0.012938\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 47: Training loss = 0.010336\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 48: Training loss = 0.012001\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 49: Training loss = 0.008090\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 50: Training loss = 0.007100\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 51: Training loss = 0.004007\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 52: Training loss = 0.003738\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 53: Training loss = 0.001651\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 54: Training loss = 0.002572\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 55: Training loss = 0.000572\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 56: Training loss = 0.001868\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 57: Training loss = 0.000282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 58: Training loss = 0.003034\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 59: Training loss = 0.000804\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 60: Training loss = 0.001302\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 61: Training loss = 0.000318\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 62: Training loss = 0.003650\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 63: Training loss = 0.003365\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 64: Training loss = 0.005901\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 65: Training loss = 0.005159\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 66: Training loss = 0.005994\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 67: Training loss = 0.004921\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 68: Training loss = 0.005757\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 69: Training loss = 0.005465\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 70: Training loss = 0.006275\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 71: Training loss = 0.005173\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 72: Training loss = 0.006798\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 73: Training loss = 0.003073\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 74: Training loss = 0.002727\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 75: Training loss = 0.004207\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 76: Training loss = 0.009338\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 77: Training loss = 0.009909\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 78: Training loss = 0.014525\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 79: Training loss = 0.013540\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 80: Training loss = 0.015764\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 81: Training loss = 0.016822\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 82: Training loss = 0.022937\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 83: Training loss = 0.022237\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 84: Training loss = 0.023888\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 85: Training loss = 0.024006\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 86: Training loss = 0.025115\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 87: Training loss = 0.020759\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 88: Training loss = 0.017128\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 89: Training loss = 0.017082\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 90: Training loss = 0.021330\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 91: Training loss = 0.018027\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 92: Training loss = 0.014647\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 93: Training loss = 0.013402\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 94: Training loss = 0.012892\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 95: Training loss = 0.008590\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 96: Training loss = 0.009098\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 97: Training loss = 0.008187\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 98: Training loss = 0.009093\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 99: Training loss = 0.008574\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 100: Training loss = 0.007827\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 101: Training loss = 0.007300\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 102: Training loss = 0.005507\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 103: Training loss = 0.005257\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 104: Training loss = 0.008783\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 105: Training loss = 0.005954\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 106: Training loss = 0.004937\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 107: Training loss = 0.005035\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 108: Training loss = 0.008419\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 109: Training loss = 0.006364\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 110: Training loss = 0.005761\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 111: Training loss = 0.005390\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 112: Training loss = 0.006109\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 113: Training loss = 0.006407\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 114: Training loss = 0.006957\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 115: Training loss = 0.007996\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 116: Training loss = 0.010340\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 117: Training loss = 0.010929\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 118: Training loss = 0.010178\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 119: Training loss = 0.010694\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 120: Training loss = 0.011670\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 121: Training loss = 0.010995\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 122: Training loss = 0.008977\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 123: Training loss = 0.009141\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 124: Training loss = 0.009965\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 125: Training loss = 0.007753\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 126: Training loss = 0.005065\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 127: Training loss = 0.004168\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 128: Training loss = 0.004665\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 129: Training loss = 0.003526\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 130: Training loss = 0.003375\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 131: Training loss = 0.003061\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 132: Training loss = 0.003649\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 133: Training loss = 0.003663\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 134: Training loss = 0.003959\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 135: Training loss = 0.005116\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 136: Training loss = 0.019246\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 137: Training loss = 0.011321\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 138: Training loss = 0.009646\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 139: Training loss = 0.009208\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 140: Training loss = 0.021140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 141: Training loss = 0.012103\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 142: Training loss = 0.009937\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 143: Training loss = 0.010304\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 144: Training loss = 0.022755\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 145: Training loss = 0.012403\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 146: Training loss = 0.009821\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 147: Training loss = 0.007190\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 148: Training loss = 0.007185\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 149: Training loss = 0.007115\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 150: Training loss = 0.008071\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 151: Training loss = 0.006266\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 152: Training loss = 0.006786\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 1: Validation loss = 0.005001\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 2: Validation loss = 0.004347\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 3: Validation loss = 0.003389\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 4: Validation loss = 0.003726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 5: Validation loss = 0.003110\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 6: Validation loss = 0.006791\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 7: Validation loss = 0.006426\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 8: Validation loss = 0.004734\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 9: Validation loss = 0.003920\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 10: Validation loss = 0.009905\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 11: Validation loss = 0.007972\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 12: Validation loss = 0.006731\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 13: Validation loss = 0.006948\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 14: Validation loss = 0.012520\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 15: Validation loss = 0.009344\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 16: Validation loss = 0.006690\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 17: Validation loss = 0.005405\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 18: Validation loss = 0.007188\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 19: Validation loss = 0.006995\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 20: Validation loss = 0.006906\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 21: Validation loss = 0.006311\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 22: Validation loss = 0.004814\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 23: Validation loss = 0.003905\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 24: Validation loss = 0.004261\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 25: Validation loss = 0.003630\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 26: Validation loss = 0.003841\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 27: Validation loss = 0.003480\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 28: Validation loss = 0.004079\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 29: Validation loss = 0.002534\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 30: Validation loss = 0.002529\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 31: Validation loss = 0.002321\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 32: Validation loss = 0.004015\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 33: Validation loss = 0.004924\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 34: Validation loss = 0.009486\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 35: Validation loss = 0.009534\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 36: Validation loss = 0.011021\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 37: Validation loss = 0.011458\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 38: Validation loss = 0.014855\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 1: Training loss = 0.013870\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 2: Training loss = 0.015834\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 3: Training loss = 0.017101\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 4: Training loss = 0.020733\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 5: Training loss = 0.016791\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 6: Training loss = 0.017917\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 7: Training loss = 0.016697\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 8: Training loss = 0.018835\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 9: Training loss = 0.017540\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 10: Training loss = 0.016811\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 11: Training loss = 0.014973\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 12: Training loss = 0.013020\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 13: Training loss = 0.010318\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 14: Training loss = 0.012078\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 15: Training loss = 0.012089\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 16: Training loss = 0.013458\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 17: Training loss = 0.010221\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 18: Training loss = 0.011023\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 19: Training loss = 0.007701\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 20: Training loss = 0.010222\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 21: Training loss = 0.009933\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 22: Training loss = 0.013364\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 23: Training loss = 0.014172\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 24: Training loss = 0.015826\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 25: Training loss = 0.015848\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 26: Training loss = 0.016741\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 27: Training loss = 0.015314\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 28: Training loss = 0.016429\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 29: Training loss = 0.016390\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 30: Training loss = 0.017642\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 31: Training loss = 0.014371\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 32: Training loss = 0.015795\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 33: Training loss = 0.010859\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 34: Training loss = 0.006615\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 35: Training loss = 0.003547\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 36: Training loss = 0.008313\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 37: Training loss = 0.006310\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 38: Training loss = 0.006033\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 39: Training loss = 0.006472\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 40: Training loss = 0.011017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 41: Training loss = 0.009537\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 42: Training loss = 0.011040\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 43: Training loss = 0.010299\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 44: Training loss = 0.013458\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 45: Training loss = 0.011205\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 46: Training loss = 0.010956\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 47: Training loss = 0.009435\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 48: Training loss = 0.009765\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 49: Training loss = 0.006641\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 50: Training loss = 0.006058\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 51: Training loss = 0.003411\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 52: Training loss = 0.004965\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 53: Training loss = 0.001981\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 54: Training loss = 0.000924\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 55: Training loss = 0.000239\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 56: Training loss = 0.002747\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 57: Training loss = 0.000592\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 58: Training loss = 0.001422\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 59: Training loss = 0.000175\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 60: Training loss = 0.002973\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 61: Training loss = 0.000747\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 62: Training loss = 0.002400\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 63: Training loss = 0.002542\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 64: Training loss = 0.004730\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 65: Training loss = 0.003882\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 66: Training loss = 0.004568\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 67: Training loss = 0.003935\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 68: Training loss = 0.004851\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 69: Training loss = 0.004189\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 70: Training loss = 0.004998\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 71: Training loss = 0.004412\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 72: Training loss = 0.004036\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 73: Training loss = 0.002234\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 74: Training loss = 0.003910\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 75: Training loss = 0.003220\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 76: Training loss = 0.007337\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 77: Training loss = 0.007259\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 78: Training loss = 0.010179\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 79: Training loss = 0.009501\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 80: Training loss = 0.011757\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 81: Training loss = 0.012920\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 82: Training loss = 0.014653\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 83: Training loss = 0.015569\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 84: Training loss = 0.019903\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 85: Training loss = 0.018288\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 86: Training loss = 0.015338\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 87: Training loss = 0.014534\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 88: Training loss = 0.015377\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 89: Training loss = 0.012932\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 90: Training loss = 0.011611\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 91: Training loss = 0.011335\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 92: Training loss = 0.012964\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 93: Training loss = 0.009835\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 94: Training loss = 0.006930\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 95: Training loss = 0.006283\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 96: Training loss = 0.007158\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 97: Training loss = 0.006166\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 98: Training loss = 0.007052\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 99: Training loss = 0.006735\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 100: Training loss = 0.005926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 101: Training loss = 0.004633\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 102: Training loss = 0.006530\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 103: Training loss = 0.004949\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 104: Training loss = 0.004919\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 105: Training loss = 0.003659\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 106: Training loss = 0.005655\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 107: Training loss = 0.004636\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 108: Training loss = 0.005254\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 109: Training loss = 0.004432\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 110: Training loss = 0.005943\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 111: Training loss = 0.004790\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 112: Training loss = 0.005731\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 113: Training loss = 0.005667\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 114: Training loss = 0.006401\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 115: Training loss = 0.007405\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 116: Training loss = 0.008365\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 117: Training loss = 0.009172\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 118: Training loss = 0.010009\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 119: Training loss = 0.009814\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 120: Training loss = 0.008901\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 121: Training loss = 0.009380\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 122: Training loss = 0.009478\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 123: Training loss = 0.008425\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 124: Training loss = 0.007099\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 125: Training loss = 0.006418\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 126: Training loss = 0.005964\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 127: Training loss = 0.004150\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 128: Training loss = 0.003395\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 129: Training loss = 0.002522\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 130: Training loss = 0.003095\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 131: Training loss = 0.002444\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 132: Training loss = 0.002486\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 133: Training loss = 0.002443\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 134: Training loss = 0.002737\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 135: Training loss = 0.004080\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 136: Training loss = 0.005713\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 137: Training loss = 0.006906\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 138: Training loss = 0.018503\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 139: Training loss = 0.009951\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 140: Training loss = 0.007255\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 141: Training loss = 0.008278\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 142: Training loss = 0.019243\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 143: Training loss = 0.011370\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 144: Training loss = 0.011332\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 145: Training loss = 0.010017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 146: Training loss = 0.007392\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 147: Training loss = 0.006749\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 148: Training loss = 0.008220\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 149: Training loss = 0.006815\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 150: Training loss = 0.006111\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 151: Training loss = 0.005733\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 152: Training loss = 0.007557\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 1: Validation loss = 0.004292\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 2: Validation loss = 0.004478\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 3: Validation loss = 0.003215\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 4: Validation loss = 0.003974\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 5: Validation loss = 0.004222\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Validation window 6: Validation loss = 0.004322\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 7: Validation loss = 0.003725\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 8: Validation loss = 0.008676\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 9: Validation loss = 0.007092\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 10: Validation loss = 0.004961\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 11: Validation loss = 0.004153\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 12: Validation loss = 0.011848\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 13: Validation loss = 0.009927\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 14: Validation loss = 0.006543\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 15: Validation loss = 0.005453\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 16: Validation loss = 0.008424\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 17: Validation loss = 0.005658\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 18: Validation loss = 0.005137\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 19: Validation loss = 0.005083\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 20: Validation loss = 0.005783\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 21: Validation loss = 0.005709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 22: Validation loss = 0.004379\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 23: Validation loss = 0.003308\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 24: Validation loss = 0.003772\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 25: Validation loss = 0.003648\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 26: Validation loss = 0.003770\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 27: Validation loss = 0.003119\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 28: Validation loss = 0.003158\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 29: Validation loss = 0.002346\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 30: Validation loss = 0.002639\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 31: Validation loss = 0.002250\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Validation window 32: Validation loss = 0.003169\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 33: Validation loss = 0.005074\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 34: Validation loss = 0.007025\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 35: Validation loss = 0.008524\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 36: Validation loss = 0.012743\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 37: Validation loss = 0.012221\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 38: Validation loss = 0.012418\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 1: Training loss = 0.010613\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 2: Training loss = 0.014318\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Training window 3: Training loss = 0.012981\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 4: Training loss = 0.014452\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 5: Training loss = 0.013082\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 6: Training loss = 0.014116\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 7: Training loss = 0.012555\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 8: Training loss = 0.014524\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 9: Training loss = 0.013677\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 10: Training loss = 0.013715\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 11: Training loss = 0.010953\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 12: Training loss = 0.010470\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 13: Training loss = 0.008856\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 14: Training loss = 0.009276\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 15: Training loss = 0.009192\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 16: Training loss = 0.009820\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 17: Training loss = 0.007571\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 18: Training loss = 0.008965\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 19: Training loss = 0.005642\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 20: Training loss = 0.007105\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Training window 21: Training loss = 0.007379\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 22: Training loss = 0.009560\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 23: Training loss = 0.009402\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 24: Training loss = 0.013139\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 25: Training loss = 0.010805\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 26: Training loss = 0.010605\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 27: Training loss = 0.009597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 28: Training loss = 0.011985\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 29: Training loss = 0.011226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 30: Training loss = 0.011508\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 31: Training loss = 0.009410\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 32: Training loss = 0.009500\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 33: Training loss = 0.006310\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 34: Training loss = 0.006820\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 35: Training loss = 0.003067\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 36: Training loss = 0.005102\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 37: Training loss = 0.004092\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 38: Training loss = 0.007384\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 39: Training loss = 0.005471\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 40: Training loss = 0.008066\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 41: Training loss = 0.007638\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 42: Training loss = 0.009019\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 43: Training loss = 0.008239\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 44: Training loss = 0.011369\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 45: Training loss = 0.009583\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 46: Training loss = 0.009387\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 47: Training loss = 0.007451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 48: Training loss = 0.009544\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 49: Training loss = 0.006114\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 50: Training loss = 0.005445\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 51: Training loss = 0.003364\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 52: Training loss = 0.003923\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 53: Training loss = 0.001688\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 54: Training loss = 0.002320\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 55: Training loss = 0.000593\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 56: Training loss = 0.001136\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 57: Training loss = 0.000197\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 58: Training loss = 0.002588\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 59: Training loss = 0.000577\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 60: Training loss = 0.001036\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 61: Training loss = 0.000190\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 62: Training loss = 0.003009\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 63: Training loss = 0.001980\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 64: Training loss = 0.003468\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 65: Training loss = 0.003129\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 66: Training loss = 0.004176\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 67: Training loss = 0.003109\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 68: Training loss = 0.003578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 69: Training loss = 0.003350\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 70: Training loss = 0.004263\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 71: Training loss = 0.003308\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 72: Training loss = 0.004835\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 73: Training loss = 0.002237\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 74: Training loss = 0.002481\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 75: Training loss = 0.002323\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 76: Training loss = 0.005189\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 77: Training loss = 0.004573\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 78: Training loss = 0.007259\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 79: Training loss = 0.006662\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 80: Training loss = 0.009125\n","313/313 [==============================] - 1s 3ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Training window 81: Training loss = 0.008978\n","313/313 [==============================] - 1s 5ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 82: Training loss = 0.011955\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 83: Training loss = 0.011408\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 84: Training loss = 0.011943\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 85: Training loss = 0.011718\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 86: Training loss = 0.012965\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 87: Training loss = 0.010872\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 88: Training loss = 0.008784\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 89: Training loss = 0.008471\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 90: Training loss = 0.011490\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 91: Training loss = 0.008449\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 92: Training loss = 0.006351\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 93: Training loss = 0.006034\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 94: Training loss = 0.007906\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 95: Training loss = 0.005080\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Training window 96: Training loss = 0.004696\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 97: Training loss = 0.004694\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 98: Training loss = 0.006482\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 99: Training loss = 0.005445\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 100: Training loss = 0.005264\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 101: Training loss = 0.004238\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 102: Training loss = 0.005035\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 103: Training loss = 0.003866\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 104: Training loss = 0.004571\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 105: Training loss = 0.003259\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 106: Training loss = 0.004640\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 107: Training loss = 0.003605\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 108: Training loss = 0.004713\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 109: Training loss = 0.003974\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 110: Training loss = 0.005417\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 111: Training loss = 0.004260\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 112: Training loss = 0.005033\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 113: Training loss = 0.005280\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 114: Training loss = 0.005783\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 115: Training loss = 0.006457\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 116: Training loss = 0.007954\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 117: Training loss = 0.008260\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 118: Training loss = 0.007527\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 119: Training loss = 0.008234\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 120: Training loss = 0.009053\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 121: Training loss = 0.008619\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 122: Training loss = 0.006715\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 123: Training loss = 0.006789\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 124: Training loss = 0.007589\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 125: Training loss = 0.006090\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 126: Training loss = 0.004194\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 127: Training loss = 0.003327\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 128: Training loss = 0.003741\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 129: Training loss = 0.002412\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 130: Training loss = 0.002221\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 131: Training loss = 0.001697\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 132: Training loss = 0.002174\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 133: Training loss = 0.002022\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 134: Training loss = 0.002136\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 135: Training loss = 0.002563\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 136: Training loss = 0.013696\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 137: Training loss = 0.006985\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 138: Training loss = 0.005997\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 139: Training loss = 0.006382\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 140: Training loss = 0.015130\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 141: Training loss = 0.008303\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 142: Training loss = 0.006870\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 143: Training loss = 0.008256\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 144: Training loss = 0.016625\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 145: Training loss = 0.009496\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 146: Training loss = 0.008229\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 147: Training loss = 0.006130\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 148: Training loss = 0.005040\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 149: Training loss = 0.005527\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 150: Training loss = 0.007200\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 151: Training loss = 0.005201\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 152: Training loss = 0.004663\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 1: Validation loss = 0.003748\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 2: Validation loss = 0.003524\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 3: Validation loss = 0.002908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Validation window 4: Validation loss = 0.003437\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 5: Validation loss = 0.002846\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 6: Validation loss = 0.005891\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 7: Validation loss = 0.005669\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 8: Validation loss = 0.004665\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 9: Validation loss = 0.003747\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 10: Validation loss = 0.008935\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 11: Validation loss = 0.006985\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 12: Validation loss = 0.005733\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 13: Validation loss = 0.005270\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 14: Validation loss = 0.009688\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 15: Validation loss = 0.006948\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 16: Validation loss = 0.005102\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 17: Validation loss = 0.003865\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 18: Validation loss = 0.005112\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 19: Validation loss = 0.004742\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 20: Validation loss = 0.004967\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 21: Validation loss = 0.004202\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 22: Validation loss = 0.003590\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 23: Validation loss = 0.003121\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 24: Validation loss = 0.003323\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 25: Validation loss = 0.002844\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 26: Validation loss = 0.003173\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Validation window 27: Validation loss = 0.002845\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 28: Validation loss = 0.003015\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 29: Validation loss = 0.001929\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 30: Validation loss = 0.002456\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 31: Validation loss = 0.002124\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 32: Validation loss = 0.003077\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 33: Validation loss = 0.004097\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 34: Validation loss = 0.007881\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 35: Validation loss = 0.008138\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 36: Validation loss = 0.008669\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Validation window 37: Validation loss = 0.009475\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-04-26 13:11:46,310]\u001b[0m Trial 0 finished with value: 0.004662954248487949 and parameters: {'dropout_rate': 0.33699129803466454, 'learning_rate': 0.0008032352533476955, 'activation': 'relu', 'kernel_initializer': None}. Best is trial 0 with value: 0.004662954248487949.\u001b[0m\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Iteration 4, Training window 80: Training loss = 0.203604\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 81: Training loss = 0.224078\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 82: Training loss = 0.261577\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 83: Training loss = 0.124999\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 84: Training loss = 0.221351\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 85: Training loss = 0.362646\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 86: Training loss = 0.211232\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 87: Training loss = 0.173548\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 88: Training loss = 0.281024\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 89: Training loss = 0.176927\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 90: Training loss = 0.418182\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 91: Training loss = 0.742076\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 92: Training loss = 0.368112\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 93: Training loss = 0.227169\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 94: Training loss = 0.404198\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 95: Training loss = 0.233035\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 96: Training loss = 0.373646\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 97: Training loss = 0.560711\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 98: Training loss = 0.327866\n","313/313 [==============================] - 0s 1ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 99: Training loss = 0.209776\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 100: Training loss = 0.165935\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 101: Training loss = 0.174790\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 102: Training loss = 0.370978\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 103: Training loss = 0.439887\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 104: Training loss = 0.233291\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 105: Training loss = 0.222914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 106: Training loss = 0.223926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 107: Training loss = 0.123441\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 108: Training loss = 0.293785\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 109: Training loss = 0.399465\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 110: Training loss = 0.272021\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 111: Training loss = 0.246360\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 112: Training loss = 0.187777\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 113: Training loss = 0.160642\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 114: Training loss = 0.179287\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 115: Training loss = 0.187966\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 116: Training loss = 0.187122\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 117: Training loss = 0.164902\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 118: Training loss = 0.135032\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 119: Training loss = 0.117871\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 120: Training loss = 0.138734\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 121: Training loss = 0.110887\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 122: Training loss = 0.069228\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 123: Training loss = 0.055839\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 124: Training loss = 0.051492\n","313/313 [==============================] - 0s 1ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 125: Training loss = 0.045397\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 126: Training loss = 0.069280\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 127: Training loss = 0.078226\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 128: Training loss = 0.089775\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 129: Training loss = 0.160369\n","313/313 [==============================] - 0s 1ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 130: Training loss = 0.155263\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 131: Training loss = 0.177017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 4, Training window 132: Training loss = 0.234482\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 133: Training loss = 0.257240\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 134: Training loss = 0.270443\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 135: Training loss = 0.921028\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 136: Training loss = 3.527988\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 137: Training loss = 2.038236\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 138: Training loss = 0.600552\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 139: Training loss = 1.343978\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 140: Training loss = 0.516391\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 141: Training loss = 1.407081\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 142: Training loss = 3.305607\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 143: Training loss = 1.911320\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 144: Training loss = 0.610716\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 145: Training loss = 1.695137\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 146: Training loss = 0.403610\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 147: Training loss = 0.111520\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 148: Training loss = 0.403830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 149: Training loss = 0.172274\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 150: Training loss = 0.303066\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 151: Training loss = 0.763082\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 152: Training loss = 0.379140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 1: Validation loss = 0.084534\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 2: Validation loss = 0.096239\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 3: Validation loss = 0.060823\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 4: Validation loss = 0.057592\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 5: Validation loss = 0.058621\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 6: Validation loss = 0.046955\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 7: Validation loss = 0.041017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 8: Validation loss = 0.034561\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 9: Validation loss = 0.022171\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 10: Validation loss = 0.060357\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 11: Validation loss = 0.074266\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 12: Validation loss = 0.056610\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 13: Validation loss = 0.061833\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 14: Validation loss = 0.094640\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 15: Validation loss = 0.060213\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 16: Validation loss = 0.063878\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 17: Validation loss = 0.127461\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 18: Validation loss = 0.091219\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 19: Validation loss = 0.068086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 20: Validation loss = 0.141368\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 21: Validation loss = 0.099810\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 22: Validation loss = 0.060829\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 23: Validation loss = 0.059399\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 24: Validation loss = 0.039385\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 25: Validation loss = 0.065161\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 26: Validation loss = 0.080743\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 27: Validation loss = 0.049495\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 28: Validation loss = 0.049635\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 29: Validation loss = 0.077381\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 30: Validation loss = 0.051526\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 31: Validation loss = 0.026830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 32: Validation loss = 0.064149\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 33: Validation loss = 0.226917\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 34: Validation loss = 0.415382\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 35: Validation loss = 1.543033\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 36: Validation loss = 0.864136\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 37: Validation loss = 0.293454\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 38: Validation loss = 1.179268\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 1: Training loss = 0.762843\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 2: Training loss = 0.637490\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 3: Training loss = 1.848643\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 4: Training loss = 0.579541\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 5: Training loss = 0.471458\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 6: Training loss = 1.236515\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 7: Training loss = 0.628214\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 8: Training loss = 0.423469\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 9: Training loss = 1.072974\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 10: Training loss = 0.209247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 11: Training loss = 0.131792\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 12: Training loss = 0.123437\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 13: Training loss = 0.096302\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 14: Training loss = 0.128268\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 15: Training loss = 0.251908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 16: Training loss = 0.167465\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 17: Training loss = 0.101588\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 18: Training loss = 0.064189\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 19: Training loss = 0.021050\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 20: Training loss = 0.194564\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 21: Training loss = 0.218340\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 22: Training loss = 0.098077\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 23: Training loss = 0.077845\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 24: Training loss = 0.044808\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 25: Training loss = 0.015748\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 26: Training loss = 0.086300\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 27: Training loss = 0.077348\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 28: Training loss = 0.028177\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 29: Training loss = 0.053572\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 30: Training loss = 0.032451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 31: Training loss = 0.014273\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 32: Training loss = 0.091421\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 33: Training loss = 0.074183\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 34: Training loss = 0.053216\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 35: Training loss = 0.087321\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 36: Training loss = 0.057528\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 37: Training loss = 0.042691\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 38: Training loss = 0.189188\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 39: Training loss = 0.125994\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 40: Training loss = 0.086559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 41: Training loss = 0.110356\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 42: Training loss = 0.097835\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 43: Training loss = 0.087300\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 44: Training loss = 0.219986\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 45: Training loss = 0.114211\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 46: Training loss = 0.073174\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 47: Training loss = 0.145572\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 48: Training loss = 0.116095\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 49: Training loss = 0.091106\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 50: Training loss = 0.098084\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 51: Training loss = 0.058419\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 52: Training loss = 0.040874\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 53: Training loss = 0.063797\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 54: Training loss = 0.049101\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 55: Training loss = 0.038002\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 56: Training loss = 0.034296\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 57: Training loss = 0.042717\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 58: Training loss = 0.024186\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 59: Training loss = 0.026610\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 60: Training loss = 0.030407\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 61: Training loss = 0.017978\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 62: Training loss = 0.027963\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 63: Training loss = 0.038793\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 64: Training loss = 0.039241\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 65: Training loss = 0.074117\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 66: Training loss = 0.075384\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 67: Training loss = 0.065021\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 68: Training loss = 0.067059\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 69: Training loss = 0.078722\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 70: Training loss = 0.088059\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 71: Training loss = 0.114193\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 72: Training loss = 0.197570\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 73: Training loss = 0.203452\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 74: Training loss = 0.114843\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 75: Training loss = 0.158680\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 76: Training loss = 0.105475\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 77: Training loss = 0.127651\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 78: Training loss = 0.246088\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 79: Training loss = 0.195481\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 80: Training loss = 0.175417\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 81: Training loss = 0.228204\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 82: Training loss = 0.138249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 83: Training loss = 0.123065\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 84: Training loss = 0.176567\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 85: Training loss = 0.098519\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 86: Training loss = 0.163872\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 87: Training loss = 0.274451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 88: Training loss = 0.201279\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 89: Training loss = 0.161307\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 90: Training loss = 0.357852\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 91: Training loss = 0.157042\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 92: Training loss = 0.343993\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 93: Training loss = 0.606949\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 94: Training loss = 0.328996\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 95: Training loss = 0.204349\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 96: Training loss = 0.307686\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 97: Training loss = 0.188668\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 98: Training loss = 0.200134\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 99: Training loss = 0.406913\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 100: Training loss = 0.115255\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 101: Training loss = 0.125209\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 102: Training loss = 0.158122\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 103: Training loss = 0.107484\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 104: Training loss = 0.185226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 105: Training loss = 0.272732\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 106: Training loss = 0.167060\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 107: Training loss = 0.095361\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 108: Training loss = 0.121242\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 109: Training loss = 0.096535\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 110: Training loss = 0.199705\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 111: Training loss = 0.125178\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 112: Training loss = 0.125476\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 113: Training loss = 0.126148\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 114: Training loss = 0.122606\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 115: Training loss = 0.122961\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 116: Training loss = 0.132002\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 117: Training loss = 0.137000\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 118: Training loss = 0.126409\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 119: Training loss = 0.117617\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 120: Training loss = 0.092133\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 121: Training loss = 0.068334\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 122: Training loss = 0.070444\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 123: Training loss = 0.057866\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 124: Training loss = 0.062984\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 125: Training loss = 0.079082\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 126: Training loss = 0.067649\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 127: Training loss = 0.066140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 128: Training loss = 0.076896\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 129: Training loss = 0.133474\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 130: Training loss = 0.153392\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 131: Training loss = 0.212311\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 132: Training loss = 0.225857\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 133: Training loss = 0.195183\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 134: Training loss = 0.225145\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 135: Training loss = 0.367420\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 136: Training loss = 0.856256\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 137: Training loss = 0.737199\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 138: Training loss = 2.171477\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 139: Training loss = 1.379293\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 140: Training loss = 0.399614\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 141: Training loss = 1.152519\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 142: Training loss = 0.544992\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 143: Training loss = 0.722263\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 144: Training loss = 2.417159\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 145: Training loss = 0.735517\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 146: Training loss = 0.139399\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 147: Training loss = 0.547163\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 148: Training loss = 0.373632\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 149: Training loss = 0.054885\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 150: Training loss = 0.307900\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 151: Training loss = 0.186896\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 152: Training loss = 0.156752\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 1: Validation loss = 0.162644\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 2: Validation loss = 0.073649\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 3: Validation loss = 0.055571\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 4: Validation loss = 0.056997\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 5: Validation loss = 0.054692\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 6: Validation loss = 0.047709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 7: Validation loss = 0.052229\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 8: Validation loss = 0.057959\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 9: Validation loss = 0.041374\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 10: Validation loss = 0.027606\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 11: Validation loss = 0.029481\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 12: Validation loss = 0.037289\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 13: Validation loss = 0.113809\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 14: Validation loss = 0.105437\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 15: Validation loss = 0.041970\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 16: Validation loss = 0.078376\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 17: Validation loss = 0.084832\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 18: Validation loss = 0.060560\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 19: Validation loss = 0.103093\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 20: Validation loss = 0.092907\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 21: Validation loss = 0.042382\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 22: Validation loss = 0.098116\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 23: Validation loss = 0.075125\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 24: Validation loss = 0.043212\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 25: Validation loss = 0.038357\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 26: Validation loss = 0.046792\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 27: Validation loss = 0.040754\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 28: Validation loss = 0.033667\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 29: Validation loss = 0.041992\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 30: Validation loss = 0.028451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 31: Validation loss = 0.043320\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 32: Validation loss = 0.073315\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 33: Validation loss = 0.106612\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 34: Validation loss = 0.667375\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 35: Validation loss = 0.581118\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 36: Validation loss = 0.248902\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 37: Validation loss = 1.130978\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 38: Validation loss = 0.682455\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 1: Training loss = 0.293427\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 2: Training loss = 1.236541\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 3: Training loss = 0.680464\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 4: Training loss = 0.242096\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 5: Training loss = 0.839048\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 6: Training loss = 0.530791\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 7: Training loss = 0.208133\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 8: Training loss = 0.794435\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 9: Training loss = 0.473657\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 10: Training loss = 0.107674\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 11: Training loss = 0.096242\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 12: Training loss = 0.076578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 13: Training loss = 0.078030\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 14: Training loss = 0.071441\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 15: Training loss = 0.061317\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 16: Training loss = 0.109599\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 17: Training loss = 0.142792\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 18: Training loss = 0.122379\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 19: Training loss = 0.079303\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 20: Training loss = 0.045414\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 21: Training loss = 0.018467\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 22: Training loss = 0.085641\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 23: Training loss = 0.118807\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 24: Training loss = 0.069250\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 25: Training loss = 0.032986\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 26: Training loss = 0.028708\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 27: Training loss = 0.017096\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 28: Training loss = 0.019528\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 29: Training loss = 0.041167\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 30: Training loss = 0.028062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 31: Training loss = 0.024990\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 32: Training loss = 0.033722\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 33: Training loss = 0.016441\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 34: Training loss = 0.026813\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 35: Training loss = 0.038557\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 36: Training loss = 0.048452\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 37: Training loss = 0.051494\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 38: Training loss = 0.049080\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 39: Training loss = 0.038538\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 40: Training loss = 0.065237\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 41: Training loss = 0.056892\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 42: Training loss = 0.091822\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 43: Training loss = 0.092667\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 44: Training loss = 0.082824\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 45: Training loss = 0.068515\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 46: Training loss = 0.057722\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 47: Training loss = 0.054555\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 48: Training loss = 0.045954\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 49: Training loss = 0.056435\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 50: Training loss = 0.043580\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 51: Training loss = 0.054783\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 52: Training loss = 0.069304\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 53: Training loss = 0.025832\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 54: Training loss = 0.036122\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 55: Training loss = 0.076190\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 56: Training loss = 0.028195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 57: Training loss = 0.041020\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 58: Training loss = 0.045830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 59: Training loss = 0.019821\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 60: Training loss = 0.019375\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 61: Training loss = 0.034875\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 62: Training loss = 0.014536\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 63: Training loss = 0.034682\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 64: Training loss = 0.045138\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 65: Training loss = 0.031065\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 66: Training loss = 0.058070\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 67: Training loss = 0.083495\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 68: Training loss = 0.055803\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 69: Training loss = 0.048838\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 70: Training loss = 0.063372\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 71: Training loss = 0.073265\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 72: Training loss = 0.053314\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 73: Training loss = 0.068080\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 74: Training loss = 0.074044\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 75: Training loss = 0.206394\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 76: Training loss = 0.226660\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 77: Training loss = 0.171852\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 78: Training loss = 0.111076\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 79: Training loss = 0.075580\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 80: Training loss = 0.108948\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 81: Training loss = 0.154140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 82: Training loss = 0.109786\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 83: Training loss = 0.177883\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 84: Training loss = 0.116959\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 85: Training loss = 0.059954\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 86: Training loss = 0.141743\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 87: Training loss = 0.101562\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 88: Training loss = 0.102711\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 89: Training loss = 0.229636\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 90: Training loss = 0.322555\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 91: Training loss = 0.104734\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 92: Training loss = 0.249852\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 93: Training loss = 0.148673\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 94: Training loss = 0.187582\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 95: Training loss = 0.370225\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 96: Training loss = 0.231333\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 97: Training loss = 0.125704\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 98: Training loss = 0.196975\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 99: Training loss = 0.120864\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 100: Training loss = 0.082891\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 101: Training loss = 0.242525\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 102: Training loss = 0.172843\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 103: Training loss = 0.077300\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 104: Training loss = 0.109708\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 105: Training loss = 0.059782\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 106: Training loss = 0.124485\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 107: Training loss = 0.210245\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 108: Training loss = 0.114736\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 109: Training loss = 0.067087\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 110: Training loss = 0.112208\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 111: Training loss = 0.081282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 112: Training loss = 0.088942\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 113: Training loss = 0.094226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 114: Training loss = 0.095504\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 115: Training loss = 0.098921\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 116: Training loss = 0.097851\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 117: Training loss = 0.090874\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 118: Training loss = 0.106309\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 119: Training loss = 0.101739\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 120: Training loss = 0.082602\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 121: Training loss = 0.069898\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 122: Training loss = 0.060602\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 123: Training loss = 0.058091\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 124: Training loss = 0.057680\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 125: Training loss = 0.043431\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 126: Training loss = 0.051703\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 127: Training loss = 0.082891\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 128: Training loss = 0.114924\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 129: Training loss = 0.112074\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 130: Training loss = 0.142445\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 131: Training loss = 0.192945\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 132: Training loss = 0.199282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 133: Training loss = 0.251943\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 134: Training loss = 0.251284\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 135: Training loss = 0.731118\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 136: Training loss = 0.447190\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 137: Training loss = 1.195487\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 138: Training loss = 0.718282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 139: Training loss = 0.557198\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 140: Training loss = 1.676909\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 141: Training loss = 0.983367\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 142: Training loss = 0.329540\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 143: Training loss = 1.316690\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 144: Training loss = 0.641975\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 145: Training loss = 0.272374\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 146: Training loss = 0.300411\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 147: Training loss = 0.161693\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 148: Training loss = 0.109534\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 149: Training loss = 0.418692\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 150: Training loss = 0.277381\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 151: Training loss = 0.057104\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 152: Training loss = 0.286200\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 1: Validation loss = 0.087417\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 2: Validation loss = 0.049111\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 3: Validation loss = 0.051027\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 4: Validation loss = 0.046825\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 5: Validation loss = 0.040711\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 6: Validation loss = 0.037605\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 7: Validation loss = 0.027801\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 8: Validation loss = 0.030308\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 9: Validation loss = 0.043571\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 10: Validation loss = 0.049208\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 11: Validation loss = 0.031967\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 12: Validation loss = 0.036290\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 13: Validation loss = 0.066292\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 14: Validation loss = 0.039475\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 15: Validation loss = 0.094754\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 16: Validation loss = 0.079843\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 17: Validation loss = 0.031967\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 18: Validation loss = 0.089696\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 19: Validation loss = 0.089013\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 20: Validation loss = 0.039926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 21: Validation loss = 0.078286\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 22: Validation loss = 0.072791\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Validation window 23: Validation loss = 0.030443\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 24: Validation loss = 0.050777\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 25: Validation loss = 0.062020\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 26: Validation loss = 0.035643\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 27: Validation loss = 0.039041\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 28: Validation loss = 0.049153\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 29: Validation loss = 0.032203\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 30: Validation loss = 0.027958\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 31: Validation loss = 0.031552\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 32: Validation loss = 0.020134\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 33: Validation loss = 0.204795\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Validation window 34: Validation loss = 0.429734\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 35: Validation loss = 0.144320\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 36: Validation loss = 0.871528\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 37: Validation loss = 0.564132\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 38: Validation loss = 0.205735\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 1: Training loss = 1.197562\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 2: Training loss = 0.611681\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 3: Training loss = 0.263260\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 4: Training loss = 0.790408\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 5: Training loss = 0.401009\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 6: Training loss = 0.194303\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 7: Training loss = 0.688912\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 8: Training loss = 0.408723\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 9: Training loss = 0.166554\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 10: Training loss = 0.141290\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 11: Training loss = 0.058358\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 12: Training loss = 0.057584\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 13: Training loss = 0.067886\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 14: Training loss = 0.057165\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 15: Training loss = 0.055376\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 16: Training loss = 0.054029\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 17: Training loss = 0.036105\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 18: Training loss = 0.069203\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 19: Training loss = 0.083832\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 20: Training loss = 0.090127\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 21: Training loss = 0.052284\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 22: Training loss = 0.032320\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 23: Training loss = 0.016051\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 24: Training loss = 0.062751\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 25: Training loss = 0.027206\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 26: Training loss = 0.018321\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 27: Training loss = 0.024642\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 28: Training loss = 0.024296\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 29: Training loss = 0.013482\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 30: Training loss = 0.016581\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 31: Training loss = 0.024579\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 32: Training loss = 0.020810\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 33: Training loss = 0.038009\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 34: Training loss = 0.037517\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 35: Training loss = 0.012835\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 36: Training loss = 0.053064\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 37: Training loss = 0.047040\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 38: Training loss = 0.043182\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 39: Training loss = 0.051954\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 40: Training loss = 0.046353\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 41: Training loss = 0.047956\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 42: Training loss = 0.064857\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 43: Training loss = 0.052950\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 44: Training loss = 0.049026\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 45: Training loss = 0.049989\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 46: Training loss = 0.048173\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 47: Training loss = 0.042604\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 48: Training loss = 0.071933\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 49: Training loss = 0.044054\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 50: Training loss = 0.026427\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 51: Training loss = 0.031262\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 52: Training loss = 0.016503\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 53: Training loss = 0.040358\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 54: Training loss = 0.052454\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 55: Training loss = 0.009517\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 56: Training loss = 0.059219\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 57: Training loss = 0.084207\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 58: Training loss = 0.020025\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 59: Training loss = 0.023381\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 60: Training loss = 0.041955\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 61: Training loss = 0.012541\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 62: Training loss = 0.025675\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 63: Training loss = 0.037060\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 64: Training loss = 0.018692\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 65: Training loss = 0.041753\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 66: Training loss = 0.047630\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 67: Training loss = 0.025464\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 68: Training loss = 0.052667\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 69: Training loss = 0.066051\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 70: Training loss = 0.043396\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 71: Training loss = 0.093077\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 72: Training loss = 0.176072\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 73: Training loss = 0.079430\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 74: Training loss = 0.048660\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 75: Training loss = 0.061926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 76: Training loss = 0.090109\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 77: Training loss = 0.180594\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 78: Training loss = 0.190770\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 79: Training loss = 0.138670\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 80: Training loss = 0.092715\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 81: Training loss = 0.058941\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 82: Training loss = 0.099668\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 83: Training loss = 0.070565\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 84: Training loss = 0.068711\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 85: Training loss = 0.181621\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 86: Training loss = 0.116975\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 87: Training loss = 0.061332\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 88: Training loss = 0.137519\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 89: Training loss = 0.092030\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 90: Training loss = 0.135115\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 91: Training loss = 0.368611\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 92: Training loss = 0.248597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 93: Training loss = 0.102120\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 94: Training loss = 0.212564\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 95: Training loss = 0.115792\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 96: Training loss = 0.147497\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 97: Training loss = 0.279764\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 98: Training loss = 0.167262\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 99: Training loss = 0.079279\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 100: Training loss = 0.064662\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 101: Training loss = 0.073097\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 102: Training loss = 0.118267\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 103: Training loss = 0.182779\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 104: Training loss = 0.119609\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 105: Training loss = 0.043787\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 106: Training loss = 0.073597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 107: Training loss = 0.042017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 108: Training loss = 0.104354\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 109: Training loss = 0.175938\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 110: Training loss = 0.108569\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 111: Training loss = 0.067793\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 112: Training loss = 0.063510\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 113: Training loss = 0.070404\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 114: Training loss = 0.083261\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 115: Training loss = 0.089781\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 116: Training loss = 0.088287\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 117: Training loss = 0.089712\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 118: Training loss = 0.083562\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 119: Training loss = 0.088100\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 120: Training loss = 0.089194\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 121: Training loss = 0.071671\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 122: Training loss = 0.059874\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 123: Training loss = 0.059021\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 124: Training loss = 0.050922\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 125: Training loss = 0.046616\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 126: Training loss = 0.049431\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 127: Training loss = 0.056661\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 128: Training loss = 0.082631\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 129: Training loss = 0.136726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 130: Training loss = 0.152416\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 131: Training loss = 0.142313\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 132: Training loss = 0.173002\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 133: Training loss = 0.207547\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 134: Training loss = 0.211706\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 135: Training loss = 0.459323\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 136: Training loss = 1.453948\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 137: Training loss = 0.819166\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 138: Training loss = 0.395620\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 139: Training loss = 1.051082\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 140: Training loss = 0.588712\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 141: Training loss = 0.399960\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 142: Training loss = 1.270013\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 143: Training loss = 0.761612\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 144: Training loss = 0.362258\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 145: Training loss = 1.160056\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 146: Training loss = 0.197677\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 147: Training loss = 0.070023\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 148: Training loss = 0.270627\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 149: Training loss = 0.159990\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 150: Training loss = 0.091644\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 151: Training loss = 0.338708\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 152: Training loss = 0.215773\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 1: Validation loss = 0.040255\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 2: Validation loss = 0.055274\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 3: Validation loss = 0.047537\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 4: Validation loss = 0.036037\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 5: Validation loss = 0.039433\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 6: Validation loss = 0.039380\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 7: Validation loss = 0.026736\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 8: Validation loss = 0.021863\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 9: Validation loss = 0.028825\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 10: Validation loss = 0.034064\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 11: Validation loss = 0.037037\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 12: Validation loss = 0.039704\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 13: Validation loss = 0.024881\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 14: Validation loss = 0.065022\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 15: Validation loss = 0.066022\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 16: Validation loss = 0.029885\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 17: Validation loss = 0.077052\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 18: Validation loss = 0.066611\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 19: Validation loss = 0.028417\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Validation window 20: Validation loss = 0.074928\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 21: Validation loss = 0.083402\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 22: Validation loss = 0.034526\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 23: Validation loss = 0.038865\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 24: Validation loss = 0.044686\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 25: Validation loss = 0.033080\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 26: Validation loss = 0.042771\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 27: Validation loss = 0.044548\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 28: Validation loss = 0.021912\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 29: Validation loss = 0.039569\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 30: Validation loss = 0.054817\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 31: Validation loss = 0.029247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 32: Validation loss = 0.036667\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 33: Validation loss = 0.173651\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 34: Validation loss = 0.104659\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 35: Validation loss = 0.679776\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 36: Validation loss = 0.504272\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 37: Validation loss = 0.161766\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 38: Validation loss = 0.835539\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 1: Training loss = 0.500502\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 2: Training loss = 0.258614\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 3: Training loss = 1.003888\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 4: Training loss = 0.334597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 5: Training loss = 0.195168\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 6: Training loss = 0.606530\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 7: Training loss = 0.319581\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 8: Training loss = 0.154568\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 9: Training loss = 0.573637\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 10: Training loss = 0.126034\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 11: Training loss = 0.057998\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 12: Training loss = 0.051875\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 13: Training loss = 0.045262\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 14: Training loss = 0.046295\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 15: Training loss = 0.097755\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 16: Training loss = 0.066571\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 17: Training loss = 0.040941\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 18: Training loss = 0.030084\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 19: Training loss = 0.020573\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 20: Training loss = 0.049159\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 21: Training loss = 0.066380\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 22: Training loss = 0.064303\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 23: Training loss = 0.042239\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 24: Training loss = 0.029860\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 25: Training loss = 0.016882\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 26: Training loss = 0.019768\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 27: Training loss = 0.016141\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 28: Training loss = 0.009008\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 29: Training loss = 0.016142\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 30: Training loss = 0.022216\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 31: Training loss = 0.011379\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 32: Training loss = 0.011509\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 33: Training loss = 0.018311\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 34: Training loss = 0.046389\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 35: Training loss = 0.057233\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 36: Training loss = 0.035650\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 37: Training loss = 0.021942\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 38: Training loss = 0.048102\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 39: Training loss = 0.031286\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 40: Training loss = 0.038549\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 41: Training loss = 0.054682\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 42: Training loss = 0.049585\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 43: Training loss = 0.044363\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 44: Training loss = 0.054506\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 45: Training loss = 0.041715\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 46: Training loss = 0.028383\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 47: Training loss = 0.048118\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 48: Training loss = 0.040460\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 49: Training loss = 0.052061\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 50: Training loss = 0.058193\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 51: Training loss = 0.023444\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 52: Training loss = 0.016586\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 53: Training loss = 0.025081\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 54: Training loss = 0.009123\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 55: Training loss = 0.047627\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 56: Training loss = 0.062064\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 57: Training loss = 0.006729\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 58: Training loss = 0.055199\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 59: Training loss = 0.074818\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 60: Training loss = 0.014985\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 61: Training loss = 0.028664\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 62: Training loss = 0.040674\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 63: Training loss = 0.009781\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 64: Training loss = 0.028268\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 65: Training loss = 0.038305\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 66: Training loss = 0.027698\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 67: Training loss = 0.042947\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 68: Training loss = 0.045712\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 69: Training loss = 0.023137\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 70: Training loss = 0.057954\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 71: Training loss = 0.077808\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 72: Training loss = 0.044122\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 73: Training loss = 0.143147\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 74: Training loss = 0.166367\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 75: Training loss = 0.090253\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 76: Training loss = 0.066495\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 77: Training loss = 0.053398\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 78: Training loss = 0.083716\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 79: Training loss = 0.174392\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 80: Training loss = 0.169549\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 81: Training loss = 0.117356\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 82: Training loss = 0.093234\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 83: Training loss = 0.046072\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 84: Training loss = 0.098148\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 85: Training loss = 0.060860\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 86: Training loss = 0.067243\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 87: Training loss = 0.163694\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 88: Training loss = 0.122325\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 89: Training loss = 0.077434\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 90: Training loss = 0.207447\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 91: Training loss = 0.103974\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 92: Training loss = 0.110805\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 93: Training loss = 0.293461\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 94: Training loss = 0.195868\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 95: Training loss = 0.106581\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 96: Training loss = 0.169927\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 97: Training loss = 0.102884\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 98: Training loss = 0.114727\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 99: Training loss = 0.217913\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 100: Training loss = 0.060759\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 101: Training loss = 0.062771\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 102: Training loss = 0.086926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 103: Training loss = 0.052138\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 104: Training loss = 0.080595\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 105: Training loss = 0.117402\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 106: Training loss = 0.073293\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 107: Training loss = 0.045483\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 108: Training loss = 0.069765\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 109: Training loss = 0.041106\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 110: Training loss = 0.095189\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 111: Training loss = 0.057592\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 112: Training loss = 0.056838\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 113: Training loss = 0.060004\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 114: Training loss = 0.065025\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 115: Training loss = 0.080414\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 116: Training loss = 0.089029\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 117: Training loss = 0.082158\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 118: Training loss = 0.080687\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 119: Training loss = 0.086395\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 120: Training loss = 0.070041\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 121: Training loss = 0.067525\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 122: Training loss = 0.072667\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 123: Training loss = 0.056399\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 124: Training loss = 0.050597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 125: Training loss = 0.052176\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 126: Training loss = 0.048730\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 127: Training loss = 0.054910\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 128: Training loss = 0.060684\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 129: Training loss = 0.102527\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 130: Training loss = 0.130398\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 131: Training loss = 0.187789\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 132: Training loss = 0.200003\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 133: Training loss = 0.172327\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 134: Training loss = 0.192804\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 135: Training loss = 0.355906\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 136: Training loss = 0.521276\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 137: Training loss = 0.513503\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 138: Training loss = 1.169660\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 139: Training loss = 0.606630\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 140: Training loss = 0.287224\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 141: Training loss = 0.817943\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 142: Training loss = 0.411289\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 143: Training loss = 0.350959\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 144: Training loss = 1.243177\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 145: Training loss = 0.357829\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 146: Training loss = 0.083584\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 147: Training loss = 0.302879\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 148: Training loss = 0.166612\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 149: Training loss = 0.070215\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 150: Training loss = 0.253614\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 151: Training loss = 0.147354\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 152: Training loss = 0.068290\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 1: Validation loss = 0.112710\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 2: Validation loss = 0.053863\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 3: Validation loss = 0.034230\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 4: Validation loss = 0.034679\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 5: Validation loss = 0.040455\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 6: Validation loss = 0.034948\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 7: Validation loss = 0.035097\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 8: Validation loss = 0.029940\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 9: Validation loss = 0.023253\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 10: Validation loss = 0.026307\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 11: Validation loss = 0.040294\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 12: Validation loss = 0.039500\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 13: Validation loss = 0.058521\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 14: Validation loss = 0.057459\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 15: Validation loss = 0.024454\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 16: Validation loss = 0.067180\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 17: Validation loss = 0.071008\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 18: Validation loss = 0.035829\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 19: Validation loss = 0.070998\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 20: Validation loss = 0.063692\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 21: Validation loss = 0.028853\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 22: Validation loss = 0.055250\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 23: Validation loss = 0.036054\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 24: Validation loss = 0.023886\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 25: Validation loss = 0.034140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 26: Validation loss = 0.050914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 27: Validation loss = 0.034486\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 28: Validation loss = 0.020444\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 29: Validation loss = 0.025761\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 30: Validation loss = 0.017484\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 31: Validation loss = 0.034438\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 32: Validation loss = 0.052590\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 33: Validation loss = 0.090030\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 34: Validation loss = 0.562148\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 35: Validation loss = 0.461548\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 36: Validation loss = 0.142597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 37: Validation loss = 0.638915\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 38: Validation loss = 0.418681\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 1: Training loss = 0.210265\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 2: Training loss = 0.865882\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 3: Training loss = 0.430856\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 4: Training loss = 0.173567\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 5: Training loss = 0.522614\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 6: Training loss = 0.241001\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 7: Training loss = 0.167182\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 8: Training loss = 0.506652\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 9: Training loss = 0.259087\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 10: Training loss = 0.062149\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 11: Training loss = 0.056038\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 12: Training loss = 0.045667\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 13: Training loss = 0.044781\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 14: Training loss = 0.037404\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 15: Training loss = 0.036863\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 16: Training loss = 0.053859\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 17: Training loss = 0.061908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 18: Training loss = 0.043357\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 19: Training loss = 0.035450\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 20: Training loss = 0.024337\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 21: Training loss = 0.021413\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 22: Training loss = 0.039929\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 23: Training loss = 0.042581\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 24: Training loss = 0.034511\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 25: Training loss = 0.027297\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 26: Training loss = 0.017182\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 27: Training loss = 0.013747\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 28: Training loss = 0.011119\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 29: Training loss = 0.018845\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 30: Training loss = 0.011991\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 31: Training loss = 0.013252\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 32: Training loss = 0.018111\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 33: Training loss = 0.013519\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 34: Training loss = 0.024460\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 35: Training loss = 0.016717\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 36: Training loss = 0.034926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 37: Training loss = 0.043394\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 38: Training loss = 0.028673\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 39: Training loss = 0.027342\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 40: Training loss = 0.043412\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 41: Training loss = 0.028477\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 42: Training loss = 0.044773\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 43: Training loss = 0.052068\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 44: Training loss = 0.043389\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 45: Training loss = 0.034362\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 46: Training loss = 0.029741\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 47: Training loss = 0.026536\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 48: Training loss = 0.040514\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 49: Training loss = 0.053719\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 50: Training loss = 0.026757\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 51: Training loss = 0.033714\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 52: Training loss = 0.036921\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 53: Training loss = 0.008794\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 54: Training loss = 0.034313\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 55: Training loss = 0.048935\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 56: Training loss = 0.009024\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 57: Training loss = 0.059981\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 58: Training loss = 0.068179\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 59: Training loss = 0.012743\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 60: Training loss = 0.029861\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 61: Training loss = 0.042649\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 62: Training loss = 0.006012\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 63: Training loss = 0.046224\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 64: Training loss = 0.044888\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 65: Training loss = 0.019134\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 66: Training loss = 0.039206\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 67: Training loss = 0.053168\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 68: Training loss = 0.029926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 69: Training loss = 0.035640\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 70: Training loss = 0.054446\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 71: Training loss = 0.030758\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 72: Training loss = 0.058968\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 73: Training loss = 0.080033\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 74: Training loss = 0.039481\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 75: Training loss = 0.143592\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 76: Training loss = 0.145374\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 77: Training loss = 0.093206\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 78: Training loss = 0.080134\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 79: Training loss = 0.062727\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 80: Training loss = 0.073016\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 81: Training loss = 0.110275\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 82: Training loss = 0.070944\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 83: Training loss = 0.111703\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 84: Training loss = 0.086125\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 85: Training loss = 0.035097\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 86: Training loss = 0.088383\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 87: Training loss = 0.060639\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 88: Training loss = 0.072539\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 89: Training loss = 0.162398\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 90: Training loss = 0.174209\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 91: Training loss = 0.089387\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 92: Training loss = 0.178287\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 93: Training loss = 0.097547\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 94: Training loss = 0.103748\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 95: Training loss = 0.205355\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 96: Training loss = 0.140716\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 97: Training loss = 0.096656\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 98: Training loss = 0.141305\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 99: Training loss = 0.079734\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 100: Training loss = 0.050456\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 101: Training loss = 0.123073\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 102: Training loss = 0.070948\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 103: Training loss = 0.052231\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 104: Training loss = 0.075815\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 105: Training loss = 0.037838\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 106: Training loss = 0.054664\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 107: Training loss = 0.089229\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 108: Training loss = 0.049447\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 109: Training loss = 0.045907\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 110: Training loss = 0.081129\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 111: Training loss = 0.046448\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 112: Training loss = 0.050533\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 113: Training loss = 0.054553\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 114: Training loss = 0.056059\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 115: Training loss = 0.061566\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 116: Training loss = 0.066682\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 117: Training loss = 0.073841\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 118: Training loss = 0.088762\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 119: Training loss = 0.076750\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 120: Training loss = 0.073463\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 121: Training loss = 0.070519\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 122: Training loss = 0.059005\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 123: Training loss = 0.057765\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 124: Training loss = 0.053930\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 125: Training loss = 0.040917\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 126: Training loss = 0.048698\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 127: Training loss = 0.070396\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 128: Training loss = 0.086580\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 129: Training loss = 0.099986\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 130: Training loss = 0.131233\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 131: Training loss = 0.162704\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 132: Training loss = 0.176784\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 133: Training loss = 0.224366\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 134: Training loss = 0.218533\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 135: Training loss = 0.338888\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 136: Training loss = 0.461120\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 137: Training loss = 0.979472\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 138: Training loss = 0.456615\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 139: Training loss = 0.369828\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 140: Training loss = 0.884347\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 141: Training loss = 0.405714\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 142: Training loss = 0.254521\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 143: Training loss = 0.886320\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 144: Training loss = 0.442304\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 145: Training loss = 0.175117\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 146: Training loss = 0.238167\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 147: Training loss = 0.125448\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 148: Training loss = 0.077361\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 149: Training loss = 0.267551\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 150: Training loss = 0.148381\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 151: Training loss = 0.066695\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 152: Training loss = 0.228947\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 1: Validation loss = 0.058414\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 2: Validation loss = 0.030246\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 3: Validation loss = 0.032702\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 4: Validation loss = 0.039304\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 5: Validation loss = 0.034172\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 6: Validation loss = 0.034645\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 7: Validation loss = 0.041033\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 8: Validation loss = 0.033373\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 9: Validation loss = 0.028477\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 10: Validation loss = 0.024335\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 11: Validation loss = 0.024078\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 12: Validation loss = 0.048270\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 13: Validation loss = 0.080435\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 14: Validation loss = 0.038712\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 15: Validation loss = 0.052191\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 16: Validation loss = 0.052625\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 17: Validation loss = 0.025225\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 18: Validation loss = 0.072882\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 19: Validation loss = 0.069093\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 20: Validation loss = 0.026596\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 21: Validation loss = 0.066175\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 22: Validation loss = 0.065088\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 23: Validation loss = 0.028117\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 24: Validation loss = 0.025827\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 25: Validation loss = 0.030717\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 26: Validation loss = 0.021345\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 27: Validation loss = 0.032805\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 28: Validation loss = 0.054861\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 29: Validation loss = 0.032340\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 30: Validation loss = 0.017937\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 31: Validation loss = 0.022199\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 32: Validation loss = 0.010944\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 33: Validation loss = 0.140140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 34: Validation loss = 0.231355\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 35: Validation loss = 0.178203\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 36: Validation loss = 0.734862\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 37: Validation loss = 0.483699\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 38: Validation loss = 0.138725\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 1: Training loss = 0.697080\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 2: Training loss = 0.360337\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 3: Training loss = 0.190220\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 4: Training loss = 0.527156\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 5: Training loss = 0.227889\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 6: Training loss = 0.156935\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 7: Training loss = 0.466643\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 8: Training loss = 0.206767\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 9: Training loss = 0.143242\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 10: Training loss = 0.099613\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 11: Training loss = 0.041717\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 12: Training loss = 0.039010\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 13: Training loss = 0.036689\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 14: Training loss = 0.035873\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 15: Training loss = 0.036538\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 16: Training loss = 0.044348\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 17: Training loss = 0.033273\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 18: Training loss = 0.041020\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 19: Training loss = 0.032335\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 20: Training loss = 0.030723\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 21: Training loss = 0.031535\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 22: Training loss = 0.028413\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 23: Training loss = 0.025068\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 24: Training loss = 0.029856\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 25: Training loss = 0.012368\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 26: Training loss = 0.023182\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 27: Training loss = 0.020333\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 28: Training loss = 0.015016\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 29: Training loss = 0.007193\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 30: Training loss = 0.010181\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 31: Training loss = 0.014568\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 32: Training loss = 0.012356\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 33: Training loss = 0.020452\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 34: Training loss = 0.017731\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 35: Training loss = 0.019372\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 36: Training loss = 0.033397\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 37: Training loss = 0.017649\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 38: Training loss = 0.038159\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 39: Training loss = 0.041526\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 40: Training loss = 0.024117\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Training window 41: Training loss = 0.033877\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 42: Training loss = 0.046667\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 43: Training loss = 0.029173\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 44: Training loss = 0.025470\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 45: Training loss = 0.031398\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 46: Training loss = 0.028244\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 47: Training loss = 0.027701\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 48: Training loss = 0.045741\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 49: Training loss = 0.019785\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 50: Training loss = 0.038229\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 51: Training loss = 0.040118\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 52: Training loss = 0.012830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 53: Training loss = 0.037398\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 54: Training loss = 0.038196\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 55: Training loss = 0.004223\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 56: Training loss = 0.044010\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 57: Training loss = 0.036819\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 58: Training loss = 0.003146\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 59: Training loss = 0.056559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 60: Training loss = 0.058204\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 61: Training loss = 0.002725\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 62: Training loss = 0.037167\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 63: Training loss = 0.029823\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 64: Training loss = 0.010286\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 65: Training loss = 0.047781\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 66: Training loss = 0.035316\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 67: Training loss = 0.019395\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 68: Training loss = 0.043710\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 69: Training loss = 0.043318\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 70: Training loss = 0.025437\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 71: Training loss = 0.090821\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 72: Training loss = 0.103942\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 73: Training loss = 0.026218\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 74: Training loss = 0.081795\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 75: Training loss = 0.055300\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 76: Training loss = 0.089819\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 77: Training loss = 0.148790\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 78: Training loss = 0.106550\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 79: Training loss = 0.089253\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 80: Training loss = 0.064335\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 81: Training loss = 0.049141\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 82: Training loss = 0.079530\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 83: Training loss = 0.044254\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 84: Training loss = 0.062623\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 85: Training loss = 0.134905\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 86: Training loss = 0.082187\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 87: Training loss = 0.049085\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 88: Training loss = 0.082881\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 89: Training loss = 0.048665\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 90: Training loss = 0.261892\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 91: Training loss = 0.386576\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 92: Training loss = 0.163125\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 93: Training loss = 0.087415\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 94: Training loss = 0.123814\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 95: Training loss = 0.059005\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 96: Training loss = 0.188370\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 97: Training loss = 0.251078\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 98: Training loss = 0.119134\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 99: Training loss = 0.078933\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 100: Training loss = 0.049975\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 101: Training loss = 0.042914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 102: Training loss = 0.128374\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 103: Training loss = 0.132706\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 104: Training loss = 0.047143\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 105: Training loss = 0.075098\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 106: Training loss = 0.075316\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 107: Training loss = 0.022419\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 108: Training loss = 0.086624\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 109: Training loss = 0.097082\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 110: Training loss = 0.043641\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 111: Training loss = 0.053403\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 112: Training loss = 0.042000\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 113: Training loss = 0.039403\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 114: Training loss = 0.043204\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 115: Training loss = 0.054087\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 116: Training loss = 0.062865\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 117: Training loss = 0.064253\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 118: Training loss = 0.067553\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 119: Training loss = 0.065719\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 120: Training loss = 0.060690\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 121: Training loss = 0.066487\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 122: Training loss = 0.063379\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 123: Training loss = 0.049659\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 124: Training loss = 0.045230\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 125: Training loss = 0.038082\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 126: Training loss = 0.043406\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 127: Training loss = 0.061597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 128: Training loss = 0.075242\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 129: Training loss = 0.093923\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 130: Training loss = 0.105089\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 131: Training loss = 0.124607\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 132: Training loss = 0.145045\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 133: Training loss = 0.174039\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 134: Training loss = 0.184439\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 135: Training loss = 0.349396\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 136: Training loss = 0.977010\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 137: Training loss = 0.351763\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 138: Training loss = 0.636767\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 139: Training loss = 0.968268\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 140: Training loss = 0.291331\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 141: Training loss = 0.517460\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 142: Training loss = 0.843087\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 143: Training loss = 0.277877\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 144: Training loss = 0.571017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 145: Training loss = 0.881730\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 146: Training loss = 0.113266\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 147: Training loss = 0.101797\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 148: Training loss = 0.248322\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 149: Training loss = 0.093796\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 150: Training loss = 0.127445\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 151: Training loss = 0.280013\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Training window 152: Training loss = 0.105566\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 1: Validation loss = 0.036132\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 2: Validation loss = 0.042374\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 3: Validation loss = 0.029267\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 4: Validation loss = 0.024150\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 5: Validation loss = 0.031070\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 6: Validation loss = 0.026039\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 7: Validation loss = 0.024875\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 8: Validation loss = 0.040459\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 9: Validation loss = 0.037122\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 10: Validation loss = 0.018139\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 11: Validation loss = 0.017318\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 12: Validation loss = 0.019220\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 13: Validation loss = 0.035046\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 14: Validation loss = 0.079068\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 15: Validation loss = 0.054264\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 16: Validation loss = 0.019591\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 17: Validation loss = 0.059565\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 18: Validation loss = 0.047274\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 19: Validation loss = 0.026031\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 20: Validation loss = 0.069275\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 21: Validation loss = 0.048841\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 22: Validation loss = 0.032797\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 23: Validation loss = 0.055963\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 24: Validation loss = 0.040904\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 25: Validation loss = 0.021717\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 26: Validation loss = 0.026935\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 27: Validation loss = 0.020500\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 28: Validation loss = 0.020418\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 29: Validation loss = 0.044266\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 30: Validation loss = 0.040276\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 31: Validation loss = 0.011075\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 32: Validation loss = 0.031838\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 33: Validation loss = 0.141164\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 34: Validation loss = 0.149109\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 35: Validation loss = 0.561982\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 36: Validation loss = 0.283069\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 37: Validation loss = 0.271017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-04-26 13:57:36,718]\u001b[0m Trial 1 finished with value: 0.10556631535291672 and parameters: {'dropout_rate': 0.3067709342329206, 'learning_rate': 0.0031234704646075405, 'activation': 'relu', 'kernel_initializer': None}. Best is trial 0 with value: 0.004662954248487949.\u001b[0m\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Iteration 4, Training window 80: Training loss = 89.954750\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 81: Training loss = 80.488457\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 82: Training loss = 63.932178\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 83: Training loss = 64.487564\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 84: Training loss = 61.224266\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 85: Training loss = 58.092110\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 86: Training loss = 60.287395\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 4, Training window 87: Training loss = 59.386253\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 88: Training loss = 57.175720\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 89: Training loss = 53.751373\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 90: Training loss = 115.512642\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 91: Training loss = 118.317673\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 92: Training loss = 122.676559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 93: Training loss = 124.343605\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 94: Training loss = 129.671173\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 95: Training loss = 132.476547\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 96: Training loss = 133.876358\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 97: Training loss = 133.317154\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 98: Training loss = 135.691986\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 99: Training loss = 138.974365\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 100: Training loss = 77.149002\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 101: Training loss = 93.719933\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 102: Training loss = 92.528877\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 103: Training loss = 90.083466\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 104: Training loss = 88.549454\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 105: Training loss = 87.046875\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 106: Training loss = 88.888664\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 107: Training loss = 90.928352\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 108: Training loss = 90.563004\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 109: Training loss = 90.108742\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 110: Training loss = 91.759163\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 111: Training loss = 76.138626\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 112: Training loss = 76.583359\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 113: Training loss = 78.905647\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 114: Training loss = 78.387260\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 115: Training loss = 75.600113\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 116: Training loss = 70.235207\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 117: Training loss = 65.924301\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 118: Training loss = 61.456146\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 119: Training loss = 56.489952\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 120: Training loss = 50.300755\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 121: Training loss = 43.425968\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 122: Training loss = 35.913956\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 123: Training loss = 28.972672\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 124: Training loss = 23.524879\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 125: Training loss = 20.462862\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 126: Training loss = 18.542946\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 127: Training loss = 17.456352\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 128: Training loss = 15.277362\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 129: Training loss = 14.264643\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 130: Training loss = 13.718979\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 131: Training loss = 14.455052\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 132: Training loss = 15.259342\n","313/313 [==============================] - 0s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 133: Training loss = 15.415123\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 134: Training loss = 15.910967\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 135: Training loss = 597.854736\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 136: Training loss = 1301.879517\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 137: Training loss = 1302.589722\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 138: Training loss = 1304.049561\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 139: Training loss = 1303.495972\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 140: Training loss = 1303.027954\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 141: Training loss = 1301.427734\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 142: Training loss = 1298.770508\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 143: Training loss = 1411.914551\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 144: Training loss = 1417.683350\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 145: Training loss = 847.512878\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 146: Training loss = 161.756958\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 147: Training loss = 161.370346\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 148: Training loss = 158.449280\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 149: Training loss = 154.057098\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 150: Training loss = 150.188461\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 151: Training loss = 146.893143\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 152: Training loss = 145.794708\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 1: Validation loss = 32.695545\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 2: Validation loss = 25.230827\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 3: Validation loss = 26.271635\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 4: Validation loss = 23.783863\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 5: Validation loss = 21.645926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 6: Validation loss = 22.157320\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 7: Validation loss = 24.787647\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 8: Validation loss = 26.412083\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 9: Validation loss = 27.732376\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 10: Validation loss = 29.119055\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 11: Validation loss = 29.983019\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 12: Validation loss = 29.511850\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 13: Validation loss = 27.187904\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 14: Validation loss = 25.488674\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 15: Validation loss = 25.137993\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 16: Validation loss = 24.187361\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 17: Validation loss = 22.842543\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 18: Validation loss = 22.477203\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 19: Validation loss = 22.641056\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 20: Validation loss = 22.721889\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 21: Validation loss = 21.942837\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 22: Validation loss = 21.113876\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 23: Validation loss = 21.496473\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 24: Validation loss = 20.493067\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 25: Validation loss = 17.339787\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 26: Validation loss = 14.818332\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 27: Validation loss = 12.372843\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 28: Validation loss = 10.303156\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 29: Validation loss = 8.433642\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 30: Validation loss = 6.368575\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 31: Validation loss = 6.606888\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 32: Validation loss = 7.215875\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 33: Validation loss = 55.717735\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 34: Validation loss = 296.038147\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 35: Validation loss = 384.511993\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 36: Validation loss = 392.985718\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 37: Validation loss = 393.025665\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 38: Validation loss = 393.238770\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 1: Training loss = 681.406982\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 2: Training loss = 682.364685\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 3: Training loss = 686.534424\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 4: Training loss = 470.456207\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 5: Training loss = 465.511383\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 6: Training loss = 469.958923\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 7: Training loss = 468.355988\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 8: Training loss = 466.257751\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 9: Training loss = 464.467499\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 10: Training loss = 87.162125\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 11: Training loss = 66.951576\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 12: Training loss = 72.584740\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 13: Training loss = 74.575439\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 14: Training loss = 74.270844\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 15: Training loss = 72.505745\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 16: Training loss = 68.234192\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 17: Training loss = 60.950020\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 18: Training loss = 54.814743\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 19: Training loss = 49.764961\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 20: Training loss = 54.698032\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 21: Training loss = 63.622997\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 22: Training loss = 64.961060\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 23: Training loss = 64.363678\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 24: Training loss = 64.606941\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 25: Training loss = 64.478203\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 26: Training loss = 62.574615\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 27: Training loss = 65.100677\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 28: Training loss = 71.175545\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 29: Training loss = 76.623642\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 30: Training loss = 73.586128\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 31: Training loss = 69.423004\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 32: Training loss = 67.806519\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 33: Training loss = 60.663914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 34: Training loss = 56.535366\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 35: Training loss = 54.197296\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 36: Training loss = 60.605408\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 37: Training loss = 65.567795\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 38: Training loss = 67.086845\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 39: Training loss = 69.341629\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 40: Training loss = 73.886414\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 41: Training loss = 77.577332\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 42: Training loss = 78.394035\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 43: Training loss = 82.578575\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 44: Training loss = 81.206169\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 45: Training loss = 80.608696\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 46: Training loss = 77.094345\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 47: Training loss = 68.553474\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 48: Training loss = 63.877331\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 49: Training loss = 57.135632\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 50: Training loss = 53.249256\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 51: Training loss = 47.602470\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 52: Training loss = 40.875301\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 53: Training loss = 36.568295\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 54: Training loss = 34.231342\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 55: Training loss = 31.780899\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 56: Training loss = 27.608707\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 57: Training loss = 28.788750\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 58: Training loss = 25.416849\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 59: Training loss = 23.683519\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 60: Training loss = 21.716732\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 61: Training loss = 26.219347\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 62: Training loss = 32.856998\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 63: Training loss = 39.428661\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 64: Training loss = 47.276577\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 65: Training loss = 54.504395\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 66: Training loss = 55.187286\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 67: Training loss = 55.134064\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 68: Training loss = 56.184578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 69: Training loss = 62.460358\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 70: Training loss = 61.580967\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 71: Training loss = 66.506805\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 72: Training loss = 76.457062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 73: Training loss = 72.177544\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 74: Training loss = 68.623177\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 75: Training loss = 66.740013\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 76: Training loss = 67.361359\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 77: Training loss = 72.755310\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 78: Training loss = 77.955750\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 79: Training loss = 79.543213\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 80: Training loss = 85.592903\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 81: Training loss = 77.200340\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 82: Training loss = 62.080982\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 83: Training loss = 62.595226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 84: Training loss = 59.347908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 85: Training loss = 55.955578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 86: Training loss = 57.727859\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 87: Training loss = 56.501480\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 88: Training loss = 54.087280\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 89: Training loss = 50.285030\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 90: Training loss = 89.269775\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 91: Training loss = 92.309052\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 92: Training loss = 96.756935\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 93: Training loss = 98.581955\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 94: Training loss = 103.854607\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 95: Training loss = 108.396858\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 96: Training loss = 109.841644\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 97: Training loss = 109.322235\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 98: Training loss = 111.942764\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 99: Training loss = 115.888451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 100: Training loss = 76.114204\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 101: Training loss = 84.733452\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 102: Training loss = 84.809685\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 103: Training loss = 82.755592\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 104: Training loss = 81.438667\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 105: Training loss = 80.033768\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 106: Training loss = 82.092773\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 107: Training loss = 84.390724\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 108: Training loss = 84.110954\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 109: Training loss = 83.492653\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 110: Training loss = 84.995621\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 111: Training loss = 76.623924\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 112: Training loss = 75.829483\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 113: Training loss = 77.840797\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 114: Training loss = 76.982391\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 115: Training loss = 73.790298\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 116: Training loss = 67.968948\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 117: Training loss = 63.250778\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 118: Training loss = 58.379108\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 119: Training loss = 53.097282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 120: Training loss = 46.716671\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 121: Training loss = 39.793011\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 122: Training loss = 32.347775\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 123: Training loss = 25.623383\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 124: Training loss = 20.738617\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 125: Training loss = 18.304136\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 126: Training loss = 17.250837\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 127: Training loss = 18.198954\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 128: Training loss = 17.530067\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 129: Training loss = 18.435617\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 130: Training loss = 19.318596\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 131: Training loss = 21.419056\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 132: Training loss = 22.945168\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 133: Training loss = 23.272552\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 134: Training loss = 23.402777\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 135: Training loss = 418.366089\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 136: Training loss = 896.320679\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 137: Training loss = 896.826233\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 138: Training loss = 898.483704\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 139: Training loss = 897.588257\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 140: Training loss = 897.100098\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 141: Training loss = 895.403503\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 142: Training loss = 893.224182\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 143: Training loss = 974.333130\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 144: Training loss = 979.397095\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 145: Training loss = 591.416260\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 146: Training loss = 125.409653\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 147: Training loss = 124.855743\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 148: Training loss = 121.926247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 149: Training loss = 117.617592\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 150: Training loss = 113.994408\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 151: Training loss = 111.135101\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 152: Training loss = 110.585701\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 1: Validation loss = 30.283085\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 2: Validation loss = 25.590645\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 3: Validation loss = 27.353367\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 4: Validation loss = 25.732555\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 5: Validation loss = 24.696154\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 6: Validation loss = 26.339725\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 7: Validation loss = 29.970770\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 8: Validation loss = 32.356186\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 9: Validation loss = 34.187298\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 10: Validation loss = 35.921661\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 11: Validation loss = 37.027351\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 12: Validation loss = 36.549313\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 13: Validation loss = 33.530003\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 14: Validation loss = 30.915745\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 15: Validation loss = 29.454058\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 16: Validation loss = 27.385603\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 17: Validation loss = 25.016893\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 18: Validation loss = 23.739033\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 19: Validation loss = 22.971537\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 20: Validation loss = 22.076918\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 21: Validation loss = 20.409035\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 22: Validation loss = 18.908386\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 23: Validation loss = 19.165598\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 24: Validation loss = 18.243845\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 25: Validation loss = 15.260275\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 26: Validation loss = 12.907921\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 27: Validation loss = 10.669430\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 28: Validation loss = 8.789569\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 29: Validation loss = 7.251086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 30: Validation loss = 5.562563\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 31: Validation loss = 5.908156\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 32: Validation loss = 6.510973\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 33: Validation loss = 42.962040\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 34: Validation loss = 216.612900\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 35: Validation loss = 281.783447\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 36: Validation loss = 288.410126\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 37: Validation loss = 288.381561\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 38: Validation loss = 288.510437\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 1: Training loss = 491.922546\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 2: Training loss = 493.246063\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 3: Training loss = 497.925049\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 4: Training loss = 345.378296\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 5: Training loss = 343.799561\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 6: Training loss = 348.442535\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 7: Training loss = 346.872559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 8: Training loss = 344.808624\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 9: Training loss = 343.454651\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 10: Training loss = 80.909912\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 11: Training loss = 66.913147\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 12: Training loss = 72.822540\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 13: Training loss = 75.122871\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 14: Training loss = 74.874496\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 15: Training loss = 73.058388\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 16: Training loss = 69.237312\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 17: Training loss = 61.836273\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 18: Training loss = 55.593658\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 19: Training loss = 50.365158\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 20: Training loss = 55.534710\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 21: Training loss = 65.003258\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 22: Training loss = 66.149139\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 23: Training loss = 65.227142\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 24: Training loss = 65.584267\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 25: Training loss = 65.668274\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 26: Training loss = 63.464298\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 27: Training loss = 66.193565\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 28: Training loss = 72.519753\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 29: Training loss = 78.258369\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 30: Training loss = 75.080276\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 31: Training loss = 70.428329\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 32: Training loss = 68.720085\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 33: Training loss = 61.116089\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 34: Training loss = 56.038860\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 35: Training loss = 54.414211\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 36: Training loss = 61.672516\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 37: Training loss = 66.707367\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 38: Training loss = 68.130928\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 39: Training loss = 70.109245\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 40: Training loss = 74.559853\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 41: Training loss = 78.212952\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 42: Training loss = 79.101517\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 43: Training loss = 84.151741\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 44: Training loss = 83.668350\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 45: Training loss = 82.263634\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 46: Training loss = 77.660583\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 47: Training loss = 69.021675\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 48: Training loss = 64.472305\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 49: Training loss = 57.595192\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 50: Training loss = 53.550285\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 51: Training loss = 47.826172\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 52: Training loss = 40.918182\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 53: Training loss = 35.919334\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 54: Training loss = 33.386509\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 55: Training loss = 30.863132\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 56: Training loss = 26.850161\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 57: Training loss = 27.935358\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 58: Training loss = 24.367243\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 59: Training loss = 22.656435\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 60: Training loss = 20.740915\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 61: Training loss = 25.243921\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 62: Training loss = 31.892984\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 63: Training loss = 38.523422\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 64: Training loss = 46.330299\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 65: Training loss = 53.480251\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 66: Training loss = 54.187710\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 67: Training loss = 54.163269\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 68: Training loss = 55.159164\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 69: Training loss = 61.421906\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 70: Training loss = 60.615257\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 71: Training loss = 65.503464\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 72: Training loss = 74.925903\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 73: Training loss = 70.691414\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 74: Training loss = 67.108284\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 75: Training loss = 64.330048\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 76: Training loss = 65.203903\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 77: Training loss = 70.773384\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 78: Training loss = 76.089508\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 79: Training loss = 77.737976\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 80: Training loss = 83.780937\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 81: Training loss = 75.593605\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 82: Training loss = 61.032829\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 83: Training loss = 61.391712\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 84: Training loss = 58.307587\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 85: Training loss = 54.891891\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 86: Training loss = 56.380547\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 87: Training loss = 54.811760\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 88: Training loss = 52.138950\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 89: Training loss = 48.020962\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 90: Training loss = 72.761627\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 91: Training loss = 75.801086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 92: Training loss = 80.131645\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 93: Training loss = 81.892227\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 94: Training loss = 86.916428\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 95: Training loss = 92.351456\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 96: Training loss = 93.672241\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 97: Training loss = 93.137749\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 98: Training loss = 95.975136\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 99: Training loss = 100.234436\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 100: Training loss = 74.517143\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 101: Training loss = 79.092491\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 102: Training loss = 79.965897\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 103: Training loss = 77.988785\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 104: Training loss = 76.650406\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 105: Training loss = 75.141029\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 106: Training loss = 77.254219\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 107: Training loss = 79.660385\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 108: Training loss = 79.323540\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 109: Training loss = 78.686081\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 110: Training loss = 80.216194\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 111: Training loss = 75.625282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 112: Training loss = 74.069786\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 113: Training loss = 76.075180\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 114: Training loss = 75.144348\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 115: Training loss = 71.826271\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 116: Training loss = 65.795876\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 117: Training loss = 60.907562\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 118: Training loss = 55.842918\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 119: Training loss = 50.381744\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 120: Training loss = 43.928997\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 121: Training loss = 37.042816\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 122: Training loss = 29.700598\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 123: Training loss = 23.207098\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 124: Training loss = 18.787043\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 125: Training loss = 16.804760\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 126: Training loss = 16.382465\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 127: Training loss = 19.021194\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 128: Training loss = 19.633518\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 129: Training loss = 22.050684\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 130: Training loss = 24.076235\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 131: Training loss = 27.251465\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 132: Training loss = 29.331249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 133: Training loss = 29.833908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 134: Training loss = 29.722195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 135: Training loss = 287.000793\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 136: Training loss = 602.057495\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 137: Training loss = 601.711548\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 138: Training loss = 602.747437\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 139: Training loss = 600.816467\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 140: Training loss = 599.548889\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 141: Training loss = 597.114075\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 142: Training loss = 594.700867\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 143: Training loss = 650.365295\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 144: Training loss = 653.805054\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 145: Training loss = 402.000671\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 146: Training loss = 96.789062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 147: Training loss = 96.074669\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 148: Training loss = 93.090309\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 149: Training loss = 88.857857\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 150: Training loss = 85.448250\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 151: Training loss = 82.917870\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 152: Training loss = 82.698647\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 1: Validation loss = 27.992237\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 2: Validation loss = 25.681738\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 3: Validation loss = 27.749485\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 4: Validation loss = 26.635389\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 5: Validation loss = 26.262434\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 6: Validation loss = 28.627092\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 7: Validation loss = 32.838692\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 8: Validation loss = 35.614414\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 9: Validation loss = 37.716267\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 10: Validation loss = 39.630390\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 11: Validation loss = 40.882389\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 12: Validation loss = 40.369236\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 13: Validation loss = 36.936268\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 14: Validation loss = 33.755360\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Validation window 15: Validation loss = 31.617321\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 16: Validation loss = 28.828331\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 17: Validation loss = 25.834749\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 18: Validation loss = 24.024136\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 19: Validation loss = 22.656124\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 20: Validation loss = 21.172556\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 21: Validation loss = 18.973228\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 22: Validation loss = 17.144028\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 23: Validation loss = 17.389114\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 24: Validation loss = 16.598249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 25: Validation loss = 13.817698\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 26: Validation loss = 11.663001\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 27: Validation loss = 9.635073\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 28: Validation loss = 7.931378\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 29: Validation loss = 6.655078\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 30: Validation loss = 5.237287\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 31: Validation loss = 5.636609\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 32: Validation loss = 6.180335\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 33: Validation loss = 32.015690\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 34: Validation loss = 150.958466\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 35: Validation loss = 196.064819\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 36: Validation loss = 200.659760\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 37: Validation loss = 200.687744\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 38: Validation loss = 200.828934\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 1: Training loss = 341.217529\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 2: Training loss = 342.941132\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 3: Training loss = 348.141479\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 4: Training loss = 246.904007\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 5: Training loss = 248.324661\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 6: Training loss = 253.091858\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 7: Training loss = 251.616409\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 8: Training loss = 249.648224\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 9: Training loss = 248.674500\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 10: Training loss = 76.079185\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 11: Training loss = 66.815857\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 12: Training loss = 72.764122\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 13: Training loss = 75.317970\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 14: Training loss = 75.024918\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 15: Training loss = 73.329559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 16: Training loss = 69.717850\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 17: Training loss = 62.272537\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 18: Training loss = 55.971882\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 19: Training loss = 50.521236\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 20: Training loss = 55.885361\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 21: Training loss = 65.857986\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 22: Training loss = 66.939705\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 23: Training loss = 65.726891\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 24: Training loss = 66.254585\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 25: Training loss = 66.344589\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 26: Training loss = 63.900810\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 27: Training loss = 66.631706\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 28: Training loss = 73.048363\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 29: Training loss = 79.056610\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 30: Training loss = 75.680626\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 31: Training loss = 70.458511\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 32: Training loss = 68.627861\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 33: Training loss = 60.694691\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 34: Training loss = 54.934258\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 35: Training loss = 53.867867\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 36: Training loss = 61.863647\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 37: Training loss = 66.916779\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 38: Training loss = 68.276947\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 39: Training loss = 70.086655\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 40: Training loss = 74.650269\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 41: Training loss = 78.411446\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 42: Training loss = 79.364136\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 43: Training loss = 84.996437\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 44: Training loss = 85.054260\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 45: Training loss = 82.900269\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 46: Training loss = 77.373894\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 47: Training loss = 68.836586\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 48: Training loss = 64.453064\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 49: Training loss = 57.425568\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 50: Training loss = 53.128613\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 51: Training loss = 47.253418\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 52: Training loss = 40.161491\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 53: Training loss = 34.650551\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 54: Training loss = 32.061359\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 55: Training loss = 29.569490\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 56: Training loss = 25.760485\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 57: Training loss = 26.722357\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 58: Training loss = 23.002295\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 59: Training loss = 21.320795\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 60: Training loss = 19.477715\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 61: Training loss = 23.952307\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 62: Training loss = 30.633726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 63: Training loss = 37.310917\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 64: Training loss = 45.079697\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 65: Training loss = 52.159233\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 66: Training loss = 52.912720\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 67: Training loss = 52.938156\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 68: Training loss = 53.884945\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 69: Training loss = 60.075386\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 70: Training loss = 59.340820\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 71: Training loss = 64.117714\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 72: Training loss = 72.848259\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 73: Training loss = 68.647133\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 74: Training loss = 65.059807\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 75: Training loss = 61.666229\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 76: Training loss = 62.794289\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 77: Training loss = 68.571716\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 78: Training loss = 74.043427\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 79: Training loss = 75.827499\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 80: Training loss = 81.932800\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 81: Training loss = 74.148560\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 82: Training loss = 60.392365\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 83: Training loss = 60.710606\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 84: Training loss = 57.845905\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 85: Training loss = 54.475475\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 86: Training loss = 55.738972\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 87: Training loss = 53.786106\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 88: Training loss = 50.820263\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 89: Training loss = 46.387299\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 90: Training loss = 60.169739\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 91: Training loss = 63.156368\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 92: Training loss = 67.320724\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 93: Training loss = 68.958351\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 94: Training loss = 73.690201\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 95: Training loss = 79.707336\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 96: Training loss = 80.871361\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 97: Training loss = 80.367752\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 98: Training loss = 83.456558\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 99: Training loss = 87.971428\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 100: Training loss = 72.920555\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 101: Training loss = 74.911522\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 102: Training loss = 76.484276\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 103: Training loss = 74.521660\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 104: Training loss = 73.100258\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 105: Training loss = 71.423920\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 106: Training loss = 73.525528\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 107: Training loss = 75.970947\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 108: Training loss = 75.529449\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 109: Training loss = 74.914795\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 110: Training loss = 76.511673\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 111: Training loss = 74.284111\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 112: Training loss = 72.088669\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 113: Training loss = 74.165375\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 114: Training loss = 73.251701\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 115: Training loss = 69.902000\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 116: Training loss = 63.769695\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 117: Training loss = 58.799351\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 118: Training loss = 53.629513\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 119: Training loss = 48.063278\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 120: Training loss = 41.622849\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 121: Training loss = 34.819786\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 122: Training loss = 27.581678\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 123: Training loss = 21.268347\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 124: Training loss = 17.199213\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 125: Training loss = 15.552888\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 126: Training loss = 15.643332\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 127: Training loss = 19.938950\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 128: Training loss = 21.777586\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 129: Training loss = 25.585701\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 130: Training loss = 28.672970\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 131: Training loss = 32.829582\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 132: Training loss = 35.428165\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 133: Training loss = 36.163044\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 134: Training loss = 35.925629\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 135: Training loss = 193.674484\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 136: Training loss = 388.673370\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 137: Training loss = 387.352478\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 138: Training loss = 387.777496\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 139: Training loss = 384.940918\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 140: Training loss = 382.974426\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 141: Training loss = 379.897522\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 142: Training loss = 377.310059\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 143: Training loss = 413.363525\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 144: Training loss = 415.719116\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 145: Training loss = 261.951477\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 146: Training loss = 74.618256\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 147: Training loss = 73.786057\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 148: Training loss = 70.770424\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 149: Training loss = 66.649445\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 150: Training loss = 63.451855\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 151: Training loss = 61.170456\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 152: Training loss = 61.140247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 1: Validation loss = 26.013109\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 2: Validation loss = 25.295698\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 3: Validation loss = 27.347815\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 4: Validation loss = 26.426701\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 5: Validation loss = 26.364487\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 6: Validation loss = 29.071474\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 7: Validation loss = 33.532066\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 8: Validation loss = 36.381653\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 9: Validation loss = 38.593822\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 10: Validation loss = 40.562401\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 11: Validation loss = 41.875824\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 12: Validation loss = 41.403408\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 13: Validation loss = 37.873096\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 14: Validation loss = 34.444427\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 15: Validation loss = 31.965151\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 16: Validation loss = 28.806416\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 17: Validation loss = 25.489861\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 18: Validation loss = 23.476969\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 19: Validation loss = 21.766018\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 20: Validation loss = 19.987730\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 21: Validation loss = 17.565969\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 22: Validation loss = 15.622452\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 23: Validation loss = 15.874516\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 24: Validation loss = 15.252436\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 25: Validation loss = 12.718807\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 26: Validation loss = 10.794906\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 27: Validation loss = 8.979025\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 28: Validation loss = 7.436356\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 29: Validation loss = 6.381401\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 30: Validation loss = 5.189962\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 31: Validation loss = 5.582072\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Validation window 32: Validation loss = 6.028901\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 33: Validation loss = 23.659664\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 34: Validation loss = 101.377876\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 35: Validation loss = 131.532700\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 36: Validation loss = 134.726517\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 37: Validation loss = 134.805511\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 38: Validation loss = 134.980621\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 1: Training loss = 230.085876\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 2: Training loss = 232.146057\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 3: Training loss = 237.796173\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 4: Training loss = 175.098724\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 5: Training loss = 178.672958\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 6: Training loss = 183.516937\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 7: Training loss = 182.179657\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 8: Training loss = 180.298828\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 9: Training loss = 179.539810\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 10: Training loss = 71.634201\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 11: Training loss = 65.750725\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 12: Training loss = 71.510201\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 13: Training loss = 74.238876\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 14: Training loss = 73.783203\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 15: Training loss = 72.287956\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 16: Training loss = 68.681877\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 17: Training loss = 61.305340\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 18: Training loss = 55.073578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 19: Training loss = 49.465416\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 20: Training loss = 54.859680\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 21: Training loss = 65.091751\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 22: Training loss = 66.205017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 23: Training loss = 64.714081\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 24: Training loss = 65.440491\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 25: Training loss = 65.368500\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 26: Training loss = 62.743935\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 27: Training loss = 65.167587\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 28: Training loss = 71.324440\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 29: Training loss = 77.466095\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 30: Training loss = 73.869736\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 31: Training loss = 68.053864\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 32: Training loss = 66.074425\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 33: Training loss = 58.141327\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 34: Training loss = 52.171066\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 35: Training loss = 51.403732\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 36: Training loss = 59.847191\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 37: Training loss = 64.764755\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 38: Training loss = 66.075096\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 39: Training loss = 67.794823\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 40: Training loss = 72.633766\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 41: Training loss = 76.652229\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 42: Training loss = 77.611282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 43: Training loss = 83.205421\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 44: Training loss = 83.157608\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 45: Training loss = 80.409103\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 46: Training loss = 74.305656\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 47: Training loss = 66.313591\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 48: Training loss = 62.504951\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 49: Training loss = 55.443756\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 50: Training loss = 50.830151\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 51: Training loss = 44.721092\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 52: Training loss = 37.518787\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 53: Training loss = 31.878820\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 54: Training loss = 29.544167\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 55: Training loss = 27.442720\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 56: Training loss = 24.032948\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 57: Training loss = 24.836987\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 58: Training loss = 20.776804\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 59: Training loss = 19.148151\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 60: Training loss = 17.431467\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 61: Training loss = 21.819193\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 62: Training loss = 28.502867\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 63: Training loss = 35.066990\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 64: Training loss = 42.568825\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 65: Training loss = 49.347404\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 66: Training loss = 50.167431\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 67: Training loss = 50.240471\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 68: Training loss = 51.084686\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 69: Training loss = 56.928440\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 70: Training loss = 56.569042\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 71: Training loss = 61.819038\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 72: Training loss = 70.368637\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 73: Training loss = 66.519775\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 74: Training loss = 63.076889\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 75: Training loss = 59.444111\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 76: Training loss = 60.593933\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 77: Training loss = 66.319817\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 78: Training loss = 71.823547\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 79: Training loss = 73.838936\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 80: Training loss = 79.702591\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 81: Training loss = 71.932175\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 82: Training loss = 58.650124\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 83: Training loss = 58.720417\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 84: Training loss = 56.001301\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 85: Training loss = 52.727844\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 86: Training loss = 53.821075\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 87: Training loss = 51.579830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 88: Training loss = 48.415031\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 89: Training loss = 43.779091\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 90: Training loss = 50.206810\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 91: Training loss = 53.009007\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 92: Training loss = 56.980404\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 93: Training loss = 58.509998\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 94: Training loss = 62.971523\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 95: Training loss = 69.163910\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 96: Training loss = 70.216064\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 97: Training loss = 69.783913\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 98: Training loss = 73.047905\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 99: Training loss = 77.583977\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 100: Training loss = 69.509262\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 101: Training loss = 70.112335\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 102: Training loss = 72.078659\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 103: Training loss = 70.026588\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 104: Training loss = 68.441589\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 105: Training loss = 66.546936\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 106: Training loss = 68.534706\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 107: Training loss = 70.933601\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 108: Training loss = 70.380310\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 109: Training loss = 69.911011\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 110: Training loss = 71.644417\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 111: Training loss = 70.755379\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 112: Training loss = 68.231773\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 113: Training loss = 70.485252\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 114: Training loss = 69.735870\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 115: Training loss = 66.540939\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 116: Training loss = 60.553696\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 117: Training loss = 55.706295\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 118: Training loss = 50.635315\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 119: Training loss = 45.152615\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 120: Training loss = 38.919483\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 121: Training loss = 32.355709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 122: Training loss = 25.405630\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 123: Training loss = 19.384302\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 124: Training loss = 15.690653\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 125: Training loss = 14.330971\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 126: Training loss = 14.870369\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 127: Training loss = 20.799314\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 128: Training loss = 23.774878\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 129: Training loss = 28.909361\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 130: Training loss = 33.019283\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 131: Training loss = 38.112640\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 132: Training loss = 41.146542\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 133: Training loss = 42.131451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 134: Training loss = 41.813370\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 135: Training loss = 132.359589\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 136: Training loss = 246.618866\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 137: Training loss = 243.950302\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 138: Training loss = 243.530548\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 139: Training loss = 239.563202\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 140: Training loss = 236.677475\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 141: Training loss = 232.831360\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 142: Training loss = 230.053635\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 143: Training loss = 252.551376\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 144: Training loss = 254.161316\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 145: Training loss = 166.501663\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 146: Training loss = 58.169819\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 147: Training loss = 57.365662\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 148: Training loss = 54.430016\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 149: Training loss = 50.531784\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 150: Training loss = 47.611279\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 151: Training loss = 45.580021\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 152: Training loss = 45.683456\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 1: Validation loss = 23.980894\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 2: Validation loss = 24.192060\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 3: Validation loss = 26.230417\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 4: Validation loss = 25.523579\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 5: Validation loss = 25.736427\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 6: Validation loss = 28.662226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 7: Validation loss = 33.279015\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 8: Validation loss = 36.071144\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 9: Validation loss = 38.316059\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 10: Validation loss = 40.259678\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 11: Validation loss = 41.609890\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 12: Validation loss = 41.272987\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 13: Validation loss = 37.805782\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 14: Validation loss = 34.195080\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 15: Validation loss = 31.418749\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 16: Validation loss = 27.999790\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 17: Validation loss = 24.421072\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 18: Validation loss = 22.329584\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 19: Validation loss = 20.380308\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 20: Validation loss = 18.454563\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 21: Validation loss = 15.952104\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 22: Validation loss = 13.999221\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 23: Validation loss = 14.251564\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 24: Validation loss = 13.896207\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 25: Validation loss = 11.742714\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 26: Validation loss = 10.146695\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 27: Validation loss = 8.580680\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 28: Validation loss = 7.227108\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 29: Validation loss = 6.412607\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 30: Validation loss = 5.471236\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 31: Validation loss = 5.788545\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 32: Validation loss = 6.082907\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 33: Validation loss = 17.796223\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 34: Validation loss = 66.110352\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 35: Validation loss = 85.438782\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 36: Validation loss = 87.655022\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 37: Validation loss = 87.713013\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 38: Validation loss = 87.934029\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 1: Training loss = 152.434708\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 2: Training loss = 154.635559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 3: Training loss = 160.541092\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 4: Training loss = 124.811707\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 5: Training loss = 129.687973\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 6: Training loss = 134.535614\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 7: Training loss = 133.335770\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 8: Training loss = 131.468842\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 9: Training loss = 130.702942\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 10: Training loss = 66.817589\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 11: Training loss = 63.123062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 12: Training loss = 68.579765\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 13: Training loss = 71.432236\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 14: Training loss = 70.768433\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 15: Training loss = 69.537788\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 16: Training loss = 65.915359\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 17: Training loss = 58.770084\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 18: Training loss = 52.742271\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 19: Training loss = 47.142017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 20: Training loss = 52.422195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 21: Training loss = 62.642319\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 22: Training loss = 63.829811\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 23: Training loss = 62.128773\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 24: Training loss = 63.054871\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 25: Training loss = 62.750572\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 26: Training loss = 60.040440\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 27: Training loss = 62.062183\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 28: Training loss = 67.843025\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 29: Training loss = 73.979340\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 30: Training loss = 70.249092\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 31: Training loss = 64.015320\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 32: Training loss = 61.951679\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 33: Training loss = 54.232845\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 34: Training loss = 48.325161\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 35: Training loss = 47.865513\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 36: Training loss = 56.552284\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 37: Training loss = 61.252502\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 38: Training loss = 62.513760\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 39: Training loss = 64.188629\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 40: Training loss = 69.290756\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 41: Training loss = 73.545288\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 42: Training loss = 74.523903\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 43: Training loss = 79.942978\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 44: Training loss = 79.700493\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 45: Training loss = 76.461952\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 46: Training loss = 69.934570\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 47: Training loss = 62.692299\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 48: Training loss = 59.450695\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 49: Training loss = 52.484280\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 50: Training loss = 47.604454\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 51: Training loss = 41.314892\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 52: Training loss = 34.116489\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 53: Training loss = 28.469475\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 1ms/step\n","Iteration 9, Training window 54: Training loss = 26.429340\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 55: Training loss = 24.746824\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 56: Training loss = 21.826796\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 57: Training loss = 22.431911\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 58: Training loss = 18.189363\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 59: Training loss = 16.641602\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 60: Training loss = 15.091613\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 61: Training loss = 19.387730\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 62: Training loss = 25.991993\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 63: Training loss = 32.374249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 64: Training loss = 39.544899\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 65: Training loss = 45.969856\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 66: Training loss = 46.884697\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 67: Training loss = 47.038532\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 68: Training loss = 47.796719\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 69: Training loss = 53.229706\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 70: Training loss = 53.203640\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 71: Training loss = 58.526882\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 72: Training loss = 66.423096\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 73: Training loss = 62.895199\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 74: Training loss = 59.668953\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 75: Training loss = 56.021137\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 76: Training loss = 57.107655\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 77: Training loss = 62.691982\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 78: Training loss = 68.159073\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 79: Training loss = 70.393661\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 80: Training loss = 76.016769\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 81: Training loss = 68.621391\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 82: Training loss = 56.299252\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 83: Training loss = 56.182842\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 84: Training loss = 53.576893\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 85: Training loss = 50.437424\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 86: Training loss = 51.400787\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 87: Training loss = 48.923336\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 88: Training loss = 45.643524\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 89: Training loss = 40.924595\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 90: Training loss = 42.520870\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 91: Training loss = 45.138504\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 92: Training loss = 48.888958\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 93: Training loss = 50.344662\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 94: Training loss = 54.549896\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 95: Training loss = 60.721333\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 96: Training loss = 61.690651\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 97: Training loss = 61.366688\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 98: Training loss = 64.721825\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 99: Training loss = 69.190636\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 100: Training loss = 65.658157\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 101: Training loss = 65.563713\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 102: Training loss = 67.921997\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 103: Training loss = 65.781105\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 104: Training loss = 64.042366\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 105: Training loss = 61.919281\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 106: Training loss = 63.755100\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 107: Training loss = 66.061943\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 108: Training loss = 65.408272\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 109: Training loss = 65.069283\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 110: Training loss = 66.933228\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 111: Training loss = 66.733925\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 112: Training loss = 63.882824\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 113: Training loss = 66.318222\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 114: Training loss = 65.814560\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 115: Training loss = 62.931889\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 116: Training loss = 57.260891\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 117: Training loss = 52.700432\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 118: Training loss = 47.899818\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 119: Training loss = 42.632336\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 120: Training loss = 36.707623\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 121: Training loss = 30.469608\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 122: Training loss = 23.880013\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 123: Training loss = 18.155184\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 124: Training loss = 14.717350\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 125: Training loss = 13.464599\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 126: Training loss = 14.215158\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 127: Training loss = 21.305449\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 128: Training loss = 24.915012\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 129: Training loss = 30.897066\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 130: Training loss = 35.608597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 131: Training loss = 41.263966\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 132: Training loss = 44.428005\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 133: Training loss = 45.592903\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 134: Training loss = 45.278168\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 135: Training loss = 93.547607\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 136: Training loss = 155.523911\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 137: Training loss = 151.744614\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 138: Training loss = 150.813293\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 139: Training loss = 146.228561\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 140: Training loss = 142.928787\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 141: Training loss = 138.665710\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 142: Training loss = 135.867142\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 143: Training loss = 148.880249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 144: Training loss = 149.970779\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 145: Training loss = 103.726906\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 146: Training loss = 46.185406\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 147: Training loss = 45.405708\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 148: Training loss = 42.600109\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 149: Training loss = 38.943775\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 150: Training loss = 36.281612\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 151: Training loss = 34.436127\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 152: Training loss = 34.528862\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 1: Validation loss = 22.025661\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 2: Validation loss = 22.714045\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 3: Validation loss = 24.598631\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 4: Validation loss = 23.960039\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 5: Validation loss = 24.271887\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 6: Validation loss = 27.219345\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 7: Validation loss = 31.847843\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 8: Validation loss = 34.435822\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 9: Validation loss = 36.605156\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 10: Validation loss = 38.480232\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 11: Validation loss = 39.857422\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 12: Validation loss = 39.724266\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 13: Validation loss = 36.513878\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 14: Validation loss = 32.918259\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 15: Validation loss = 30.035723\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 16: Validation loss = 26.548571\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 17: Validation loss = 22.860886\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 18: Validation loss = 20.880062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 19: Validation loss = 18.888380\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 20: Validation loss = 17.027319\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 21: Validation loss = 14.623207\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 22: Validation loss = 12.809802\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 23: Validation loss = 13.073175\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 24: Validation loss = 12.975698\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 25: Validation loss = 11.199887\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 26: Validation loss = 9.899299\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 27: Validation loss = 8.550756\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 28: Validation loss = 7.349212\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 29: Validation loss = 6.712400\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 30: Validation loss = 5.940624\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 31: Validation loss = 6.146863\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 32: Validation loss = 6.290022\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 33: Validation loss = 13.584875\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 34: Validation loss = 41.641914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 35: Validation loss = 53.262196\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 36: Validation loss = 54.674809\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 37: Validation loss = 54.709469\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 38: Validation loss = 55.055248\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 1: Training loss = 101.128136\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 2: Training loss = 103.388298\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 3: Training loss = 109.498299\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 4: Training loss = 92.027992\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 5: Training loss = 97.709160\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 6: Training loss = 102.469910\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 7: Training loss = 101.380463\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 8: Training loss = 99.544853\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 9: Training loss = 98.735672\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 10: Training loss = 62.575298\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 11: Training loss = 60.405689\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 12: Training loss = 65.623100\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 13: Training loss = 68.608490\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 14: Training loss = 67.791481\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 15: Training loss = 66.911636\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 16: Training loss = 63.419296\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 17: Training loss = 56.579720\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 18: Training loss = 50.830177\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 19: Training loss = 45.291039\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 20: Training loss = 50.456108\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 21: Training loss = 60.604740\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 22: Training loss = 61.815266\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 23: Training loss = 59.886318\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 24: Training loss = 60.965996\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 25: Training loss = 60.392345\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 26: Training loss = 57.588837\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 27: Training loss = 59.272247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 28: Training loss = 64.684807\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 29: Training loss = 70.821465\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 30: Training loss = 67.010071\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 31: Training loss = 60.497112\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 32: Training loss = 58.401733\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 33: Training loss = 50.957825\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 34: Training loss = 45.160378\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 35: Training loss = 44.982311\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 36: Training loss = 53.881287\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 37: Training loss = 58.362118\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 38: Training loss = 59.543312\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 39: Training loss = 61.065247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 40: Training loss = 66.261200\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 41: Training loss = 70.619789\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 42: Training loss = 71.596565\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 43: Training loss = 76.845116\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 44: Training loss = 76.511551\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 45: Training loss = 72.899673\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 46: Training loss = 65.928947\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 47: Training loss = 59.371128\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 48: Training loss = 56.633991\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 49: Training loss = 49.822182\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 50: Training loss = 44.769207\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 51: Training loss = 38.422096\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 52: Training loss = 31.309715\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 53: Training loss = 25.669701\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 54: Training loss = 23.844942\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 55: Training loss = 22.510906\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 56: Training loss = 20.057184\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 57: Training loss = 20.466021\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 58: Training loss = 16.121273\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 59: Training loss = 14.658198\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 60: Training loss = 13.263716\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 61: Training loss = 17.424915\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 62: Training loss = 23.872988\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 63: Training loss = 30.026114\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 64: Training loss = 36.818531\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 65: Training loss = 42.844185\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 66: Training loss = 43.835030\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 67: Training loss = 44.065151\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 68: Training loss = 44.745213\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 69: Training loss = 49.788536\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 70: Training loss = 50.085262\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 71: Training loss = 55.379246\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 72: Training loss = 62.543209\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 73: Training loss = 59.319225\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 74: Training loss = 56.321041\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 75: Training loss = 52.748585\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 76: Training loss = 53.778694\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 77: Training loss = 59.199631\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 78: Training loss = 64.577644\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 79: Training loss = 66.948586\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 80: Training loss = 72.243805\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 81: Training loss = 65.268532\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 82: Training loss = 53.977921\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 83: Training loss = 53.695717\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 84: Training loss = 51.217918\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 85: Training loss = 48.230946\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 86: Training loss = 49.044384\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 87: Training loss = 46.363102\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 88: Training loss = 43.040920\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 89: Training loss = 38.327221\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 90: Training loss = 36.864693\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 91: Training loss = 39.306496\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 92: Training loss = 42.821781\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 93: Training loss = 44.211010\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 94: Training loss = 48.149307\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 95: Training loss = 54.210400\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 96: Training loss = 55.130886\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 97: Training loss = 54.918800\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 98: Training loss = 58.288040\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 99: Training loss = 62.641148\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 100: Training loss = 61.993534\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 101: Training loss = 61.686756\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 102: Training loss = 64.420677\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 103: Training loss = 62.235348\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 104: Training loss = 60.372738\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 105: Training loss = 58.050720\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 106: Training loss = 59.700756\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 107: Training loss = 61.870155\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 108: Training loss = 61.132938\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 109: Training loss = 60.892162\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 110: Training loss = 62.831062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 111: Training loss = 62.828979\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 112: Training loss = 59.668816\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 113: Training loss = 62.236458\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 114: Training loss = 61.994419\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 115: Training loss = 59.474949\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 116: Training loss = 54.202400\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 117: Training loss = 50.005428\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 118: Training loss = 45.561378\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 119: Training loss = 40.593414\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 120: Training loss = 35.045086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 121: Training loss = 29.171167\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 122: Training loss = 22.956942\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 123: Training loss = 17.500341\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 124: Training loss = 14.198282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 125: Training loss = 12.921070\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 126: Training loss = 13.620914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 127: Training loss = 21.093788\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 128: Training loss = 24.816977\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 129: Training loss = 30.899284\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 130: Training loss = 35.658619\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 131: Training loss = 41.275249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 132: Training loss = 44.270679\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 133: Training loss = 45.476723\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 134: Training loss = 45.250271\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 135: Training loss = 70.299011\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 136: Training loss = 102.394966\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 137: Training loss = 98.176285\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 138: Training loss = 97.101250\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 139: Training loss = 92.469048\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 140: Training loss = 89.109840\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 141: Training loss = 84.940422\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 142: Training loss = 82.433838\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 143: Training loss = 89.238922\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 144: Training loss = 89.898659\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 145: Training loss = 66.365280\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 146: Training loss = 37.789688\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 147: Training loss = 37.065712\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 148: Training loss = 34.437939\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 149: Training loss = 30.999598\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 150: Training loss = 28.520281\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 151: Training loss = 26.753700\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 152: Training loss = 26.702219\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 1: Validation loss = 20.194843\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 2: Validation loss = 20.984444\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 3: Validation loss = 22.541473\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 4: Validation loss = 21.758928\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Validation window 5: Validation loss = 21.872877\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 6: Validation loss = 24.524807\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 7: Validation loss = 28.885651\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 8: Validation loss = 31.093317\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 9: Validation loss = 33.040813\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 10: Validation loss = 34.761959\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 11: Validation loss = 36.108040\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 12: Validation loss = 36.205841\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 13: Validation loss = 33.416882\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 14: Validation loss = 30.102621\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 15: Validation loss = 27.439003\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 16: Validation loss = 24.210859\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 17: Validation loss = 20.727940\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 18: Validation loss = 19.083416\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 19: Validation loss = 17.291231\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 20: Validation loss = 15.760821\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 21: Validation loss = 13.672621\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 22: Validation loss = 12.164108\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 23: Validation loss = 12.453982\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 3ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 24: Validation loss = 12.529355\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 25: Validation loss = 11.037490\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 26: Validation loss = 9.926704\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 27: Validation loss = 8.721135\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 28: Validation loss = 7.597020\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 29: Validation loss = 7.019884\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 30: Validation loss = 6.249864\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 31: Validation loss = 6.314062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Validation window 32: Validation loss = 6.335289\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 33: Validation loss = 10.505211\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 34: Validation loss = 25.814095\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 35: Validation loss = 32.473274\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 36: Validation loss = 33.293407\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 37: Validation loss = 33.353081\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-04-26 14:44:09,581]\u001b[0m Trial 2 finished with value: 26.702219009399414 and parameters: {'dropout_rate': 0.4245357537546656, 'learning_rate': 2.1719847499079514e-05, 'activation': 'relu', 'kernel_initializer': 'he_normal'}. Best is trial 0 with value: 0.004662954248487949.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 81: Training loss = 55.171871\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 82: Training loss = 57.515022\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 83: Training loss = 60.495121\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 84: Training loss = 57.091385\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 85: Training loss = 54.851124\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 86: Training loss = 52.880531\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 87: Training loss = 53.818336\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 88: Training loss = 54.135815\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 89: Training loss = 54.723209\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 90: Training loss = 50.867767\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 91: Training loss = 53.465160\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 92: Training loss = 57.561382\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 93: Training loss = 60.031387\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 94: Training loss = 65.394119\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 95: Training loss = 70.653313\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 96: Training loss = 75.138702\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 97: Training loss = 75.013580\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 98: Training loss = 74.128349\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 99: Training loss = 74.402672\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 100: Training loss = 77.546181\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 101: Training loss = 80.221123\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 102: Training loss = 81.465790\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 103: Training loss = 78.909904\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 104: Training loss = 76.978806\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 105: Training loss = 75.216827\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 106: Training loss = 74.800301\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 107: Training loss = 74.377365\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 108: Training loss = 74.588470\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 109: Training loss = 73.377121\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 4, Training window 110: Training loss = 73.881233\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 111: Training loss = 71.093620\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 112: Training loss = 69.379776\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 113: Training loss = 71.568443\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 114: Training loss = 73.530449\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 115: Training loss = 75.641289\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 116: Training loss = 76.260559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 117: Training loss = 77.344849\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 118: Training loss = 78.189232\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 119: Training loss = 77.126175\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 120: Training loss = 74.543846\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 121: Training loss = 70.940712\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 122: Training loss = 66.690964\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 123: Training loss = 61.666718\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 124: Training loss = 58.069878\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 125: Training loss = 51.281300\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 126: Training loss = 46.163719\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 127: Training loss = 42.722950\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 128: Training loss = 39.611244\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 129: Training loss = 37.783741\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 130: Training loss = 37.692955\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 131: Training loss = 38.769184\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 132: Training loss = 40.333649\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 133: Training loss = 43.575108\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 134: Training loss = 44.093876\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 135: Training loss = 47.867809\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 136: Training loss = 51.689030\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 137: Training loss = 52.747280\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 138: Training loss = 55.643597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 139: Training loss = 60.628483\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 140: Training loss = 64.150772\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 141: Training loss = 66.289963\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 142: Training loss = 66.534088\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 143: Training loss = 62.453026\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 144: Training loss = 59.243671\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 145: Training loss = 55.179466\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 146: Training loss = 57.176262\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 147: Training loss = 59.103092\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 148: Training loss = 59.541142\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 149: Training loss = 57.886787\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 150: Training loss = 52.988125\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 4, Training window 151: Training loss = 49.888191\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 152: Training loss = 51.309528\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 1: Validation loss = 57.966476\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 2: Validation loss = 64.852783\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 3: Validation loss = 78.650887\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 4: Validation loss = 90.145279\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 5: Validation loss = 108.952332\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 6: Validation loss = 128.446106\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 7: Validation loss = 147.238083\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 8: Validation loss = 160.341278\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 9: Validation loss = 169.585098\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 10: Validation loss = 177.445007\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 11: Validation loss = 184.747314\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 12: Validation loss = 187.115265\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 13: Validation loss = 177.679077\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 14: Validation loss = 168.569687\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 15: Validation loss = 152.048706\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 16: Validation loss = 136.637100\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 17: Validation loss = 120.073784\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 18: Validation loss = 111.921066\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 19: Validation loss = 101.579903\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 20: Validation loss = 91.246239\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 21: Validation loss = 80.036240\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 22: Validation loss = 71.411644\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 23: Validation loss = 67.543449\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 24: Validation loss = 58.946308\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 25: Validation loss = 50.865704\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 4, Validation window 26: Validation loss = 40.092785\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 4, Validation window 27: Validation loss = 31.243803\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 28: Validation loss = 23.713789\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 29: Validation loss = 20.958864\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 30: Validation loss = 17.826982\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 31: Validation loss = 17.514559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 32: Validation loss = 23.168615\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 33: Validation loss = 33.652649\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 34: Validation loss = 44.262508\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 35: Validation loss = 54.571529\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 36: Validation loss = 59.468838\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 37: Validation loss = 70.497383\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 38: Validation loss = 97.108063\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 1: Training loss = 46.725876\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 2: Training loss = 48.333641\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 3: Training loss = 50.669411\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 4: Training loss = 50.642803\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 5: Training loss = 55.793789\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 6: Training loss = 60.692268\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 7: Training loss = 59.941502\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 8: Training loss = 58.391830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 9: Training loss = 56.586742\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 10: Training loss = 54.777321\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 11: Training loss = 55.034481\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 12: Training loss = 59.570099\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 13: Training loss = 62.874866\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 14: Training loss = 62.819786\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 15: Training loss = 66.569443\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 16: Training loss = 65.674759\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 17: Training loss = 59.136578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 18: Training loss = 53.407135\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 19: Training loss = 48.752155\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 20: Training loss = 53.853218\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 21: Training loss = 62.548378\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 22: Training loss = 64.470856\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 23: Training loss = 62.030743\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 24: Training loss = 62.680859\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 25: Training loss = 58.211880\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 26: Training loss = 54.587391\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 27: Training loss = 57.204823\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 28: Training loss = 63.512806\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 29: Training loss = 70.527016\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 30: Training loss = 67.318382\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 31: Training loss = 62.370403\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 32: Training loss = 60.512711\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 33: Training loss = 52.835812\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 34: Training loss = 46.107727\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 35: Training loss = 43.361366\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 36: Training loss = 50.755432\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 37: Training loss = 55.020096\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 38: Training loss = 55.442299\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 39: Training loss = 54.665211\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 40: Training loss = 57.811367\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 41: Training loss = 60.470165\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 42: Training loss = 60.564800\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 43: Training loss = 65.669556\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 44: Training loss = 68.312508\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 45: Training loss = 67.720062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 46: Training loss = 61.589813\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 47: Training loss = 55.206966\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 48: Training loss = 48.445465\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 49: Training loss = 42.725368\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 50: Training loss = 38.780674\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 51: Training loss = 33.855270\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 52: Training loss = 28.239609\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 53: Training loss = 23.577038\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 54: Training loss = 19.969181\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 55: Training loss = 17.743330\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 56: Training loss = 14.918126\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 57: Training loss = 14.645703\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 58: Training loss = 14.735744\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 59: Training loss = 13.353774\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 60: Training loss = 12.119888\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 61: Training loss = 15.554768\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 62: Training loss = 20.973747\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 63: Training loss = 26.072514\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 64: Training loss = 32.042553\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 65: Training loss = 37.808067\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 66: Training loss = 39.593475\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 67: Training loss = 40.534836\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 68: Training loss = 41.605286\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 69: Training loss = 46.727917\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 70: Training loss = 45.407101\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 71: Training loss = 40.984222\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 72: Training loss = 35.807529\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 73: Training loss = 30.921417\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 74: Training loss = 29.094519\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 75: Training loss = 26.914206\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 76: Training loss = 29.068851\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 77: Training loss = 33.082367\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 78: Training loss = 36.964237\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 79: Training loss = 37.475380\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 80: Training loss = 42.788219\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 81: Training loss = 45.295139\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 82: Training loss = 45.975708\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 83: Training loss = 47.431557\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 84: Training loss = 44.930107\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 85: Training loss = 43.120499\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 86: Training loss = 41.147068\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 87: Training loss = 40.410282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 88: Training loss = 40.877556\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 89: Training loss = 42.081398\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 90: Training loss = 38.930637\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 91: Training loss = 41.400398\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 92: Training loss = 44.641777\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 93: Training loss = 47.887501\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 94: Training loss = 52.075909\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 95: Training loss = 55.912834\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 96: Training loss = 58.549141\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 97: Training loss = 58.285267\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 98: Training loss = 57.380043\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 99: Training loss = 56.579208\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 100: Training loss = 58.250698\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 101: Training loss = 60.318943\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 102: Training loss = 61.720211\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 103: Training loss = 58.043053\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 104: Training loss = 55.531464\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 105: Training loss = 53.430069\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 106: Training loss = 53.824055\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 107: Training loss = 54.479565\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 108: Training loss = 54.355804\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 109: Training loss = 53.594624\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 110: Training loss = 54.806679\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 111: Training loss = 52.463795\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 112: Training loss = 50.504002\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 113: Training loss = 53.196144\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 114: Training loss = 56.529949\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 115: Training loss = 60.366501\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 116: Training loss = 62.509232\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 117: Training loss = 64.974075\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 118: Training loss = 67.075302\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 119: Training loss = 66.917084\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 120: Training loss = 64.966705\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 121: Training loss = 62.294685\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 122: Training loss = 59.038338\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 123: Training loss = 55.525021\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 124: Training loss = 50.673264\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 125: Training loss = 43.983799\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 126: Training loss = 39.121292\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 127: Training loss = 36.358231\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 128: Training loss = 34.063683\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 129: Training loss = 32.990852\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 130: Training loss = 33.843777\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 131: Training loss = 35.440796\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 132: Training loss = 37.780426\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 133: Training loss = 41.438950\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 134: Training loss = 44.196770\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 135: Training loss = 47.663063\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 136: Training loss = 49.905186\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 137: Training loss = 49.259106\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 138: Training loss = 48.279240\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 139: Training loss = 48.640617\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 140: Training loss = 48.648041\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 141: Training loss = 48.217655\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 142: Training loss = 46.814556\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 143: Training loss = 42.702656\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 144: Training loss = 38.868320\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 145: Training loss = 34.978474\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 146: Training loss = 34.124855\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 147: Training loss = 34.371319\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 148: Training loss = 34.153027\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 149: Training loss = 32.441357\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 150: Training loss = 30.049395\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 151: Training loss = 27.953316\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 152: Training loss = 27.776518\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 1: Validation loss = 29.321396\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 2: Validation loss = 31.184862\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 3: Validation loss = 36.244362\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 4: Validation loss = 40.107906\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 5: Validation loss = 47.301434\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 6: Validation loss = 55.508408\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 7: Validation loss = 65.370178\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 8: Validation loss = 69.612839\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 9: Validation loss = 73.071098\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 10: Validation loss = 75.913292\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 11: Validation loss = 79.359322\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 12: Validation loss = 80.723358\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 13: Validation loss = 75.931908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 14: Validation loss = 69.981888\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 15: Validation loss = 61.134323\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 16: Validation loss = 52.782578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Validation window 17: Validation loss = 43.607281\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 18: Validation loss = 40.773495\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 19: Validation loss = 37.140678\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 20: Validation loss = 34.443481\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 21: Validation loss = 30.718834\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 22: Validation loss = 28.169075\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 23: Validation loss = 28.709522\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 24: Validation loss = 28.868958\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 25: Validation loss = 27.785376\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 26: Validation loss = 25.209608\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 27: Validation loss = 22.626755\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 28: Validation loss = 19.837797\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 29: Validation loss = 17.750065\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 30: Validation loss = 14.877588\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 31: Validation loss = 13.156385\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 32: Validation loss = 12.119225\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 33: Validation loss = 19.905190\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 34: Validation loss = 27.952301\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 35: Validation loss = 34.687202\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 36: Validation loss = 37.211773\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 37: Validation loss = 36.964947\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 38: Validation loss = 40.389149\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 1: Training loss = 35.333275\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 2: Training loss = 37.148510\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 3: Training loss = 42.235386\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 4: Training loss = 43.258865\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 5: Training loss = 47.198013\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 6: Training loss = 51.275848\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 7: Training loss = 50.606060\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 8: Training loss = 48.924728\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 9: Training loss = 46.956905\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 10: Training loss = 43.780983\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 11: Training loss = 43.793289\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 12: Training loss = 46.520542\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 13: Training loss = 49.663593\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 14: Training loss = 48.882141\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 15: Training loss = 52.362865\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 16: Training loss = 50.435242\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 17: Training loss = 46.840397\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 18: Training loss = 43.987984\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 19: Training loss = 39.450180\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 20: Training loss = 43.222477\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 21: Training loss = 51.251980\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 22: Training loss = 53.943363\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 23: Training loss = 51.575829\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 24: Training loss = 53.124741\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 25: Training loss = 49.369484\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 26: Training loss = 46.350754\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 27: Training loss = 45.372421\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 28: Training loss = 48.168785\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 29: Training loss = 54.165546\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 30: Training loss = 50.533108\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 31: Training loss = 44.157326\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 32: Training loss = 41.778858\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 33: Training loss = 37.577454\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 34: Training loss = 35.764339\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 35: Training loss = 33.382904\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 36: Training loss = 40.545689\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 37: Training loss = 44.085995\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 38: Training loss = 44.422710\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 39: Training loss = 44.235073\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 40: Training loss = 48.839504\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 41: Training loss = 52.581432\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 42: Training loss = 52.672161\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 43: Training loss = 53.426605\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 44: Training loss = 49.374565\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 45: Training loss = 47.548004\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 46: Training loss = 41.362415\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 47: Training loss = 36.973976\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 48: Training loss = 32.481205\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 49: Training loss = 27.051516\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 50: Training loss = 22.269188\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 51: Training loss = 16.980488\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 52: Training loss = 11.909619\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 53: Training loss = 9.149560\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 54: Training loss = 8.291449\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 55: Training loss = 8.756162\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 56: Training loss = 8.398096\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 57: Training loss = 9.359084\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 58: Training loss = 9.449991\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 59: Training loss = 8.969470\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 60: Training loss = 8.477195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 61: Training loss = 11.279584\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 62: Training loss = 16.079370\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 63: Training loss = 19.485691\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 64: Training loss = 23.709764\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 65: Training loss = 26.990185\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 66: Training loss = 27.295990\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 67: Training loss = 26.823412\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 68: Training loss = 26.765209\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 69: Training loss = 29.981882\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 70: Training loss = 31.446520\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 71: Training loss = 30.942108\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 72: Training loss = 28.966322\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 73: Training loss = 25.599760\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 74: Training loss = 24.101460\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 75: Training loss = 22.488247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 76: Training loss = 25.100145\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 77: Training loss = 29.243921\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 78: Training loss = 33.080395\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 79: Training loss = 34.356941\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 80: Training loss = 36.901127\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 81: Training loss = 37.362656\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 82: Training loss = 36.489697\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 83: Training loss = 37.109268\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 84: Training loss = 35.815033\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 85: Training loss = 34.422543\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 86: Training loss = 32.775032\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 87: Training loss = 30.763781\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 88: Training loss = 30.446060\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 89: Training loss = 31.308973\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 90: Training loss = 28.274494\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 91: Training loss = 30.105793\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 92: Training loss = 32.054802\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 93: Training loss = 34.617062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 94: Training loss = 37.278316\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 95: Training loss = 40.221699\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 96: Training loss = 41.104908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 97: Training loss = 40.590816\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 98: Training loss = 40.312691\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 99: Training loss = 39.197163\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 100: Training loss = 40.247036\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 101: Training loss = 40.754066\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 102: Training loss = 42.518822\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 103: Training loss = 39.071674\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 104: Training loss = 36.418896\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 105: Training loss = 34.155617\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 106: Training loss = 34.957996\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 107: Training loss = 36.264194\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 108: Training loss = 35.874046\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 109: Training loss = 35.731670\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 110: Training loss = 37.226917\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 111: Training loss = 36.262585\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 112: Training loss = 34.199318\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 113: Training loss = 36.591099\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 114: Training loss = 40.269897\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 115: Training loss = 44.605495\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 116: Training loss = 47.235661\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 117: Training loss = 50.004425\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 118: Training loss = 52.408218\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 119: Training loss = 52.603043\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 120: Training loss = 50.979031\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 121: Training loss = 49.185036\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 122: Training loss = 46.916962\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 123: Training loss = 45.231216\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 124: Training loss = 41.050713\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 125: Training loss = 35.928944\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 126: Training loss = 32.515102\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 127: Training loss = 31.608629\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 128: Training loss = 31.128738\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 129: Training loss = 31.603802\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 130: Training loss = 33.757931\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 131: Training loss = 36.118469\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 132: Training loss = 38.839172\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 133: Training loss = 42.159515\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 134: Training loss = 45.320236\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 135: Training loss = 49.525295\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 136: Training loss = 51.373463\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 137: Training loss = 49.281292\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 138: Training loss = 46.356861\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 139: Training loss = 44.225548\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 140: Training loss = 41.825790\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 141: Training loss = 39.311554\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 142: Training loss = 36.745625\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 143: Training loss = 34.513489\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 144: Training loss = 30.757481\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 145: Training loss = 25.925116\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 146: Training loss = 23.371332\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 147: Training loss = 22.658922\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 148: Training loss = 21.454035\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 149: Training loss = 19.549496\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 150: Training loss = 18.995720\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 151: Training loss = 18.279505\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 152: Training loss = 18.001152\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 1: Validation loss = 16.130913\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 2: Validation loss = 16.270340\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 3: Validation loss = 17.242874\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 4: Validation loss = 17.323904\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 5: Validation loss = 20.027735\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 6: Validation loss = 23.761953\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 7: Validation loss = 30.756767\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 8: Validation loss = 31.723835\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 9: Validation loss = 33.018127\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 10: Validation loss = 33.858452\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 11: Validation loss = 35.953911\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 12: Validation loss = 38.057610\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 13: Validation loss = 38.771667\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 14: Validation loss = 36.339775\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 15: Validation loss = 31.622356\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Validation window 16: Validation loss = 27.175270\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Validation window 17: Validation loss = 20.216570\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 18: Validation loss = 18.957022\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 19: Validation loss = 17.393757\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 20: Validation loss = 17.027966\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 21: Validation loss = 15.576409\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 22: Validation loss = 14.251285\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 23: Validation loss = 13.205648\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 24: Validation loss = 15.041094\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 25: Validation loss = 16.511808\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 26: Validation loss = 17.558239\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 27: Validation loss = 18.158884\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 28: Validation loss = 18.148624\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 29: Validation loss = 18.091610\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 30: Validation loss = 17.819361\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 31: Validation loss = 17.119631\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 32: Validation loss = 16.693813\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 33: Validation loss = 22.256966\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 34: Validation loss = 27.953405\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 35: Validation loss = 30.485561\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 36: Validation loss = 32.581669\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 37: Validation loss = 31.984324\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 38: Validation loss = 31.346834\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 1: Training loss = 35.088966\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 2: Training loss = 36.870602\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 3: Training loss = 42.233837\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 4: Training loss = 41.876587\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 5: Training loss = 44.927353\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 6: Training loss = 47.895226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 7: Training loss = 47.337337\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 8: Training loss = 45.912907\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 9: Training loss = 44.723923\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 10: Training loss = 37.318001\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 11: Training loss = 37.330700\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 12: Training loss = 38.283886\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 13: Training loss = 40.754364\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 14: Training loss = 39.573086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 15: Training loss = 41.865986\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 16: Training loss = 39.980007\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 17: Training loss = 38.550678\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 18: Training loss = 37.594757\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 19: Training loss = 33.919838\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 20: Training loss = 36.400848\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 21: Training loss = 42.899635\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 22: Training loss = 45.796402\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 23: Training loss = 43.775757\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 24: Training loss = 45.807617\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 25: Training loss = 43.741501\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 26: Training loss = 41.536751\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 27: Training loss = 39.162971\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 28: Training loss = 39.917286\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 29: Training loss = 44.432453\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 30: Training loss = 41.284119\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 31: Training loss = 35.196220\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 32: Training loss = 32.978558\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 33: Training loss = 30.708359\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 34: Training loss = 30.884495\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 35: Training loss = 28.921167\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 36: Training loss = 34.125355\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 37: Training loss = 36.222385\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 38: Training loss = 36.386307\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 39: Training loss = 36.590836\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 40: Training loss = 41.209850\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 41: Training loss = 44.891670\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 42: Training loss = 44.809006\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 43: Training loss = 43.724419\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 44: Training loss = 38.048512\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 45: Training loss = 36.057804\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 46: Training loss = 31.282516\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 47: Training loss = 28.636232\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 48: Training loss = 25.738613\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 49: Training loss = 20.979362\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 50: Training loss = 16.405756\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 51: Training loss = 11.752568\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 52: Training loss = 7.788228\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 53: Training loss = 6.267176\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 54: Training loss = 6.270987\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 55: Training loss = 7.363488\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 56: Training loss = 7.889356\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 57: Training loss = 9.196017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 58: Training loss = 9.269100\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 59: Training loss = 9.188409\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 60: Training loss = 9.024403\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 61: Training loss = 11.000170\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 62: Training loss = 14.812353\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 63: Training loss = 17.248968\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 64: Training loss = 20.430281\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 65: Training loss = 22.587311\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 66: Training loss = 22.287611\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 67: Training loss = 21.411615\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 68: Training loss = 21.009024\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 69: Training loss = 23.012917\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 70: Training loss = 25.045343\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 71: Training loss = 26.169117\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 72: Training loss = 25.818153\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 73: Training loss = 23.240738\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 74: Training loss = 21.872875\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 75: Training loss = 20.385576\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 76: Training loss = 23.153416\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 77: Training loss = 27.380531\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 78: Training loss = 30.972727\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 79: Training loss = 32.747375\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 80: Training loss = 34.459370\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 81: Training loss = 34.423157\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 82: Training loss = 33.152134\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 83: Training loss = 33.638775\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 84: Training loss = 33.484882\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 85: Training loss = 32.534161\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 86: Training loss = 31.199945\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 87: Training loss = 28.546921\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 88: Training loss = 27.701899\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 89: Training loss = 27.621103\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 90: Training loss = 26.119459\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 91: Training loss = 27.432550\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 92: Training loss = 28.497908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 93: Training loss = 30.091961\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 94: Training loss = 31.188169\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 95: Training loss = 33.345676\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 96: Training loss = 33.116402\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 97: Training loss = 32.313183\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 98: Training loss = 32.458809\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 99: Training loss = 31.992825\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 100: Training loss = 31.475321\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 101: Training loss = 30.678249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 102: Training loss = 32.254101\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 103: Training loss = 29.691118\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 104: Training loss = 27.658594\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 105: Training loss = 25.982725\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 106: Training loss = 27.242052\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 107: Training loss = 29.070847\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 108: Training loss = 28.818953\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 109: Training loss = 29.019812\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 110: Training loss = 30.492043\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 111: Training loss = 30.498989\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 112: Training loss = 28.845358\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 113: Training loss = 30.377390\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 114: Training loss = 32.908424\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 115: Training loss = 35.954464\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 116: Training loss = 37.450741\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 117: Training loss = 38.914833\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 118: Training loss = 40.034515\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 119: Training loss = 39.258476\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 120: Training loss = 37.347767\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 121: Training loss = 35.679710\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 122: Training loss = 33.941891\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 123: Training loss = 34.043266\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 124: Training loss = 32.018635\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 125: Training loss = 29.696745\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 126: Training loss = 28.096050\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 127: Training loss = 27.661760\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 128: Training loss = 27.600243\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 129: Training loss = 28.302279\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 130: Training loss = 30.130119\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 131: Training loss = 31.773024\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 132: Training loss = 33.565578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 133: Training loss = 34.988602\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 134: Training loss = 36.624092\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 135: Training loss = 45.141171\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 136: Training loss = 57.370300\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 137: Training loss = 56.854511\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 138: Training loss = 55.268768\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 139: Training loss = 54.313690\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 140: Training loss = 52.615280\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 141: Training loss = 50.858562\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 142: Training loss = 49.096390\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 143: Training loss = 51.369457\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 144: Training loss = 49.363640\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 145: Training loss = 39.544197\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 146: Training loss = 26.121046\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 147: Training loss = 24.812820\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 148: Training loss = 23.777802\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 149: Training loss = 22.819855\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 150: Training loss = 22.995468\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 151: Training loss = 23.090967\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 152: Training loss = 23.349365\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 1: Validation loss = 18.987743\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 2: Validation loss = 19.391043\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 3: Validation loss = 19.786695\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 4: Validation loss = 19.048901\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 5: Validation loss = 20.299770\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 6: Validation loss = 21.703394\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 7: Validation loss = 25.539251\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 8: Validation loss = 25.751688\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 9: Validation loss = 26.188269\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 10: Validation loss = 26.153883\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 11: Validation loss = 26.945898\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 12: Validation loss = 26.914164\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 13: Validation loss = 26.937449\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 14: Validation loss = 26.106297\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 15: Validation loss = 24.033554\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 16: Validation loss = 22.866428\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Validation window 17: Validation loss = 18.919407\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 18: Validation loss = 18.464573\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 19: Validation loss = 17.016960\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 20: Validation loss = 16.351246\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 21: Validation loss = 15.749722\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Validation window 22: Validation loss = 15.718366\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 23: Validation loss = 15.320722\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 24: Validation loss = 16.554533\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 25: Validation loss = 17.898472\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 26: Validation loss = 19.041525\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 27: Validation loss = 19.518375\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 28: Validation loss = 19.610735\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 29: Validation loss = 20.826612\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 30: Validation loss = 22.390701\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 31: Validation loss = 22.091810\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 32: Validation loss = 21.741261\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 33: Validation loss = 23.579020\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 34: Validation loss = 27.806004\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 35: Validation loss = 27.839109\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 36: Validation loss = 27.446154\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 37: Validation loss = 27.154129\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 38: Validation loss = 28.896870\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 1: Training loss = 43.632481\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 2: Training loss = 46.811436\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 3: Training loss = 52.184818\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 4: Training loss = 49.868195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 5: Training loss = 52.650833\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 6: Training loss = 54.758541\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 7: Training loss = 54.013554\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 8: Training loss = 52.679241\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 9: Training loss = 52.606102\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 10: Training loss = 37.964863\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 11: Training loss = 36.367558\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 12: Training loss = 36.109364\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 13: Training loss = 37.924492\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 14: Training loss = 36.762188\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 15: Training loss = 38.323700\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 16: Training loss = 36.497063\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 17: Training loss = 35.146500\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 18: Training loss = 34.239479\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 19: Training loss = 30.556627\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 20: Training loss = 32.941360\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 21: Training loss = 38.994144\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 22: Training loss = 41.726303\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 23: Training loss = 39.995712\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 24: Training loss = 42.086002\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 25: Training loss = 40.915791\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 26: Training loss = 38.941719\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 27: Training loss = 36.886066\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 28: Training loss = 37.518219\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 29: Training loss = 41.779228\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 30: Training loss = 38.755974\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 31: Training loss = 33.045044\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 32: Training loss = 31.101471\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 33: Training loss = 28.623207\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 34: Training loss = 28.028399\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 35: Training loss = 25.804293\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 36: Training loss = 30.198153\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 37: Training loss = 31.824600\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 38: Training loss = 32.111202\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 39: Training loss = 32.299252\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 40: Training loss = 36.753704\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 41: Training loss = 40.290897\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 42: Training loss = 40.166542\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 43: Training loss = 39.238049\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 44: Training loss = 34.531666\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 45: Training loss = 32.815964\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 46: Training loss = 28.845804\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 47: Training loss = 26.697905\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 48: Training loss = 24.322403\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 49: Training loss = 19.880053\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 50: Training loss = 15.598272\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 51: Training loss = 11.226955\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 52: Training loss = 7.538105\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 53: Training loss = 6.204089\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 54: Training loss = 6.222530\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 55: Training loss = 7.189171\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 56: Training loss = 7.571926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 57: Training loss = 8.710805\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 58: Training loss = 8.486555\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 59: Training loss = 8.344895\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 60: Training loss = 8.154398\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 61: Training loss = 9.966168\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 62: Training loss = 13.520065\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 63: Training loss = 15.989918\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 64: Training loss = 19.039089\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 65: Training loss = 21.156746\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 66: Training loss = 20.864681\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 67: Training loss = 20.111889\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 68: Training loss = 19.802391\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 69: Training loss = 21.527277\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 70: Training loss = 23.348709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 71: Training loss = 24.866205\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 72: Training loss = 25.067350\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 73: Training loss = 22.731268\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 74: Training loss = 21.337706\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 75: Training loss = 19.919849\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 76: Training loss = 22.925850\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 77: Training loss = 27.313047\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 78: Training loss = 30.765205\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 79: Training loss = 32.658314\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 80: Training loss = 34.418995\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 81: Training loss = 34.202335\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 82: Training loss = 32.994564\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 83: Training loss = 33.535870\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 84: Training loss = 34.021515\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 85: Training loss = 33.470890\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 86: Training loss = 32.151062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 87: Training loss = 29.117535\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 88: Training loss = 27.982557\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 89: Training loss = 27.298212\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 90: Training loss = 26.700861\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 91: Training loss = 27.808943\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 92: Training loss = 28.346373\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 93: Training loss = 29.300493\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 94: Training loss = 29.480047\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 95: Training loss = 30.802429\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 96: Training loss = 29.933483\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 97: Training loss = 28.992136\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 98: Training loss = 29.275511\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 99: Training loss = 29.282726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 100: Training loss = 28.092461\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 101: Training loss = 27.628958\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 102: Training loss = 29.121555\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 103: Training loss = 27.021603\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 104: Training loss = 25.387785\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 105: Training loss = 24.105246\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 106: Training loss = 25.535015\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 107: Training loss = 27.472401\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 108: Training loss = 27.307045\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 109: Training loss = 27.565546\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 110: Training loss = 28.933775\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 111: Training loss = 28.432602\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 112: Training loss = 26.950390\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 113: Training loss = 27.999155\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 114: Training loss = 29.665239\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 115: Training loss = 31.673645\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 116: Training loss = 32.262733\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 117: Training loss = 32.738468\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 118: Training loss = 32.862286\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 119: Training loss = 31.312922\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 120: Training loss = 29.043846\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 121: Training loss = 26.880665\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 122: Training loss = 24.643305\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 123: Training loss = 24.375414\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 124: Training loss = 22.608070\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 125: Training loss = 20.492220\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 126: Training loss = 18.683058\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 127: Training loss = 17.767673\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 128: Training loss = 17.231270\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 129: Training loss = 17.365726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 130: Training loss = 18.268410\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 131: Training loss = 19.185551\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 132: Training loss = 20.145718\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 133: Training loss = 20.889757\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 134: Training loss = 21.744053\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 135: Training loss = 29.732880\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 136: Training loss = 43.771797\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 137: Training loss = 44.625031\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 138: Training loss = 44.298470\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 139: Training loss = 44.452152\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 140: Training loss = 43.909470\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 141: Training loss = 43.246380\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 142: Training loss = 42.557632\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 143: Training loss = 44.110386\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 144: Training loss = 43.792633\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 145: Training loss = 36.060387\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 146: Training loss = 22.804726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 147: Training loss = 21.294283\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 148: Training loss = 20.596071\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 149: Training loss = 20.533409\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 150: Training loss = 20.502937\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 151: Training loss = 20.008972\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 152: Training loss = 19.646830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 1: Validation loss = 17.013678\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 2: Validation loss = 16.415810\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Validation window 3: Validation loss = 15.752938\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 4: Validation loss = 14.466603\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 5: Validation loss = 14.210962\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 6: Validation loss = 13.751035\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 7: Validation loss = 14.211466\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 8: Validation loss = 13.664328\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 9: Validation loss = 13.603261\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 10: Validation loss = 13.417645\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 11: Validation loss = 13.588571\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 12: Validation loss = 13.374272\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 13: Validation loss = 13.371027\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 14: Validation loss = 13.162590\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 15: Validation loss = 13.010973\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 16: Validation loss = 14.068029\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 17: Validation loss = 13.550423\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 18: Validation loss = 14.668105\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 19: Validation loss = 14.248212\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 20: Validation loss = 14.164869\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 21: Validation loss = 14.896151\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 22: Validation loss = 15.559977\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 23: Validation loss = 15.507726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 24: Validation loss = 16.427473\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 25: Validation loss = 17.173676\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 26: Validation loss = 17.574190\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 27: Validation loss = 16.948215\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 28: Validation loss = 16.285709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 29: Validation loss = 17.537367\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 30: Validation loss = 19.369110\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 31: Validation loss = 18.975765\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 32: Validation loss = 18.164860\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 33: Validation loss = 19.235010\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 34: Validation loss = 21.572935\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 35: Validation loss = 21.245014\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 36: Validation loss = 20.032421\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 37: Validation loss = 19.868984\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 38: Validation loss = 23.622211\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 1: Training loss = 32.248283\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 2: Training loss = 35.518349\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 3: Training loss = 40.549770\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 4: Training loss = 41.115540\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 5: Training loss = 43.586422\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 6: Training loss = 45.382191\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 7: Training loss = 44.783730\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 8: Training loss = 43.729912\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 9: Training loss = 44.012238\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 10: Training loss = 35.189240\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 11: Training loss = 34.052471\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 12: Training loss = 33.312271\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 13: Training loss = 34.786446\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 14: Training loss = 33.550781\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 15: Training loss = 35.183323\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 16: Training loss = 33.534111\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 17: Training loss = 32.117950\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 18: Training loss = 30.998928\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 19: Training loss = 27.596075\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 20: Training loss = 29.894384\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 21: Training loss = 35.312801\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 22: Training loss = 37.809277\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 23: Training loss = 36.176968\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 24: Training loss = 38.198959\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 25: Training loss = 36.876530\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 26: Training loss = 35.010132\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 27: Training loss = 33.182022\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 28: Training loss = 33.668751\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 29: Training loss = 37.630741\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 30: Training loss = 34.783234\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 31: Training loss = 29.603268\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 32: Training loss = 27.908327\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 33: Training loss = 25.645247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 34: Training loss = 24.991041\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 35: Training loss = 22.895929\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 36: Training loss = 26.459709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 37: Training loss = 27.611166\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 38: Training loss = 27.884809\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 39: Training loss = 27.894430\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 40: Training loss = 31.992743\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 41: Training loss = 35.253090\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 42: Training loss = 35.106213\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 43: Training loss = 34.152523\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 44: Training loss = 30.073095\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 45: Training loss = 28.596510\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 46: Training loss = 25.351023\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 47: Training loss = 23.729233\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 48: Training loss = 21.787828\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 49: Training loss = 17.811363\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 50: Training loss = 13.862331\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 51: Training loss = 9.911899\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 52: Training loss = 6.721784\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 53: Training loss = 5.725788\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 54: Training loss = 5.603104\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 55: Training loss = 6.443748\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 56: Training loss = 6.873842\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 57: Training loss = 7.915201\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 58: Training loss = 7.735242\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 59: Training loss = 7.643887\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 60: Training loss = 7.512436\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 61: Training loss = 9.037413\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 62: Training loss = 12.103695\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 63: Training loss = 14.238242\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 64: Training loss = 16.909760\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 65: Training loss = 18.818062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 66: Training loss = 18.478258\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 67: Training loss = 17.752523\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 68: Training loss = 17.412754\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 69: Training loss = 18.662817\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 70: Training loss = 20.281370\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 71: Training loss = 21.651218\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 72: Training loss = 21.705618\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 73: Training loss = 19.592901\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 74: Training loss = 18.295656\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 75: Training loss = 17.270935\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 76: Training loss = 20.437357\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 77: Training loss = 24.604006\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 78: Training loss = 27.728029\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 79: Training loss = 29.726521\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 80: Training loss = 31.505869\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 81: Training loss = 31.775023\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 82: Training loss = 31.174452\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 83: Training loss = 31.948511\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 84: Training loss = 32.761520\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 85: Training loss = 32.450962\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 86: Training loss = 31.179163\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 87: Training loss = 28.283800\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 88: Training loss = 27.099529\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 89: Training loss = 26.299332\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 90: Training loss = 24.902077\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 91: Training loss = 25.515078\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 92: Training loss = 25.806620\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 93: Training loss = 26.369684\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 94: Training loss = 26.136625\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 95: Training loss = 26.876640\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 96: Training loss = 25.790398\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 97: Training loss = 24.893610\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 98: Training loss = 25.329063\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 99: Training loss = 25.284636\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 100: Training loss = 24.824917\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 101: Training loss = 24.565109\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 102: Training loss = 25.582163\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 103: Training loss = 23.693451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 104: Training loss = 22.146685\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 105: Training loss = 20.934795\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 106: Training loss = 22.187269\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 107: Training loss = 23.947382\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 108: Training loss = 23.733980\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 109: Training loss = 24.191084\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 110: Training loss = 25.573940\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 111: Training loss = 25.159685\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 112: Training loss = 24.324026\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 113: Training loss = 25.254549\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 114: Training loss = 26.634575\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 115: Training loss = 28.219458\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 116: Training loss = 28.537453\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 117: Training loss = 28.650501\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 118: Training loss = 28.414938\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 119: Training loss = 26.649681\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 120: Training loss = 24.374521\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 121: Training loss = 22.014925\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 122: Training loss = 19.524113\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 123: Training loss = 18.940035\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 124: Training loss = 17.224468\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 125: Training loss = 15.168371\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 126: Training loss = 13.255813\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 127: Training loss = 12.052726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 128: Training loss = 11.152205\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 129: Training loss = 10.832897\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 130: Training loss = 11.071441\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 131: Training loss = 11.528344\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 132: Training loss = 11.979533\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 133: Training loss = 12.348734\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 134: Training loss = 12.801747\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 135: Training loss = 19.143044\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 136: Training loss = 29.732038\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 137: Training loss = 31.238228\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 138: Training loss = 31.806694\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 139: Training loss = 32.670193\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 140: Training loss = 32.884743\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 141: Training loss = 33.014683\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 142: Training loss = 33.021725\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 143: Training loss = 34.028767\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 144: Training loss = 34.834949\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 145: Training loss = 29.381287\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 146: Training loss = 20.074608\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 147: Training loss = 18.636234\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 148: Training loss = 18.049393\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 149: Training loss = 18.201675\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 150: Training loss = 18.014956\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 151: Training loss = 17.347164\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 152: Training loss = 16.874163\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 1: Validation loss = 15.416993\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 2: Validation loss = 14.144248\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 3: Validation loss = 13.136682\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 4: Validation loss = 11.900225\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 5: Validation loss = 11.308808\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 6: Validation loss = 10.465950\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 7: Validation loss = 9.772316\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 8: Validation loss = 9.306929\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 9: Validation loss = 9.160002\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 10: Validation loss = 9.054709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 11: Validation loss = 9.140012\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 12: Validation loss = 8.988931\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 13: Validation loss = 8.931564\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 14: Validation loss = 8.768896\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 15: Validation loss = 9.044756\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 16: Validation loss = 10.482389\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 17: Validation loss = 11.209551\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 18: Validation loss = 12.473009\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 19: Validation loss = 12.279237\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 20: Validation loss = 12.339972\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 21: Validation loss = 13.251267\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 22: Validation loss = 13.916200\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 23: Validation loss = 13.728452\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 24: Validation loss = 14.291875\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 25: Validation loss = 14.711652\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 26: Validation loss = 14.543221\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 27: Validation loss = 13.475843\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 28: Validation loss = 12.581579\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 29: Validation loss = 13.622903\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 30: Validation loss = 14.921803\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 31: Validation loss = 14.327934\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 32: Validation loss = 13.692642\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 33: Validation loss = 14.752847\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 34: Validation loss = 16.682875\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 35: Validation loss = 16.693367\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 36: Validation loss = 16.183193\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 37: Validation loss = 16.414478\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 38: Validation loss = 20.500891\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 1: Training loss = 27.019289\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 2: Training loss = 30.264647\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Training window 3: Training loss = 34.646366\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 4: Training loss = 35.853821\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 5: Training loss = 37.795933\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 6: Training loss = 39.278351\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 7: Training loss = 38.856068\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 8: Training loss = 38.029465\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 9: Training loss = 38.357864\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 10: Training loss = 32.563545\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 11: Training loss = 31.412294\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 12: Training loss = 30.019754\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 13: Training loss = 31.037336\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 14: Training loss = 29.736088\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 15: Training loss = 31.062075\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 16: Training loss = 29.498117\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 17: Training loss = 28.479914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 18: Training loss = 27.577301\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 19: Training loss = 24.615620\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 20: Training loss = 26.346754\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 21: Training loss = 30.734348\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 22: Training loss = 33.044197\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 23: Training loss = 31.710569\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 24: Training loss = 33.528313\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 25: Training loss = 32.379681\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 26: Training loss = 30.789366\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 27: Training loss = 28.843843\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 28: Training loss = 28.828056\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 29: Training loss = 31.996023\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 30: Training loss = 29.670252\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 31: Training loss = 25.364723\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 32: Training loss = 23.997093\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 33: Training loss = 22.491304\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 34: Training loss = 22.659000\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 35: Training loss = 20.677340\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 36: Training loss = 23.282282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 37: Training loss = 23.993662\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 38: Training loss = 24.208866\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 39: Training loss = 24.391054\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 40: Training loss = 28.107054\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 41: Training loss = 31.087910\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 42: Training loss = 30.897560\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 43: Training loss = 29.489880\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 44: Training loss = 25.480326\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 45: Training loss = 24.295589\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 46: Training loss = 21.873417\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 47: Training loss = 20.768335\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 48: Training loss = 19.234045\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 49: Training loss = 15.758512\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 50: Training loss = 12.172183\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 51: Training loss = 8.651402\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 52: Training loss = 6.007527\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 53: Training loss = 5.456251\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 54: Training loss = 5.182388\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 55: Training loss = 5.968884\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 56: Training loss = 6.452483\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 57: Training loss = 7.489510\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 58: Training loss = 7.418319\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 59: Training loss = 7.340884\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 60: Training loss = 7.265769\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 61: Training loss = 8.513353\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 62: Training loss = 11.070869\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 63: Training loss = 12.760542\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 64: Training loss = 15.075432\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 65: Training loss = 16.767977\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 66: Training loss = 16.381845\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 67: Training loss = 15.651385\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 68: Training loss = 15.275545\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 69: Training loss = 16.123926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 70: Training loss = 17.661465\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 71: Training loss = 18.954809\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Training window 72: Training loss = 18.985825\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 73: Training loss = 17.188084\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 74: Training loss = 16.061302\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 75: Training loss = 15.253557\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 76: Training loss = 18.142206\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 77: Training loss = 21.919207\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 78: Training loss = 24.735365\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 79: Training loss = 26.728912\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 80: Training loss = 28.309114\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 81: Training loss = 28.880329\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 82: Training loss = 28.693722\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 83: Training loss = 29.584608\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 84: Training loss = 30.654362\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 85: Training loss = 30.450809\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 86: Training loss = 29.440704\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 87: Training loss = 26.882118\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 88: Training loss = 25.822596\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 89: Training loss = 25.044436\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 90: Training loss = 23.323620\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 91: Training loss = 23.554667\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 92: Training loss = 23.648054\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 93: Training loss = 23.956800\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 94: Training loss = 23.409897\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 95: Training loss = 23.782042\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 96: Training loss = 22.571918\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 97: Training loss = 21.728865\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 98: Training loss = 22.167488\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 99: Training loss = 21.950171\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 100: Training loss = 21.826008\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 101: Training loss = 21.555145\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 102: Training loss = 22.007252\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 103: Training loss = 20.286886\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 104: Training loss = 18.851919\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 105: Training loss = 17.761307\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 106: Training loss = 18.858219\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 107: Training loss = 20.448059\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 108: Training loss = 20.242624\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 109: Training loss = 20.850922\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 110: Training loss = 22.205914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 111: Training loss = 22.053652\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 112: Training loss = 21.851234\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 113: Training loss = 22.668360\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 114: Training loss = 23.814798\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 115: Training loss = 25.062664\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 116: Training loss = 25.190754\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 117: Training loss = 25.052275\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 118: Training loss = 24.611942\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 119: Training loss = 22.803036\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 120: Training loss = 20.665529\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Training window 121: Training loss = 18.349791\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 122: Training loss = 15.918373\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 123: Training loss = 15.335734\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 124: Training loss = 13.867907\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 125: Training loss = 12.047034\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 126: Training loss = 10.221931\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 127: Training loss = 8.972878\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 128: Training loss = 7.933596\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 129: Training loss = 7.533423\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 130: Training loss = 7.479869\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 131: Training loss = 7.551057\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 132: Training loss = 7.583999\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 133: Training loss = 7.605271\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 134: Training loss = 7.837149\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 135: Training loss = 12.208160\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 136: Training loss = 18.578173\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 137: Training loss = 20.297302\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 138: Training loss = 21.375711\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 139: Training loss = 22.510103\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 140: Training loss = 23.030079\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 141: Training loss = 23.468090\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 142: Training loss = 23.772709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 143: Training loss = 24.578335\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 144: Training loss = 26.068218\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 145: Training loss = 22.911167\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 146: Training loss = 17.916815\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 147: Training loss = 16.586998\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 148: Training loss = 16.004919\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 149: Training loss = 16.222685\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 150: Training loss = 16.058191\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 151: Training loss = 15.409903\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 152: Training loss = 14.928672\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 1: Validation loss = 14.047484\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 2: Validation loss = 12.417459\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 3: Validation loss = 11.277515\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 4: Validation loss = 10.149973\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 5: Validation loss = 9.626635\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 6: Validation loss = 8.858147\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 7: Validation loss = 8.097750\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 8: Validation loss = 7.694860\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 9: Validation loss = 7.572171\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 10: Validation loss = 7.538982\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 11: Validation loss = 7.644860\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 12: Validation loss = 7.560885\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 13: Validation loss = 7.537879\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 14: Validation loss = 7.409173\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 15: Validation loss = 7.716527\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 16: Validation loss = 9.054893\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 17: Validation loss = 9.887174\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 18: Validation loss = 11.041938\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 19: Validation loss = 10.931714\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 20: Validation loss = 11.021660\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 21: Validation loss = 11.851920\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 22: Validation loss = 12.428055\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 23: Validation loss = 12.197300\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 24: Validation loss = 12.571199\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 25: Validation loss = 12.840146\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 26: Validation loss = 12.556603\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 27: Validation loss = 11.466023\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 28: Validation loss = 10.592449\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 29: Validation loss = 11.482223\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 30: Validation loss = 12.570724\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 31: Validation loss = 12.038300\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 32: Validation loss = 11.500591\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 33: Validation loss = 12.383351\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 34: Validation loss = 13.920522\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 35: Validation loss = 14.187962\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 36: Validation loss = 14.020970\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 37: Validation loss = 14.337764\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-04-26 15:32:43,038]\u001b[0m Trial 3 finished with value: 14.928671836853027 and parameters: {'dropout_rate': 0.3489596461025247, 'learning_rate': 3.5191560371327834e-05, 'activation': 'tanh', 'kernel_initializer': 'he_normal'}. Best is trial 0 with value: 0.004662954248487949.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 81: Training loss = 59.086086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 82: Training loss = 63.343739\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 83: Training loss = 66.059761\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 84: Training loss = 63.934540\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 85: Training loss = 61.072273\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 86: Training loss = 61.301338\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 87: Training loss = 60.001030\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 88: Training loss = 59.533443\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 89: Training loss = 58.225948\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 90: Training loss = 63.192429\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 91: Training loss = 64.295250\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 92: Training loss = 67.261269\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 93: Training loss = 69.584442\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 94: Training loss = 72.754982\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 95: Training loss = 78.904572\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 96: Training loss = 80.015099\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 97: Training loss = 79.600151\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 98: Training loss = 80.135452\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 99: Training loss = 80.611504\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 100: Training loss = 73.913666\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 101: Training loss = 73.435043\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 102: Training loss = 71.108521\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 103: Training loss = 68.196754\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 104: Training loss = 66.853226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 105: Training loss = 65.902885\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 106: Training loss = 67.401398\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 107: Training loss = 69.250107\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 108: Training loss = 69.097336\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 4, Training window 109: Training loss = 69.441536\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 110: Training loss = 71.002068\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 111: Training loss = 71.639778\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 112: Training loss = 73.052559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 113: Training loss = 75.179497\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 114: Training loss = 76.015839\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 115: Training loss = 76.242142\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 116: Training loss = 74.962120\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 117: Training loss = 74.155861\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 118: Training loss = 73.106995\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 119: Training loss = 71.005920\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 120: Training loss = 67.981812\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 121: Training loss = 65.797348\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 122: Training loss = 64.098831\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 123: Training loss = 63.960056\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 124: Training loss = 64.320564\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 125: Training loss = 65.314857\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 126: Training loss = 66.775581\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 127: Training loss = 68.713989\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 128: Training loss = 70.492622\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 129: Training loss = 73.339737\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 130: Training loss = 76.992531\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 131: Training loss = 80.139801\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 132: Training loss = 82.638168\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 133: Training loss = 83.721870\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 134: Training loss = 83.009666\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 135: Training loss = 149.882019\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 136: Training loss = 261.203094\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 137: Training loss = 258.394928\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 138: Training loss = 255.397156\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 139: Training loss = 251.810776\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 140: Training loss = 248.185654\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 141: Training loss = 244.337921\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 142: Training loss = 240.784225\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 143: Training loss = 257.239685\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 144: Training loss = 253.060410\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 145: Training loss = 180.637787\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 146: Training loss = 65.867523\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 147: Training loss = 65.699585\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 148: Training loss = 64.287247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 149: Training loss = 62.131088\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Training window 150: Training loss = 61.686714\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 151: Training loss = 62.866306\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Training window 152: Training loss = 66.007545\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 1: Validation loss = 50.322643\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 2: Validation loss = 58.168678\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 3: Validation loss = 65.602905\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 4: Validation loss = 70.880127\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 5: Validation loss = 75.971260\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 6: Validation loss = 82.582642\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 7: Validation loss = 88.532234\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 8: Validation loss = 93.379204\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 9: Validation loss = 95.664108\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 10: Validation loss = 97.176483\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 11: Validation loss = 97.251976\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 12: Validation loss = 93.491592\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 13: Validation loss = 83.606773\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 14: Validation loss = 74.249229\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 15: Validation loss = 66.544411\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 16: Validation loss = 58.756413\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 17: Validation loss = 52.769352\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 18: Validation loss = 46.629677\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 19: Validation loss = 42.104439\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 20: Validation loss = 37.134907\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 21: Validation loss = 32.135002\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 22: Validation loss = 29.099087\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 23: Validation loss = 32.496250\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 24: Validation loss = 35.319649\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 25: Validation loss = 35.776836\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 26: Validation loss = 36.179577\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 27: Validation loss = 36.590302\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 28: Validation loss = 36.734520\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 29: Validation loss = 36.239170\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 30: Validation loss = 35.351181\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 4, Validation window 31: Validation loss = 34.166248\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 32: Validation loss = 32.010338\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 33: Validation loss = 38.693783\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 34: Validation loss = 89.880936\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 35: Validation loss = 107.515327\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 36: Validation loss = 106.447845\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 37: Validation loss = 103.396408\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 4, Validation window 38: Validation loss = 100.590561\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 1: Training loss = 166.860107\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 2: Training loss = 170.782898\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 3: Training loss = 177.046768\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 4: Training loss = 134.788620\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 5: Training loss = 139.745544\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 6: Training loss = 143.511780\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 7: Training loss = 142.564026\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 8: Training loss = 140.764832\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 9: Training loss = 139.109924\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 10: Training loss = 63.455830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 11: Training loss = 61.332226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 12: Training loss = 62.229912\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 13: Training loss = 62.666977\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 14: Training loss = 61.599964\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 15: Training loss = 60.263100\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 16: Training loss = 55.184738\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 17: Training loss = 47.902592\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 18: Training loss = 41.437931\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 19: Training loss = 36.676899\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 20: Training loss = 40.826637\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 21: Training loss = 47.613548\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 22: Training loss = 50.349995\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 23: Training loss = 50.366962\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 24: Training loss = 51.663658\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 25: Training loss = 52.679142\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 26: Training loss = 51.621780\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 27: Training loss = 53.496799\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 28: Training loss = 58.735039\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 29: Training loss = 63.510311\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 30: Training loss = 60.248821\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 31: Training loss = 55.730492\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 32: Training loss = 53.963001\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 33: Training loss = 45.850391\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 34: Training loss = 39.189663\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 35: Training loss = 33.730446\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 36: Training loss = 36.314419\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 37: Training loss = 38.728683\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 38: Training loss = 40.150829\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 39: Training loss = 42.777363\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 40: Training loss = 48.916752\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 41: Training loss = 53.758575\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 42: Training loss = 54.025333\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 43: Training loss = 55.747192\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 44: Training loss = 54.815140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 45: Training loss = 55.127441\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 46: Training loss = 55.558212\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 47: Training loss = 52.084568\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 48: Training loss = 45.610455\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 49: Training loss = 39.630901\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 50: Training loss = 35.326302\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 51: Training loss = 29.546024\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 52: Training loss = 23.808908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 53: Training loss = 22.808592\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 54: Training loss = 22.150057\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 55: Training loss = 20.614538\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 56: Training loss = 17.023514\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 57: Training loss = 16.773119\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 58: Training loss = 17.117043\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 59: Training loss = 15.495484\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 60: Training loss = 14.040069\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 61: Training loss = 17.290182\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 62: Training loss = 23.247629\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 63: Training loss = 29.098331\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 64: Training loss = 36.057079\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 65: Training loss = 43.089596\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 66: Training loss = 44.587795\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 67: Training loss = 45.436691\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 68: Training loss = 46.775902\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 69: Training loss = 50.535542\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 70: Training loss = 48.396652\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 71: Training loss = 44.180656\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 72: Training loss = 39.413147\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 73: Training loss = 33.769531\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 74: Training loss = 31.469290\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 75: Training loss = 27.823574\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 76: Training loss = 30.029261\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 77: Training loss = 34.923031\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 78: Training loss = 39.204411\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 79: Training loss = 42.179699\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 80: Training loss = 48.949226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 81: Training loss = 52.945152\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 82: Training loss = 54.552483\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 83: Training loss = 56.578587\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 84: Training loss = 54.918301\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 85: Training loss = 52.102577\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 86: Training loss = 51.711498\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 87: Training loss = 49.809044\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 88: Training loss = 49.047768\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 89: Training loss = 47.334339\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 90: Training loss = 52.527328\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 91: Training loss = 53.534409\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 92: Training loss = 56.456253\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 93: Training loss = 59.145470\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 94: Training loss = 61.893738\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 95: Training loss = 67.132675\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 96: Training loss = 67.740051\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 97: Training loss = 66.845451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 98: Training loss = 67.512001\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 99: Training loss = 68.169403\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 100: Training loss = 61.018742\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 101: Training loss = 60.495148\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 102: Training loss = 58.153309\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 103: Training loss = 54.892021\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 104: Training loss = 53.219357\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 105: Training loss = 52.012520\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 106: Training loss = 54.047619\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 107: Training loss = 56.699528\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 108: Training loss = 56.541374\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 109: Training loss = 56.973072\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 110: Training loss = 58.798141\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 111: Training loss = 59.344643\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 112: Training loss = 60.544834\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 113: Training loss = 62.798626\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 114: Training loss = 63.727226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 115: Training loss = 63.850803\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 116: Training loss = 61.954323\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 117: Training loss = 60.709198\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 118: Training loss = 59.093056\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 119: Training loss = 56.161140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 120: Training loss = 51.619419\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 121: Training loss = 47.702610\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 122: Training loss = 43.700394\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 123: Training loss = 40.937695\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 124: Training loss = 38.119896\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 125: Training loss = 36.142651\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 126: Training loss = 35.587078\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 127: Training loss = 36.200874\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 128: Training loss = 37.056976\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 129: Training loss = 38.763889\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 130: Training loss = 41.813114\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 131: Training loss = 44.838913\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 132: Training loss = 47.767769\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 133: Training loss = 50.104858\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 134: Training loss = 51.324329\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 135: Training loss = 127.581467\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 136: Training loss = 247.649368\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 137: Training loss = 246.637421\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 138: Training loss = 245.039215\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 139: Training loss = 242.979858\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 140: Training loss = 240.625717\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 141: Training loss = 237.677429\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 142: Training loss = 234.392761\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 143: Training loss = 251.206787\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 144: Training loss = 249.237000\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 145: Training loss = 171.202194\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 5, Training window 146: Training loss = 51.064274\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 147: Training loss = 50.343487\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Training window 148: Training loss = 48.109905\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 149: Training loss = 45.042442\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 150: Training loss = 43.266613\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 151: Training loss = 42.507446\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Training window 152: Training loss = 43.446259\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 1: Validation loss = 24.549793\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 2: Validation loss = 26.342873\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 3: Validation loss = 28.045195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 4: Validation loss = 27.241341\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 5: Validation loss = 26.310204\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 6: Validation loss = 27.345751\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 7: Validation loss = 28.570269\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 8: Validation loss = 29.861891\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 9: Validation loss = 30.352465\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 10: Validation loss = 30.596430\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 11: Validation loss = 30.126581\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 12: Validation loss = 28.355913\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 13: Validation loss = 26.012146\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 14: Validation loss = 22.822718\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 15: Validation loss = 21.150276\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 16: Validation loss = 19.317116\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 17: Validation loss = 18.488977\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 18: Validation loss = 17.137123\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 19: Validation loss = 15.856705\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 20: Validation loss = 14.538498\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 21: Validation loss = 13.481404\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 22: Validation loss = 12.385930\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 23: Validation loss = 12.256443\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 24: Validation loss = 13.255681\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 25: Validation loss = 12.465837\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 26: Validation loss = 11.608212\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 27: Validation loss = 10.796296\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 28: Validation loss = 9.914738\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 29: Validation loss = 9.025640\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 30: Validation loss = 7.716108\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 31: Validation loss = 7.067281\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 32: Validation loss = 7.267359\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 33: Validation loss = 17.350519\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 34: Validation loss = 73.664940\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 5, Validation window 35: Validation loss = 95.233727\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 36: Validation loss = 98.422028\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 37: Validation loss = 98.867546\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 5, Validation window 38: Validation loss = 99.251701\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 1: Training loss = 160.403290\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 2: Training loss = 164.139282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 3: Training loss = 170.994904\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 4: Training loss = 127.030701\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 5: Training loss = 131.009003\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 6: Training loss = 134.894165\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 7: Training loss = 133.591248\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 8: Training loss = 131.218796\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Training window 9: Training loss = 129.659210\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 10: Training loss = 54.595333\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 11: Training loss = 52.588158\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 12: Training loss = 52.966030\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 13: Training loss = 53.579151\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 14: Training loss = 52.369358\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 15: Training loss = 51.893669\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 16: Training loss = 47.558750\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 17: Training loss = 42.898170\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 18: Training loss = 39.100075\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 19: Training loss = 34.617287\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 20: Training loss = 37.956272\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 21: Training loss = 44.873829\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 22: Training loss = 48.226566\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 23: Training loss = 48.077625\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 24: Training loss = 49.814129\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 25: Training loss = 50.448483\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 26: Training loss = 48.789272\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 27: Training loss = 48.127060\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 28: Training loss = 50.885998\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 29: Training loss = 55.575001\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 30: Training loss = 52.361973\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 31: Training loss = 47.248905\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 32: Training loss = 45.308800\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 33: Training loss = 40.446587\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 34: Training loss = 39.263599\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 35: Training loss = 34.490307\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 36: Training loss = 37.256489\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 37: Training loss = 39.196407\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 38: Training loss = 40.486557\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 39: Training loss = 43.160828\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 40: Training loss = 49.613232\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 41: Training loss = 54.781517\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 42: Training loss = 54.924446\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 43: Training loss = 53.708176\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 44: Training loss = 48.219368\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 45: Training loss = 47.566765\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 46: Training loss = 47.105755\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 47: Training loss = 44.080780\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 48: Training loss = 39.882263\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 49: Training loss = 33.565845\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 50: Training loss = 28.572285\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 51: Training loss = 22.290819\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 52: Training loss = 16.712852\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 53: Training loss = 15.999857\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 54: Training loss = 14.868906\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 55: Training loss = 15.092647\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 56: Training loss = 13.412695\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 57: Training loss = 14.573186\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 58: Training loss = 13.648189\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 59: Training loss = 12.586266\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 60: Training loss = 11.516179\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 61: Training loss = 14.848223\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 62: Training loss = 20.695183\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 63: Training loss = 25.506187\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 64: Training loss = 31.479143\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 65: Training loss = 36.583939\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 66: Training loss = 36.854870\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 67: Training loss = 36.380249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 68: Training loss = 36.699604\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 69: Training loss = 39.547024\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 70: Training loss = 40.893829\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 71: Training loss = 43.232193\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 72: Training loss = 45.386551\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 73: Training loss = 41.647800\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 74: Training loss = 39.428822\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 75: Training loss = 36.613342\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 76: Training loss = 39.567871\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 77: Training loss = 44.574219\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 78: Training loss = 49.054001\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 79: Training loss = 52.538868\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 80: Training loss = 55.904793\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 81: Training loss = 53.790684\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 82: Training loss = 48.607597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 83: Training loss = 48.327908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 84: Training loss = 47.162357\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 85: Training loss = 44.656258\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 86: Training loss = 43.555412\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 87: Training loss = 41.092705\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 88: Training loss = 39.889198\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 89: Training loss = 37.634041\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 90: Training loss = 41.121517\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 91: Training loss = 42.044666\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 92: Training loss = 44.570164\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 93: Training loss = 47.223949\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 94: Training loss = 49.152126\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 95: Training loss = 53.119198\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 96: Training loss = 53.136097\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 97: Training loss = 51.710625\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 98: Training loss = 52.508163\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 99: Training loss = 53.596886\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 100: Training loss = 48.185181\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 101: Training loss = 46.999546\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 102: Training loss = 45.194786\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 103: Training loss = 42.185928\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 104: Training loss = 40.429256\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 105: Training loss = 39.089687\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 106: Training loss = 41.511734\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 107: Training loss = 44.820217\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 108: Training loss = 44.722195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 109: Training loss = 45.156132\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 110: Training loss = 46.989811\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 111: Training loss = 47.887302\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 112: Training loss = 48.474094\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 113: Training loss = 50.379986\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 114: Training loss = 51.018726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 115: Training loss = 50.736809\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 116: Training loss = 48.080032\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 117: Training loss = 46.146702\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 118: Training loss = 43.739273\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 119: Training loss = 40.070660\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 120: Training loss = 34.936058\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 121: Training loss = 30.317406\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 122: Training loss = 25.622578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 123: Training loss = 21.907902\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 124: Training loss = 18.217680\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 125: Training loss = 14.987997\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 126: Training loss = 13.050849\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 127: Training loss = 11.900090\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 128: Training loss = 11.413313\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 129: Training loss = 11.215896\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 130: Training loss = 12.274829\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 131: Training loss = 13.568340\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 132: Training loss = 14.952989\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 133: Training loss = 16.560175\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 134: Training loss = 17.736038\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 135: Training loss = 91.852798\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 136: Training loss = 201.048523\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 137: Training loss = 202.818878\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 138: Training loss = 203.886566\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 139: Training loss = 204.791687\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 140: Training loss = 204.923767\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 141: Training loss = 204.419388\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 142: Training loss = 203.351456\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 143: Training loss = 218.600967\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 144: Training loss = 218.411438\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 145: Training loss = 145.377121\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 146: Training loss = 39.919762\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 147: Training loss = 38.873493\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 148: Training loss = 36.674343\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Training window 149: Training loss = 34.366768\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 150: Training loss = 32.833469\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 151: Training loss = 31.483774\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Training window 152: Training loss = 30.960669\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 1: Validation loss = 14.253641\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 2: Validation loss = 13.076782\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 3: Validation loss = 12.208184\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 4: Validation loss = 8.789280\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Validation window 5: Validation loss = 6.045288\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Validation window 6: Validation loss = 4.939252\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 7: Validation loss = 4.402649\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 8: Validation loss = 4.131579\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 9: Validation loss = 4.244154\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 10: Validation loss = 4.357203\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 11: Validation loss = 4.604573\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 12: Validation loss = 5.864472\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 13: Validation loss = 8.467424\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 14: Validation loss = 9.182613\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 15: Validation loss = 10.293586\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 16: Validation loss = 11.390462\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 17: Validation loss = 12.272185\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 18: Validation loss = 13.293846\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 19: Validation loss = 13.094717\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 20: Validation loss = 12.913980\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 21: Validation loss = 13.346285\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 22: Validation loss = 12.721013\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 23: Validation loss = 10.376937\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 24: Validation loss = 10.258369\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 25: Validation loss = 9.898852\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 26: Validation loss = 9.758945\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 27: Validation loss = 9.201758\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 6, Validation window 28: Validation loss = 8.820128\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 29: Validation loss = 9.940153\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 30: Validation loss = 11.474318\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 31: Validation loss = 11.674727\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 32: Validation loss = 13.214952\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 33: Validation loss = 22.567778\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 34: Validation loss = 71.646843\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 6, Validation window 35: Validation loss = 89.449966\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 36: Validation loss = 92.420509\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 37: Validation loss = 94.711983\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 6, Validation window 38: Validation loss = 97.633881\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 1: Training loss = 136.437729\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 2: Training loss = 139.558487\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 3: Training loss = 146.026627\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 4: Training loss = 108.194649\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 5: Training loss = 111.613327\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 6: Training loss = 115.290161\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 7: Training loss = 113.755424\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 8: Training loss = 111.075218\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 9: Training loss = 109.963623\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 10: Training loss = 47.628162\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 11: Training loss = 47.266129\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 12: Training loss = 47.234226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 13: Training loss = 48.101723\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 14: Training loss = 46.850708\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 15: Training loss = 47.309872\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 16: Training loss = 44.407955\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 17: Training loss = 44.014187\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 18: Training loss = 44.490524\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 19: Training loss = 41.142952\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 20: Training loss = 42.837547\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 21: Training loss = 48.833080\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 22: Training loss = 52.520706\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 23: Training loss = 52.084602\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 24: Training loss = 54.194901\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 25: Training loss = 54.433659\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 26: Training loss = 52.333069\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 27: Training loss = 48.233818\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 28: Training loss = 47.108662\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 29: Training loss = 50.922733\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 30: Training loss = 48.100113\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 31: Training loss = 42.743462\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 32: Training loss = 40.760593\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 33: Training loss = 40.935112\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 34: Training loss = 46.982162\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 35: Training loss = 43.657993\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 36: Training loss = 46.180210\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 37: Training loss = 47.238228\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 38: Training loss = 48.163860\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 39: Training loss = 50.555912\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 40: Training loss = 56.580688\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 41: Training loss = 61.499825\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 42: Training loss = 61.475758\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 43: Training loss = 56.221581\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 44: Training loss = 45.197823\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 45: Training loss = 43.427971\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 9ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 46: Training loss = 41.997776\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 47: Training loss = 40.478931\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 48: Training loss = 40.792431\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 49: Training loss = 35.101433\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 50: Training loss = 29.901062\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 51: Training loss = 23.812271\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 52: Training loss = 19.138309\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 53: Training loss = 19.113462\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 54: Training loss = 18.211248\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 55: Training loss = 21.133692\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 56: Training loss = 22.391678\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 57: Training loss = 24.961420\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 58: Training loss = 21.667282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 59: Training loss = 21.416496\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 60: Training loss = 20.987261\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 61: Training loss = 23.943226\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 62: Training loss = 28.879047\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 63: Training loss = 31.659410\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 64: Training loss = 35.238064\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 65: Training loss = 36.750317\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 66: Training loss = 35.584778\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 67: Training loss = 33.616611\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 68: Training loss = 32.578896\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 69: Training loss = 33.693905\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 70: Training loss = 39.846687\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 71: Training loss = 51.894928\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 72: Training loss = 64.389091\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 73: Training loss = 64.303246\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 74: Training loss = 62.601501\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 75: Training loss = 60.807812\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 76: Training loss = 63.568821\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 77: Training loss = 67.591881\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 78: Training loss = 71.556572\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 79: Training loss = 75.204247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 80: Training loss = 73.238281\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 81: Training loss = 61.809414\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 82: Training loss = 46.528831\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 83: Training loss = 42.604050\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 84: Training loss = 41.697399\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 85: Training loss = 39.698750\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 86: Training loss = 37.856045\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 87: Training loss = 35.164391\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 88: Training loss = 33.568089\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 89: Training loss = 30.921593\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 90: Training loss = 31.879385\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 91: Training loss = 32.711170\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 92: Training loss = 34.736900\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 93: Training loss = 37.074596\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 94: Training loss = 38.230648\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 95: Training loss = 40.862457\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 96: Training loss = 40.844742\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 97: Training loss = 39.316704\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 98: Training loss = 40.226887\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 99: Training loss = 41.721897\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 100: Training loss = 38.926216\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 101: Training loss = 37.092293\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 102: Training loss = 36.248116\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 103: Training loss = 33.821552\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 104: Training loss = 32.060154\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 105: Training loss = 30.542435\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 106: Training loss = 32.695709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 107: Training loss = 35.905556\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 108: Training loss = 35.820930\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 109: Training loss = 36.217564\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 110: Training loss = 37.867184\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Training window 111: Training loss = 39.102703\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 112: Training loss = 38.828396\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 113: Training loss = 40.353718\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 114: Training loss = 40.715195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 115: Training loss = 40.091099\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 116: Training loss = 37.014091\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 117: Training loss = 34.630123\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 118: Training loss = 31.786396\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 119: Training loss = 28.170309\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 120: Training loss = 24.473261\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 121: Training loss = 21.646000\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 122: Training loss = 19.962011\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 123: Training loss = 19.460546\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 124: Training loss = 20.182932\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 125: Training loss = 20.348564\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 126: Training loss = 19.907198\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 127: Training loss = 18.303984\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 128: Training loss = 17.360601\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 129: Training loss = 16.154821\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 130: Training loss = 15.141735\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 131: Training loss = 13.814806\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 132: Training loss = 11.783471\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 133: Training loss = 9.756107\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 134: Training loss = 7.132521\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 135: Training loss = 69.260773\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 136: Training loss = 153.443100\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 137: Training loss = 156.645599\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 138: Training loss = 159.748398\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 139: Training loss = 162.877472\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 140: Training loss = 164.818161\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 141: Training loss = 166.667068\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 142: Training loss = 168.671249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 143: Training loss = 182.314529\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 144: Training loss = 182.305969\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 145: Training loss = 118.976830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 146: Training loss = 38.962166\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 147: Training loss = 38.249138\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 148: Training loss = 37.349350\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 149: Training loss = 37.813744\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Training window 150: Training loss = 39.093697\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 151: Training loss = 40.472454\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Training window 152: Training loss = 41.810635\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 1: Validation loss = 33.121323\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 2: Validation loss = 36.947147\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 3: Validation loss = 42.291515\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 4: Validation loss = 45.298550\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 5: Validation loss = 50.431484\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 6: Validation loss = 55.890884\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 7: Validation loss = 60.666550\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Validation window 8: Validation loss = 64.342186\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Validation window 9: Validation loss = 66.994034\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 10: Validation loss = 69.064903\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 11: Validation loss = 71.282806\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 12: Validation loss = 74.808212\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 13: Validation loss = 74.306427\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Validation window 14: Validation loss = 70.845627\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 15: Validation loss = 65.728539\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 16: Validation loss = 61.136559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 17: Validation loss = 55.880627\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 18: Validation loss = 52.224709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 19: Validation loss = 47.630436\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 20: Validation loss = 42.404774\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 21: Validation loss = 38.211983\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 22: Validation loss = 33.733772\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 7, Validation window 23: Validation loss = 31.025383\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 24: Validation loss = 31.416206\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 25: Validation loss = 33.767017\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 26: Validation loss = 36.741451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 27: Validation loss = 38.475086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 28: Validation loss = 40.496117\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 29: Validation loss = 45.880219\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 30: Validation loss = 53.179077\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 7, Validation window 31: Validation loss = 54.036907\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 32: Validation loss = 55.614532\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 33: Validation loss = 63.957272\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 34: Validation loss = 107.420403\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 35: Validation loss = 121.549011\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 36: Validation loss = 122.096794\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 37: Validation loss = 124.616272\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 7, Validation window 38: Validation loss = 129.055405\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 1: Training loss = 121.634300\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 2: Training loss = 123.294197\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 3: Training loss = 128.438461\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 4: Training loss = 93.055893\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 5: Training loss = 95.374596\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 6: Training loss = 98.834023\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 7: Training loss = 97.326942\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 8: Training loss = 94.650162\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 9: Training loss = 93.937004\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 10: Training loss = 43.085747\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 11: Training loss = 44.677689\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 12: Training loss = 44.805515\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 13: Training loss = 46.104740\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 14: Training loss = 44.814140\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 15: Training loss = 46.206726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 16: Training loss = 45.152451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 17: Training loss = 50.004246\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 18: Training loss = 55.649796\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 19: Training loss = 54.160378\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 20: Training loss = 53.690430\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 21: Training loss = 58.062172\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 22: Training loss = 61.827255\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 23: Training loss = 60.933727\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 24: Training loss = 63.399254\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 25: Training loss = 63.078522\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 26: Training loss = 60.637623\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 27: Training loss = 52.564476\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 28: Training loss = 46.724052\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 29: Training loss = 49.114346\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 30: Training loss = 46.885872\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 31: Training loss = 41.491974\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 32: Training loss = 39.541080\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 33: Training loss = 45.807369\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 34: Training loss = 60.175697\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 35: Training loss = 59.054401\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 36: Training loss = 61.040752\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 37: Training loss = 60.885597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 38: Training loss = 61.295757\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 39: Training loss = 63.201466\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 40: Training loss = 68.314171\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 41: Training loss = 72.613365\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 42: Training loss = 72.429726\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 43: Training loss = 62.596348\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 44: Training loss = 45.585884\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 45: Training loss = 42.516754\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 46: Training loss = 40.117203\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 47: Training loss = 40.813545\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 48: Training loss = 46.503361\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 49: Training loss = 42.010365\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 50: Training loss = 36.903355\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 51: Training loss = 31.406015\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 52: Training loss = 27.991898\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 53: Training loss = 28.801863\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 54: Training loss = 28.307373\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 55: Training loss = 34.177647\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 56: Training loss = 38.670113\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 57: Training loss = 42.413986\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 58: Training loss = 36.564266\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 59: Training loss = 37.102520\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 60: Training loss = 37.292675\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 61: Training loss = 39.457294\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 62: Training loss = 42.961048\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 63: Training loss = 43.174461\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 64: Training loss = 43.783718\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 65: Training loss = 41.238186\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 66: Training loss = 38.661907\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 67: Training loss = 35.278820\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 68: Training loss = 32.884823\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 69: Training loss = 32.075531\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 70: Training loss = 42.672268\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 71: Training loss = 63.220814\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 72: Training loss = 84.310120\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 73: Training loss = 87.462090\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 74: Training loss = 86.083122\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 75: Training loss = 84.788200\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 76: Training loss = 86.595993\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 77: Training loss = 89.116936\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 78: Training loss = 92.109070\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 79: Training loss = 95.509552\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 80: Training loss = 88.653145\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 81: Training loss = 69.706596\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 82: Training loss = 46.830555\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 83: Training loss = 40.018337\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 84: Training loss = 39.094330\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 85: Training loss = 37.644512\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 86: Training loss = 35.268780\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 87: Training loss = 32.671024\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 88: Training loss = 30.910971\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 89: Training loss = 28.190155\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 90: Training loss = 27.095718\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 91: Training loss = 27.926723\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 92: Training loss = 29.639914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 93: Training loss = 31.755980\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 94: Training loss = 32.579971\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 95: Training loss = 34.196037\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 96: Training loss = 34.581371\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 97: Training loss = 33.213081\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 98: Training loss = 34.209728\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 99: Training loss = 35.877029\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 100: Training loss = 35.430714\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 101: Training loss = 33.551609\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 102: Training loss = 33.776325\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 103: Training loss = 31.776455\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 104: Training loss = 29.976816\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 105: Training loss = 28.286514\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 106: Training loss = 29.922234\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 107: Training loss = 32.756943\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 108: Training loss = 32.649220\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 109: Training loss = 33.084087\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 110: Training loss = 34.635838\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 111: Training loss = 35.822979\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 112: Training loss = 34.724087\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 113: Training loss = 36.252747\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 114: Training loss = 36.713608\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 115: Training loss = 36.143154\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 116: Training loss = 33.116283\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 117: Training loss = 30.794159\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 118: Training loss = 28.008488\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 119: Training loss = 24.778353\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 120: Training loss = 22.202461\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 121: Training loss = 20.649334\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 122: Training loss = 20.723375\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 123: Training loss = 21.970285\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 124: Training loss = 24.867077\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 125: Training loss = 26.884199\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 126: Training loss = 27.368797\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 127: Training loss = 25.793118\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 128: Training loss = 24.773497\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 129: Training loss = 23.288483\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 130: Training loss = 21.540997\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 131: Training loss = 19.236464\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 132: Training loss = 15.965675\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 133: Training loss = 12.511056\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 134: Training loss = 8.518307\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 135: Training loss = 38.806053\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 136: Training loss = 71.724403\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 137: Training loss = 74.594902\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 138: Training loss = 77.757256\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 139: Training loss = 80.944778\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 140: Training loss = 82.835823\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 141: Training loss = 84.739914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 142: Training loss = 86.808853\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 143: Training loss = 92.116211\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 144: Training loss = 91.244133\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 145: Training loss = 60.227711\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 146: Training loss = 32.719120\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 147: Training loss = 31.978786\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 148: Training loss = 31.181032\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 149: Training loss = 31.822866\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Training window 150: Training loss = 33.025150\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Training window 151: Training loss = 34.384014\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Training window 152: Training loss = 35.705757\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 1: Validation loss = 35.806290\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 2: Validation loss = 40.198059\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 3: Validation loss = 45.252777\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 4: Validation loss = 47.419643\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 5: Validation loss = 51.529785\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 8, Validation window 6: Validation loss = 55.617573\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 7: Validation loss = 58.515911\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 8: Validation loss = 61.159191\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 9: Validation loss = 62.651310\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 10: Validation loss = 63.631252\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 11: Validation loss = 64.530258\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 12: Validation loss = 67.093254\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 13: Validation loss = 67.387779\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 14: Validation loss = 64.615334\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 15: Validation loss = 60.446621\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 16: Validation loss = 56.953747\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 17: Validation loss = 53.173153\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 18: Validation loss = 50.087204\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 19: Validation loss = 45.979008\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 20: Validation loss = 41.290707\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 21: Validation loss = 37.870239\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 22: Validation loss = 33.551880\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 23: Validation loss = 29.534807\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 24: Validation loss = 28.754274\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 25: Validation loss = 29.808197\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 26: Validation loss = 31.293217\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 27: Validation loss = 31.910738\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 28: Validation loss = 32.850494\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 29: Validation loss = 36.740685\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 30: Validation loss = 41.949425\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 31: Validation loss = 42.206799\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 32: Validation loss = 44.401207\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 33: Validation loss = 48.407249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 34: Validation loss = 62.900574\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 8, Validation window 35: Validation loss = 66.891594\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 36: Validation loss = 67.891190\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 37: Validation loss = 71.239761\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 8, Validation window 38: Validation loss = 75.939987\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 1: Training loss = 55.009666\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 2: Training loss = 57.289639\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 3: Training loss = 62.883865\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 4: Training loss = 56.384426\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 5: Training loss = 59.755390\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 6: Training loss = 63.014709\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 7: Training loss = 61.543236\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 8: Training loss = 58.996342\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 9: Training loss = 58.565239\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 10: Training loss = 46.309959\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 11: Training loss = 47.616405\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 12: Training loss = 47.132809\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 13: Training loss = 48.464016\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 14: Training loss = 47.070164\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 15: Training loss = 49.420769\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 16: Training loss = 48.738132\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 17: Training loss = 53.615082\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 18: Training loss = 59.079353\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 19: Training loss = 57.105247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 20: Training loss = 56.777893\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 21: Training loss = 61.738235\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 22: Training loss = 65.592377\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 23: Training loss = 64.427826\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 24: Training loss = 67.220871\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 25: Training loss = 66.549995\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 26: Training loss = 63.717884\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 27: Training loss = 55.676659\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 28: Training loss = 49.966873\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 29: Training loss = 52.916447\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 30: Training loss = 50.465061\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 31: Training loss = 44.373653\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 32: Training loss = 42.290123\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 33: Training loss = 47.813618\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 34: Training loss = 61.161751\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 35: Training loss = 59.465389\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 36: Training loss = 61.806179\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 37: Training loss = 61.548035\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 38: Training loss = 61.862282\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 39: Training loss = 63.262264\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 40: Training loss = 68.554863\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 41: Training loss = 72.955795\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 42: Training loss = 72.624680\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 43: Training loss = 63.560493\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 44: Training loss = 47.497086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 45: Training loss = 44.145603\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 46: Training loss = 41.299103\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 47: Training loss = 41.645405\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 48: Training loss = 46.054272\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 49: Training loss = 41.179474\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 50: Training loss = 35.739155\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 51: Training loss = 30.012886\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 52: Training loss = 26.307074\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 53: Training loss = 26.664360\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 54: Training loss = 25.541750\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 55: Training loss = 30.691303\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 56: Training loss = 34.606438\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 57: Training loss = 38.192966\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 58: Training loss = 33.390823\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 59: Training loss = 33.849274\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 60: Training loss = 33.983948\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 61: Training loss = 36.135250\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 62: Training loss = 39.836468\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 63: Training loss = 40.460354\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 64: Training loss = 41.707066\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 65: Training loss = 39.993320\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 66: Training loss = 37.552792\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 67: Training loss = 34.332386\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 68: Training loss = 32.116283\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 69: Training loss = 31.595276\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 70: Training loss = 41.178856\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 71: Training loss = 59.027283\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 72: Training loss = 76.834480\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 73: Training loss = 78.975700\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 74: Training loss = 77.410950\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 75: Training loss = 77.842918\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 76: Training loss = 81.566025\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 77: Training loss = 85.022209\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 78: Training loss = 88.404083\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 79: Training loss = 91.994835\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 80: Training loss = 86.439430\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 81: Training loss = 71.164413\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 82: Training loss = 51.853947\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 83: Training loss = 46.229305\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 84: Training loss = 46.784317\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 85: Training loss = 46.121811\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 86: Training loss = 42.637547\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 87: Training loss = 39.380959\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 88: Training loss = 37.460384\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 89: Training loss = 34.720943\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 90: Training loss = 33.628414\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 91: Training loss = 33.842815\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 92: Training loss = 35.324352\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 93: Training loss = 37.415909\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 94: Training loss = 37.086620\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 95: Training loss = 36.354336\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 96: Training loss = 36.422962\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 97: Training loss = 35.275871\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 98: Training loss = 36.664089\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 99: Training loss = 38.123222\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 100: Training loss = 37.116001\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 101: Training loss = 35.877548\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 102: Training loss = 36.213020\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 103: Training loss = 33.919926\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 104: Training loss = 31.890255\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 105: Training loss = 30.004471\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 106: Training loss = 31.496828\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 107: Training loss = 34.200100\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 108: Training loss = 33.759949\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 109: Training loss = 34.409512\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 110: Training loss = 36.188465\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 111: Training loss = 36.652058\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 112: Training loss = 35.535374\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 113: Training loss = 37.473469\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 114: Training loss = 38.261749\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 115: Training loss = 37.862923\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 116: Training loss = 34.989052\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 117: Training loss = 32.860176\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 118: Training loss = 30.200180\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 119: Training loss = 26.865900\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 120: Training loss = 23.181276\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 121: Training loss = 20.158522\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 122: Training loss = 17.794155\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 123: Training loss = 16.418913\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 124: Training loss = 15.989383\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 125: Training loss = 15.748054\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 126: Training loss = 15.208883\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 127: Training loss = 13.532895\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 128: Training loss = 12.442433\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 129: Training loss = 11.023554\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 130: Training loss = 10.143578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 131: Training loss = 9.090872\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 132: Training loss = 7.822860\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 133: Training loss = 6.532625\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 134: Training loss = 5.202424\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 135: Training loss = 11.838451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 136: Training loss = 18.102869\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 137: Training loss = 21.538010\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 138: Training loss = 24.671461\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 139: Training loss = 27.761314\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 140: Training loss = 29.775553\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 141: Training loss = 31.403097\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 142: Training loss = 32.377602\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 143: Training loss = 32.787296\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 144: Training loss = 33.136246\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 145: Training loss = 26.703089\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 146: Training loss = 24.026487\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 147: Training loss = 23.121061\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 148: Training loss = 21.643976\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 149: Training loss = 20.440132\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 9, Training window 150: Training loss = 19.745909\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Training window 151: Training loss = 19.444878\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Training window 152: Training loss = 19.726303\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 1: Validation loss = 21.016735\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 2: Validation loss = 21.713520\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 3: Validation loss = 22.300024\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 4: Validation loss = 20.308365\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 5: Validation loss = 19.347031\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 6: Validation loss = 19.288855\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 7: Validation loss = 19.100052\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 8: Validation loss = 19.609901\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 9: Validation loss = 19.774315\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 10: Validation loss = 19.852446\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 11: Validation loss = 19.836437\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 12: Validation loss = 21.264793\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 13: Validation loss = 23.808006\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 14: Validation loss = 24.096830\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 15: Validation loss = 24.150742\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 16: Validation loss = 24.440048\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 17: Validation loss = 24.532696\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 18: Validation loss = 24.341387\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 19: Validation loss = 23.069408\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 20: Validation loss = 21.549648\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 21: Validation loss = 20.815914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 22: Validation loss = 18.819359\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 23: Validation loss = 15.186914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 24: Validation loss = 14.034375\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 25: Validation loss = 13.432395\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 26: Validation loss = 13.042130\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 27: Validation loss = 12.465774\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 28: Validation loss = 12.169310\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 29: Validation loss = 13.600460\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 30: Validation loss = 15.438625\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 31: Validation loss = 15.518483\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 32: Validation loss = 17.977301\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 33: Validation loss = 20.320509\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 34: Validation loss = 23.259142\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 35: Validation loss = 24.186460\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 36: Validation loss = 26.796364\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 9, Validation window 37: Validation loss = 30.493097\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 9, Validation window 38: Validation loss = 34.630650\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 1: Training loss = 33.637455\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 2: Training loss = 37.504261\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 3: Training loss = 43.932381\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 4: Training loss = 48.103630\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 5: Training loss = 51.832829\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 6: Training loss = 54.965324\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 7: Training loss = 53.912556\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 8: Training loss = 51.773861\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 9: Training loss = 51.383629\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 10: Training loss = 49.236237\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 11: Training loss = 48.692249\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 12: Training loss = 47.269077\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 13: Training loss = 48.168034\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 14: Training loss = 46.602501\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 15: Training loss = 48.599686\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 16: Training loss = 47.895451\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 17: Training loss = 52.420967\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 18: Training loss = 57.348625\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 19: Training loss = 55.237144\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 20: Training loss = 54.676147\n","313/313 [==============================] - 1s 3ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 21: Training loss = 59.268536\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 22: Training loss = 63.030178\n","313/313 [==============================] - 1s 3ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 23: Training loss = 62.190216\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 24: Training loss = 64.924194\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 25: Training loss = 64.543365\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 26: Training loss = 61.704597\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 27: Training loss = 53.813290\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 28: Training loss = 48.128731\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 29: Training loss = 50.618881\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 30: Training loss = 48.527279\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 31: Training loss = 42.839870\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 32: Training loss = 40.906410\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 33: Training loss = 46.381824\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 34: Training loss = 59.590172\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 35: Training loss = 57.932652\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 36: Training loss = 59.800930\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 37: Training loss = 59.266273\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 38: Training loss = 59.487961\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 39: Training loss = 61.082466\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 40: Training loss = 66.248825\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 41: Training loss = 70.532570\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 42: Training loss = 70.151070\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 43: Training loss = 61.326599\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 44: Training loss = 46.083305\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 45: Training loss = 42.841446\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 46: Training loss = 40.367676\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 47: Training loss = 40.764877\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 48: Training loss = 44.650711\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 49: Training loss = 39.953899\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 50: Training loss = 34.520687\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 51: Training loss = 28.953074\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 52: Training loss = 25.608578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 53: Training loss = 25.976238\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 54: Training loss = 24.182917\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 55: Training loss = 28.990026\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 56: Training loss = 32.768131\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 57: Training loss = 36.364437\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 58: Training loss = 32.285759\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 59: Training loss = 32.783981\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 60: Training loss = 32.956570\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 61: Training loss = 34.909977\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 62: Training loss = 38.225590\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 63: Training loss = 38.649082\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 64: Training loss = 39.909981\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 65: Training loss = 38.424664\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 66: Training loss = 35.961040\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 67: Training loss = 32.748188\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 68: Training loss = 30.548273\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 69: Training loss = 29.908203\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 70: Training loss = 38.980541\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 71: Training loss = 55.214569\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 72: Training loss = 71.133011\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 73: Training loss = 72.913437\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 74: Training loss = 71.380280\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 75: Training loss = 72.150238\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 76: Training loss = 75.846107\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Training window 77: Training loss = 79.243744\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 78: Training loss = 82.576530\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 79: Training loss = 86.267052\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 80: Training loss = 81.325195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 81: Training loss = 68.139008\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 82: Training loss = 51.177464\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 83: Training loss = 46.440762\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 84: Training loss = 47.416908\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 85: Training loss = 46.762978\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 86: Training loss = 43.823578\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 87: Training loss = 40.753029\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 88: Training loss = 38.917976\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 89: Training loss = 36.353397\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 90: Training loss = 35.485180\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 91: Training loss = 35.174297\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 92: Training loss = 36.540054\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 93: Training loss = 38.482635\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 94: Training loss = 38.048122\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 95: Training loss = 37.403633\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 96: Training loss = 37.381542\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 97: Training loss = 36.564400\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 98: Training loss = 38.232834\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 99: Training loss = 39.203014\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 100: Training loss = 37.754879\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 101: Training loss = 35.762981\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 102: Training loss = 35.264130\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 103: Training loss = 32.702972\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 104: Training loss = 30.386086\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 105: Training loss = 28.229719\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 106: Training loss = 29.308172\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 107: Training loss = 31.573429\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 108: Training loss = 30.816914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 109: Training loss = 31.816055\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 110: Training loss = 33.845512\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 111: Training loss = 35.560661\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 112: Training loss = 35.449169\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 113: Training loss = 37.864037\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 114: Training loss = 39.026569\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 115: Training loss = 38.796425\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 116: Training loss = 36.175182\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 8ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 117: Training loss = 34.264423\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 118: Training loss = 31.839472\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 119: Training loss = 28.645260\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 120: Training loss = 24.512934\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 121: Training loss = 20.695030\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 122: Training loss = 17.003035\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 123: Training loss = 14.025045\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 124: Training loss = 11.812601\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 125: Training loss = 10.405514\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 126: Training loss = 9.389758\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 127: Training loss = 7.685443\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 128: Training loss = 6.504528\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 129: Training loss = 5.050422\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 130: Training loss = 4.577542\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 131: Training loss = 4.160741\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 132: Training loss = 3.974825\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 133: Training loss = 3.867933\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 134: Training loss = 3.910863\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 135: Training loss = 10.455764\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 136: Training loss = 16.424608\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 137: Training loss = 19.683273\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 138: Training loss = 22.528038\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 139: Training loss = 25.313364\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 140: Training loss = 27.237164\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 141: Training loss = 28.566988\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 142: Training loss = 28.829201\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 143: Training loss = 28.913157\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 144: Training loss = 29.799559\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 145: Training loss = 24.298157\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Training window 146: Training loss = 21.570335\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 147: Training loss = 20.941053\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 148: Training loss = 19.149105\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 149: Training loss = 16.867498\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 150: Training loss = 15.174620\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 151: Training loss = 14.028144\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Training window 152: Training loss = 13.835107\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 1: Validation loss = 13.791114\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 2: Validation loss = 12.692564\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 3: Validation loss = 11.459254\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 4: Validation loss = 8.208980\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 5: Validation loss = 5.528688\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 6: Validation loss = 4.336947\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 7: Validation loss = 3.979588\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 8: Validation loss = 3.908178\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 9: Validation loss = 3.783299\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 10: Validation loss = 3.694309\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 11: Validation loss = 3.586937\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 12: Validation loss = 4.386041\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 13: Validation loss = 7.013505\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 14: Validation loss = 7.803933\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 15: Validation loss = 8.943591\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 16: Validation loss = 10.030328\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 17: Validation loss = 10.752295\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 18: Validation loss = 11.386320\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 19: Validation loss = 11.230835\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 20: Validation loss = 11.073171\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 21: Validation loss = 11.127887\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Validation window 22: Validation loss = 10.200914\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Validation window 23: Validation loss = 7.438622\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 24: Validation loss = 6.620393\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 7ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 25: Validation loss = 5.404402\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 26: Validation loss = 4.348247\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 27: Validation loss = 3.396632\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 28: Validation loss = 2.671337\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 29: Validation loss = 2.840511\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 30: Validation loss = 2.998506\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 31: Validation loss = 3.069195\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 32: Validation loss = 5.110341\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 33: Validation loss = 6.964552\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 6ms/step\n","16/16 [==============================] - 0s 4ms/step\n","Iteration 10, Validation window 34: Validation loss = 10.393733\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 35: Validation loss = 12.050177\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 4ms/step\n","16/16 [==============================] - 0s 3ms/step\n","Iteration 10, Validation window 36: Validation loss = 15.012053\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n","Iteration 10, Validation window 37: Validation loss = 17.841789\n","313/313 [==============================] - 1s 2ms/step\n","16/16 [==============================] - 0s 5ms/step\n","16/16 [==============================] - 0s 2ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-04-26 16:23:20,279]\u001b[0m Trial 4 finished with value: 13.83510684967041 and parameters: {'dropout_rate': 0.18752655853422862, 'learning_rate': 2.1607520114280846e-05, 'activation': 'tanh', 'kernel_initializer': None}. Best is trial 0 with value: 0.004662954248487949.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 10, Validation window 38: Validation loss = 20.525066\n"]}]},{"cell_type":"code","source":["study.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_RgMl-Hibg53","executionInfo":{"status":"ok","timestamp":1682527114215,"user_tz":240,"elapsed":641,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"97ae787f-766f-4eec-fb62-0d6a4a097d58"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'dropout_rate': 0.33699129803466454,\n"," 'learning_rate': 0.0008032352533476955,\n"," 'activation': 'relu',\n"," 'kernel_initializer': None}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# retrieve the best hyperparameters\n","best_params = {'dropout_rate': 0.33699129803466454,\n"," 'learning_rate': 0.0008032352533476955,\n"," 'activation': 'relu',\n"," 'kernel_initializer': None}\n","\n","# Train the model with the best hyperparameters\n","\n","\n","# Load the training data\n","train_data = np.array(df.head(10000))\n","\n","\n","# Split the training data into input and output sequences\n","train_input = train_data[:, :]\n","print('train_input shape', train_input.shape)\n","train_output = train_data[:, -1:]\n","print('train_output shape', train_output.shape)\n","\n","# Define the input and output dimensions\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 3\n","\n","# Define the sizes of the hidden layers for each expert\n","expert_hidden_sizes = [16, 32, 64]\n","\n","# Define the sizes of the output layers for each expert\n","expert_output_sizes = [144,144,144]\n","\n","# Define the sizes of the gating network hidden layers\n","gating_hidden_sizes = [16, 8]\n","\n","# Define the size of the output layer of the gating network\n","gating_output_size = num_experts\n","\n","# Define the number of training iterations for the EM algorithm\n","num_iterations = 300\n","\n","# Define the optimization algorithm\n","optimizer = SGD(learning_rate=best_params[\"learning_rate\"], momentum=0.9)\n","\n","# Learning rate scheduler\n","lr_scheduler = LearningRateScheduler(scheduler)\n","\n","\n","moe_model, experts, gating_model = build_moe_model_with_autoencoder_cnn_attention(\n","    input_dim,\n","    output_dim,\n","    expert_hidden_sizes,\n","    expert_output_sizes,\n","    gating_hidden_sizes,\n","    num_experts,\n","    best_params[\"learning_rate\"],\n","    best_params[\"activation\"],\n","    best_params[\"kernel_initializer\"],\n","    best_params[\"dropout_rate\"])\n","\n","all_trainable_variables = []\n","for expert in experts:\n","    all_trainable_variables.extend(expert.trainable_variables)\n","all_trainable_variables.extend(gating_model.trainable_variables)\n","optimizer.build(all_trainable_variables)\n","\n","# Train the MoE model with the EM algorithm\n","iteration = 0\n","while iteration < num_iterations:\n","\n","    # E step: Compute the responsibilities of each expert for each data point\n","    gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","    gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","    # M step: Update the parameters of each expert and the gating network\n","    for i in range(num_experts):\n","        expert_input = train_input\n","        expert_output = experts[i](expert_input)\n","        expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        with tf.GradientTape() as tape:\n","            # Watch the trainable variables of the expert model\n","            tape.watch(experts[i].trainable_variables)\n","\n","            # Define the expert model and calculate the expert_loss\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        # Compute the gradients\n","        expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","        # Clip gradients for expert models\n","        expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","        # Update the variables\n","        optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","    \n","    current_learning_rate = scheduler(iteration, optimizer.learning_rate.numpy())\n","    optimizer.learning_rate.assign(current_learning_rate)\n","\n","    gating_input = train_input\n","\n","    with tf.GradientTape() as tape:\n","        # Watch the trainable variables of the gating model\n","        tape.watch(gating_model.trainable_variables)\n","\n","        # Define the gating model and calculate the gating_loss\n","        gating_output = gating_model(gating_input)\n","        gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(train_input), gating_output)\n","\n","\n","    # Compute the gradients\n","    gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","    # Clip gradients for the gating model\n","    gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","\n","    # Update the variables\n","    optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","    # Evaluate the performance of the MoE model on the training set\n","    train_loss = moe_loss(train_output, moe_model.predict(train_input), gating_model.predict(train_input))\n","\n","\n","    print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","\n","    # Stop training if the learning rate becomes too small\n","    if current_learning_rate < 1e-8:\n","        print('Learning rate dropped below 1e-6 after iteration %d' % iteration)\n","        break\n","\n","    iteration += 1\n","\n","moe_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n","\n","moe_model.save('/content/drive/Shareddrives/1st Paper/moe_models2.h5')\n","gating_model.save('/content/drive/Shareddrives/1st Paper/gating_models2.h5')\n","for i, expert in enumerate(experts):\n","    expert.save(f'/content/drive/Shareddrives/1st Paper/expert_{i}.h5')\n"],"metadata":{"id":"dUJsND_77bFk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682536226021,"user_tz":240,"elapsed":543371,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"8b53c658-cfdb-44b1-d79a-b6ad359f32a7"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["train_input shape (10000, 2)\n","train_output shape (10000, 1)\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 5s 8ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 1: Training loss = 1060.630981\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 3s 8ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 2: Training loss = 4028.753906\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 3: Training loss = 3720.278076\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 4: Training loss = 1003.928772\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 5: Training loss = 299.566956\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 7ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 6: Training loss = 1537.138550\n","313/313 [==============================] - 0s 1ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 7: Training loss = 1743.082397\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 8: Training loss = 3116.142334\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 9: Training loss = 6426.142578\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 10: Training loss = 6893.645508\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 11: Training loss = 4471.842773\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 12: Training loss = 4254.145508\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 13: Training loss = 5748.145508\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 14: Training loss = 9159.358398\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 15: Training loss = 10208.990234\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 16: Training loss = 8984.970703\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 17: Training loss = 6348.549316\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 18: Training loss = 3551.884033\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 19: Training loss = 2359.985352\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 20: Training loss = 1997.284058\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 21: Training loss = 2070.900879\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 22: Training loss = 2392.299072\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 23: Training loss = 2831.460205\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 24: Training loss = 2786.853516\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 25: Training loss = 2418.498779\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 26: Training loss = 1910.067627\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 27: Training loss = 1398.176758\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 28: Training loss = 960.000977\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 29: Training loss = 626.452820\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 30: Training loss = 435.551361\n","313/313 [==============================] - 0s 1ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 31: Training loss = 322.506134\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 32: Training loss = 251.997025\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 33: Training loss = 205.605896\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 34: Training loss = 173.262131\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 35: Training loss = 150.356094\n","313/313 [==============================] - 0s 1ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 36: Training loss = 134.290527\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 37: Training loss = 120.256271\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 38: Training loss = 108.389427\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 39: Training loss = 98.576164\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 40: Training loss = 90.737816\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 41: Training loss = 84.562225\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 42: Training loss = 79.608025\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 43: Training loss = 75.589973\n","313/313 [==============================] - 0s 1ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 44: Training loss = 72.335793\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 45: Training loss = 69.965652\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 46: Training loss = 68.350868\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 47: Training loss = 67.429916\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 48: Training loss = 67.042160\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 49: Training loss = 66.846313\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 50: Training loss = 66.776291\n","313/313 [==============================] - 0s 1ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 51: Training loss = 66.803528\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 52: Training loss = 66.910866\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 53: Training loss = 67.083359\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 54: Training loss = 67.308044\n","313/313 [==============================] - 0s 1ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 4ms/step\n","Iteration 55: Training loss = 67.508835\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 56: Training loss = 67.631859\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 57: Training loss = 67.689659\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 58: Training loss = 67.693352\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 59: Training loss = 67.652542\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 60: Training loss = 67.575630\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 61: Training loss = 67.469826\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 62: Training loss = 67.341354\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 63: Training loss = 67.195534\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 64: Training loss = 67.036888\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 65: Training loss = 66.869263\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 66: Training loss = 66.695862\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 67: Training loss = 66.519386\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 68: Training loss = 66.342079\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 69: Training loss = 66.165771\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 70: Training loss = 66.020042\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 71: Training loss = 65.901245\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 72: Training loss = 65.805603\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 5ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 73: Training loss = 65.729759\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 74: Training loss = 65.670769\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 75: Training loss = 65.626083\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 76: Training loss = 65.593460\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 5ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 77: Training loss = 65.571014\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 1s 5ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 78: Training loss = 65.557076\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 79: Training loss = 65.550179\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 80: Training loss = 65.549103\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 81: Training loss = 65.552780\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 82: Training loss = 65.560303\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 83: Training loss = 65.570877\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 84: Training loss = 65.583839\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 85: Training loss = 65.598640\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 86: Training loss = 65.614777\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 87: Training loss = 65.631859\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 88: Training loss = 65.649536\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 89: Training loss = 65.667549\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 90: Training loss = 65.685646\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 91: Training loss = 65.703629\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 92: Training loss = 65.721359\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 93: Training loss = 65.738724\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 94: Training loss = 65.755608\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 95: Training loss = 65.771935\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 96: Training loss = 65.787636\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 97: Training loss = 65.802612\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 98: Training loss = 65.816750\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 99: Training loss = 65.829597\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 100: Training loss = 65.840576\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 101: Training loss = 65.849815\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 0s 1ms/step\n","Iteration 102: Training loss = 65.857529\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 103: Training loss = 65.863914\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 104: Training loss = 65.869156\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 105: Training loss = 65.873428\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 106: Training loss = 65.876854\n","313/313 [==============================] - 0s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 107: Training loss = 65.879578\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 108: Training loss = 65.881683\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 109: Training loss = 65.883278\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 2s 5ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 110: Training loss = 65.884422\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 0s 2ms/step\n","Iteration 111: Training loss = 65.885216\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 112: Training loss = 65.885696\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 113: Training loss = 65.885941\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 114: Training loss = 65.885956\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 115: Training loss = 65.885811\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 2s 6ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 116: Training loss = 65.885529\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 117: Training loss = 65.885139\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 5ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 118: Training loss = 65.884659\n","313/313 [==============================] - 1s 3ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 119: Training loss = 65.884109\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 120: Training loss = 65.883522\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Iteration 121: Training loss = 65.882904\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 122: Training loss = 65.882263\n","313/313 [==============================] - 1s 2ms/step\n","313/313 [==============================] - 1s 4ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Iteration 123: Training loss = 65.881599\n","Learning rate dropped below 1e-6 after iteration 122\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","# Make predictions on the test set using the MoE model\n","\n","# Load the training data\n","test_data = np.array(df[-100:])\n","test_input = test_data[:, :]\n","test_output = test_data[:, -1:]\n","\n","# Normalize test input data\n","test_input = (test_input - np.mean(test_input, axis=0)) / np.std(test_input, axis=0)\n","\n","# Load the MoE model, experts, and gating model\n","moe_model = load_model('/content/drive/Shareddrives/1st Paper/moe_models2.h5')\n","moe_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n","\n","gating_model = load_model('/content/drive/Shareddrives/1st Paper/gating_models2.h5')\n","gating_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n","\n","experts = []\n","for i in range(num_experts):\n","    experts.append(load_model(f'/content/drive/Shareddrives/1st Paper/expert_{i}.h5'))\n","\n","# Make predictions on the test set using the MoE model\n","test_predictions = moe_model.predict(test_input)\n","\n","test_loss = moe_loss(test_output, test_predictions, gating_model.predict(test_input))\n","moe_mae = mean_absolute_error(test_output, test_predictions)\n","moe_mse = mean_squared_error(test_output, test_predictions)\n","print(f\"MoE model performance: MAE={moe_mae}, MSE={moe_mse}\")\n","\n","print('Test loss = %.6f' % test_loss)\n","test_predictions_denormalized = test_predictions * np.std(train_output, axis=0) + np.mean(train_output, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDd55Xe3ySBO","executionInfo":{"status":"ok","timestamp":1682536251795,"user_tz":240,"elapsed":7510,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"1d7f5871-a37d-4869-f2b9-4ce4b023febb"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]},{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 5ms/step\n","4/4 [==============================] - 0s 3ms/step\n","MoE model performance: MAE=6.357542872582013, MSE=41.125655392736775\n","Test loss = 41.125656\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Create a new figure object with a larger size\n","fig = plt.figure(figsize=(12, 8))\n","\n","# Create your plot within the new figure object\n","plt.plot(test_predictions_denormalized , color = 'red')\n","plt.plot(test_output, color = 'blue')\n","\n","# Display the plot\n","plt.show()"],"metadata":{"id":"b1WMSW-17wt-","colab":{"base_uri":"https://localhost:8080/","height":680},"executionInfo":{"status":"ok","timestamp":1682536324849,"user_tz":240,"elapsed":1085,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"39611a35-f1f3-48ee-e39a-d59e43c02d1b"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x800 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"YNcEY7lY7w2z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_train_expert_model(i, input_dim, output_dim, X_train, y_train, X_test, y_test, activation, kernel_initializer, dropout_rate):\n","    # Train each expert model\n","    if i == 0:  # Autoencoder\n","        expert_model = Model(inputs=experts[0].input, outputs=experts[0].output)\n","    elif i == 1:  # CNN\n","        expert_model = Model(inputs=experts[1].input, outputs=experts[1].output)\n","    else:  # Attention-based model\n","        expert_model = Model(inputs=experts[2].input, outputs=experts[2].output)\n","\n","    expert_model.compile(optimizer=Adam(learning_rate=0.0005), loss='mean_squared_error', metrics=['mae'])\n","    expert_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test), verbose=0)\n","\n","    return expert_model\n","\n","def objective(trial):\n","    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n","    kernel_initializer = trial.suggest_categorical('kernel_initializer', ['he_normal', 'lecun_normal'])\n","    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n","\n","    expert_model = create_train_expert_model(i, input_dim, output_dim, train_input, train_output, test_input, test_output, activation, kernel_initializer, dropout_rate)\n","    loss, mae = expert_model.evaluate(test_input, test_output, verbose=0)\n","\n","    return mae\n","\n","study = optuna.create_study(direction='minimize')\n","for i in range(num_experts):\n","    study.optimize(objective, n_trials=1)\n","    best_params = study.best_params\n","    print(f\"Best parameters for expert {i}: {best_params}\")\n","\n","    expert_model = create_train_expert_model(i, input_dim, output_dim, train_input, train_output, test_input, test_output, best_params['activation'], best_params['kernel_initializer'], best_params['dropout_rate'])\n","    experts[i] = expert_model\n","# Evaluate the individual expert models\n","for i, expert_model in enumerate(experts):\n","    expert_predictions = expert_model.predict(test_input)\n","    print(expert_predictions[0:10])\n","    expert_mae = mean_absolute_error(test_output, expert_predictions[:,0].T.reshape(100,1))\n","    expert_mse = mean_squared_error(test_output, expert_predictions[:,0].T.reshape(100,1))\n","    print(f\"Expert {i} model performance: MAE={expert_mae}, MSE={expert_mse}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBc5TcV-zmeb","executionInfo":{"status":"ok","timestamp":1682485035797,"user_tz":240,"elapsed":766932,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"69b8c7a4-b1a7-4a85-fd44-ce95ee0cda1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-04-26 04:44:24,322]\u001b[0m A new study created in memory with name: no-name-3ee9a729-c980-4251-bd9f-acd745459f67\u001b[0m\n","\u001b[32m[I 2023-04-26 04:46:34,198]\u001b[0m Trial 0 finished with value: 3.5128514766693115 and parameters: {'activation': 'relu', 'kernel_initializer': 'lecun_normal', 'dropout_rate': 0.46523480937255146}. Best is trial 0 with value: 3.5128514766693115.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Best parameters for expert 0: {'activation': 'relu', 'kernel_initializer': 'lecun_normal', 'dropout_rate': 0.46523480937255146}\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-04-26 04:50:32,340]\u001b[0m Trial 1 finished with value: 3.586665391921997 and parameters: {'activation': 'tanh', 'kernel_initializer': 'he_normal', 'dropout_rate': 0.25182505701547925}. Best is trial 0 with value: 3.5128514766693115.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Best parameters for expert 1: {'activation': 'relu', 'kernel_initializer': 'lecun_normal', 'dropout_rate': 0.46523480937255146}\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-04-26 04:54:46,244]\u001b[0m Trial 2 finished with value: 3.527867317199707 and parameters: {'activation': 'relu', 'kernel_initializer': 'lecun_normal', 'dropout_rate': 0.4156644660249619}. Best is trial 0 with value: 3.5128514766693115.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Best parameters for expert 2: {'activation': 'relu', 'kernel_initializer': 'lecun_normal', 'dropout_rate': 0.46523480937255146}\n","4/4 [==============================] - 0s 3ms/step\n","[[ 7.2702103]\n"," [ 8.650709 ]\n"," [ 7.068842 ]\n"," [11.79464  ]\n"," [ 8.716473 ]\n"," [13.888821 ]\n"," [ 7.1144557]\n"," [ 7.2921453]\n"," [10.830593 ]\n"," [10.606586 ]]\n","Expert 0 model performance: MAE=3.5152860225323486, MSE=14.645764550455995\n","4/4 [==============================] - 0s 3ms/step\n","[[ 7.242209 ]\n"," [ 8.495697 ]\n"," [ 6.993226 ]\n"," [11.691198 ]\n"," [ 8.578069 ]\n"," [13.738373 ]\n"," [ 7.0779233]\n"," [ 7.304846 ]\n"," [10.748892 ]\n"," [10.517881 ]]\n","Expert 1 model performance: MAE=3.4292959941510013, MSE=14.036963744267872\n","4/4 [==============================] - 0s 3ms/step\n","[[ 7.2372303]\n"," [ 8.524455 ]\n"," [ 6.9784255]\n"," [11.825805 ]\n"," [ 8.655889 ]\n"," [13.885411 ]\n"," [ 7.10109  ]\n"," [ 7.354578 ]\n"," [10.89346  ]\n"," [10.663635 ]]\n","Expert 2 model performance: MAE=3.5132233203533936, MSE=14.724905662811963\n"]}]},{"cell_type":"code","source":["# Evaluate the individual expert models\n","for i, expert_model in enumerate(experts):\n","    expert_predictions = expert_model.predict(test_input)\n","    print(expert_predictions[0:10])\n","    expert_mae = mean_absolute_error(test_output, expert_predictions[:,0].T.reshape(100,1))\n","    expert_mse = mean_squared_error(test_output, expert_predictions[:,0].T.reshape(100,1))\n","    print(f\"Expert {i} model performance: MAE={expert_mae}, MSE={expert_mse}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pqwFcl_hO9nm","executionInfo":{"status":"ok","timestamp":1682475743638,"user_tz":240,"elapsed":2154,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"cadee4d8-4147-4872-d160-a99fcbbbdb85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 4ms/step\n","[[ 7.3944426]\n"," [ 8.860658 ]\n"," [ 7.2216024]\n"," [11.845239 ]\n"," [ 8.918351 ]\n"," [13.924535 ]\n"," [ 7.260514 ]\n"," [ 7.4138894]\n"," [11.078101 ]\n"," [10.84116  ]]\n","Expert 0 model performance: MAE=3.6689217437390136, MSE=15.652423663935012\n","4/4 [==============================] - 1s 4ms/step\n","[[ 7.346663 ]\n"," [ 8.661081 ]\n"," [ 7.162971 ]\n"," [11.78999  ]\n"," [ 8.836817 ]\n"," [13.783012 ]\n"," [ 7.280067 ]\n"," [ 7.5253863]\n"," [11.04102  ]\n"," [10.811829 ]]\n","Expert 1 model performance: MAE=3.651852885592346, MSE=15.536538595880831\n","4/4 [==============================] - 1s 4ms/step\n","[[ 7.256969 ]\n"," [ 8.530761 ]\n"," [ 7.020214 ]\n"," [11.7783165]\n"," [ 8.644527 ]\n"," [13.821333 ]\n"," [ 7.104606 ]\n"," [ 7.349656 ]\n"," [10.903999 ]\n"," [10.655077 ]]\n","Expert 2 model performance: MAE=3.52630511890686, MSE=14.742063880358998\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","# Evaluate the MoE model\n","moe_model, experts, gating_model = build_moe_model_with_autoencoder_cnn_attention(\n","    input_dim,\n","    output_dim,\n","    expert_hidden_sizes,\n","    expert_output_sizes,\n","    gating_hidden_sizes,\n","    num_experts,\n","    best_params[\"learning_rate\"],\n","    best_params[\"activation\"],\n","    best_params[\"kernel_initializer\"],\n","    best_params[\"dropout_rate\"])\n","\n","moe_predictions = moe_model.predict(test_input)\n","\n","\n","print(f\"MoE model performance: MAE={moe_mae}, MSE={moe_mse}\")\n","\n","# Evaluate the individual expert models\n","for i, expert_model in enumerate(experts):\n","    expert_predictions = expert_model.predict(test_input)\n","    expert_mae = mean_absolute_error(test_output, expert_predictions)\n","    expert_mse = mean_squared_error(test_output, expert_predictions)\n","    print(f\"Expert {i} model performance: MAE={expert_mae}, MSE={expert_mse}\")"],"metadata":{"id":"R0OjDfZ-GCAe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2uGLsOLhzmoX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, LSTM, Multiply, Add\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow_probability as tfp\n","\n","def split_dataset(data):\n","  # split into standard weeks\n","  train, test = data[0:-6047], data[-1440:]\n","  #train, test = data[:-5817], data[-5817:-57] 6048\n","  # restructure into windows of weekly data\n","  train = np.array(np.split(train, len(train)/144))\n","  test = np.array(np.split( test , len(test )/144))\n","  return train, test\n","\n","def to_supervised(train, n_input):\n","    # Flatten data\n","    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n","    X, y = list(), list()\n","    in_start = 0\n","    # Step over the entire history one time step at a time\n","    for _ in range(len(data)):\n","        # Define the end of the input sequence\n","        in_end = in_start + n_input\n","        out_end = in_end + 1\n","        # Ensure we have enough data for this instance\n","        if out_end < len(data):\n","            X.append(data[in_start:in_end, :])\n","            y.append(data[in_end, 0])  # Modify this line to only include the first future time step\n","        # Move along one time step\n","        in_start += 1\n","    return np.array(X), np.array(y)\n","\n","def build_moe_model_with_autoencoder(input_dim, output_dim, expert_hidden_sizes, expert_output_sizes,\n","                                     gating_hidden_sizes, num_experts=3, learning_rate=0.0001,\n","                                     num_iterations=100):\n","    \n","    # Define the experts\n","    experts = []\n","    for i in range(num_experts):\n","        if i == 0:  # Replace first expert with an autoencoder\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            encoded = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(encoded)\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=encoded))  # Return encoded representation\n","        elif i == 1:  # Replace second expert with a CNN expert\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            expert_hidden = Dropout(0.2)(expert_hidden)\n","            expert_hidden = tf.expand_dims(expert_hidden, axis=1)  # Expand dimensions for CNN input\n","            expert_hidden = Conv1D(filters=32, kernel_size=3, activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","            expert_hidden = MaxPooling1D(pool_size=2)(expert_hidden)\n","            expert_hidden = Flatten()(expert_hidden)\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=expert_output))\n","        else:  # Replace third expert with an attention-based model\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            expert_hidden = Dropout(0.2)(expert_hidden)\n","            expert_hidden = tf.expand_dims(expert_hidden, axis=1)  # Expand dimensions for LSTM input\n","            expert_hidden, _ = LSTM(expert_hidden_sizes[i], return_state=True, kernel_initializer='he_normal')(expert_hidden)\n","            attention = Dense(expert_hidden_sizes[i], activation='tanh', kernel_initializer='he_normal')(expert_hidden)\n","            attention = Dense(1, activation='softmax', kernel_initializer='he_normal')(attention)\n","            expert_hidden = Multiply()([expert_hidden, attention])\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=expert_output))\n","\n","\n","    # Define the gating network\n","    gating_input = Input(shape=(input_dim,))\n","    gating_hidden = gating_input\n","    for i in range(len(gating_hidden_sizes)):\n","        gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","    gating_output = Dense(num_experts + num_experts * 3, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","    logits = gating_output[:, :num_experts]\n","    params = gating_output[:, num_experts:]\n","    params = tf.reshape(params, [-1, num_experts, 3])\n","\n","    gating_distribution = tfp.distributions.MixtureSameFamily(\n","        mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","        components_distribution=tfp.distributions.Normal(\n","            loc=params[..., 0],\n","            scale=tf.math.softplus(params[..., 1])\n","        ),\n","        weight_logits=params[..., 2]\n","    )\n","\n","    gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","    # Define the MoE model\n","    inputs = Input(shape=(input_dim,))\n","    outputs = []\n","    for i in range(num_experts):\n","        expert_output = experts[i](inputs)\n","        if i == 0:  # For the autoencoder expert, append encoded representation to outputs list\n","            outputs.append(expert_output)\n","        else:\n","            outputs.append(experts[i](inputs))\n","\n","    gating_output = gating_model(inputs)\n","    weighted_outputs = [gating_distribution.components_distribution[i].prob(expert_output) * gating_distribution.mixture_distribution.probs_parameter()[..., i, tf.newaxis] * expert_output for i, expert_output in enumerate(outputs)]\n","\n","\n","    outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","    moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","    return moe_model, experts, gating_model\n","\n","# Define the loss function\n","def moe_loss(y_true, y_pred, gating_output):\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","    expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","    \n","    # Apply softmax to the logits to get probabilities\n","    gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","    \n","    # Replace MSE with NLL\n","    nll = -tf.reduce_sum(tf.math.log(gating_probabilities + 1e-8) * expert_losses, axis=-1)\n","    return tf.reduce_mean(nll)\n","\n","def scheduler(epoch, lr):\n","    if epoch < 10:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","train, test = split_dataset(df.values)\n","\n","# Define the input and output dimensions\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 3\n","\n","# Define the sizes of the hidden layers for each expert\n","expert_hidden_sizes = [16, 32, 64]\n","\n","# Define the sizes of the output layers for each expert\n","expert_output_sizes = [144,144,144]\n","\n","# Define the sizes of the gating network hidden layers\n","gating_hidden_sizes = [16, 8]\n","\n","# Define the size of the output layer of the gating network\n","gating_output_size = num_experts\n","\n","# Define the number of training iterations for the EM algorithm\n","num_iterations = 100\n","\n","# Define the learning rate for the optimization algorithm\n","learning_rate = 0.0001\n","\n","#Train test split\n","train, test = split_dataset(df.values)\n","\n","# Input output\n","out, _ = to_supervised(train, 144)\n","\n","\n","# Reshape train_data so that the last column represents the output sequence\n","train_input = train.reshape(train.shape[0]*train.shape[1], train.shape[2])[:-145,:]\n","train_output = out[:,:,1]\n","\n","# Normalize input data\n","train_input = (train_input - np.mean(train_input, axis=0)) / np.std(train_input, axis=0)\n","\n","#Build model\n","moe_model, experts, gating_model = build_moe_model(input_dim, output_dim, expert_hidden_sizes,\n","                                                   expert_output_sizes, gating_hidden_sizes)\n","\n","# Define the optimization algorithm\n","optimizer = Adam(learning_rate=learning_rate)\n","\n","# Learning rate scheduler\n","lr_scheduler = LearningRateScheduler(scheduler)\n","\n","# Train the MoE model with the EM algorithm\n","# Train the MoE model with the EM algorithm\n","iteration = 0\n","while iteration < num_iterations:\n","\n","    # E step: Compute the responsibilities of each expert for each data point\n","    gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","    gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","    # M step: Update the parameters of each expert and the gating network\n","    for i in range(num_experts):\n","        expert_input = train_input\n","        expert_output = experts[i](expert_input)\n","        expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        with tf.GradientTape() as tape:\n","            # Watch the trainable variables of the expert model\n","            tape.watch(experts[i].trainable_variables)\n","\n","            # Define the expert model and calculate the expert_loss\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        # Compute the gradients\n","        expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","        # Clip gradients for expert models\n","        expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","        # Update the variables\n","        optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","    \n","    current_learning_rate = scheduler(iteration, optimizer.learning_rate.numpy())\n","    optimizer.learning_rate.assign(current_learning_rate)\n","\n","    gating_input = train_input\n","\n","    with tf.GradientTape() as tape:\n","        # Watch the trainable variables of the gating model\n","        tape.watch(gating_model.trainable_variables)\n","\n","        # Define the gating model and calculate the gating_loss\n","        gating_output = gating_model(gating_input)\n","        gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(train_input), gating_output)\n","\n","    # Compute the gradients\n","    gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","    # Clip gradients for the gating model\n","    gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","\n","    # Update the variables\n","    optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","    # Evaluate the performance of the MoE model on the training set\n","    train_loss = moe_loss(train_output, moe_model.predict(train_input), gating_model.predict(train_input))\n","\n","\n","    print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","\n","    # Stop training if the learning rate becomes too small\n","    if current_learning_rate < 1e-6:\n","        print('Learning rate dropped below 1e-6 after iteration %d' % iteration)\n","        break\n","\n","    iteration += 1\n","\n","# Input output\n","out_test, _ = to_supervised(test, 144)\n","\n","# Reshape train_data so that the last column represents the output sequence\n","test_input = test.reshape(test.shape[0]*test.shape[1], test.shape[2])[:-145,:]\n","test_output = out_test[:,:,1]\n","\n","# Normalize test input data\n","test_input = (test_input - np.mean(test_input, axis=0)) / np.std(test_input, axis=0)\n","\n","# Make predictions on the test set using the MoE model\n","test_predictions = moe_model.predict(test_input)\n","\n","test_loss = moe_loss(test_output, test_predictions, gating_model.predict(test_input))\n","\n","print('Test loss = %.6f' % test_loss)\n","test_predictions_denormalized = test_predictions * np.std(train_output, axis=0) + np.mean(train_output, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fAC9CGmYSLmu","executionInfo":{"status":"ok","timestamp":1682357636558,"user_tz":240,"elapsed":233044,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"c3a5e545-328e-49f0-dafe-3affdd525115"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 1: Training loss = 488.363586\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 2: Training loss = 498.211914\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 3: Training loss = 509.948212\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 4: Training loss = 524.086975\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 5: Training loss = 541.064819\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 6: Training loss = 561.288574\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 7: Training loss = 585.150146\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 8: Training loss = 613.019836\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 9: Training loss = 645.238403\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 10: Training loss = 682.093323\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 11: Training loss = 724.027222\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 12: Training loss = 766.502136\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 13: Training loss = 808.924072\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 14: Training loss = 850.782288\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 15: Training loss = 891.658752\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 16: Training loss = 931.242065\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 17: Training loss = 969.251831\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 18: Training loss = 1005.501221\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 19: Training loss = 1039.865356\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 20: Training loss = 1072.271606\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 21: Training loss = 1102.690430\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 22: Training loss = 1131.128906\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 23: Training loss = 1157.619141\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 24: Training loss = 1182.215942\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 25: Training loss = 1204.991089\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 26: Training loss = 1226.026367\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 27: Training loss = 1245.412109\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 28: Training loss = 1263.243774\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 29: Training loss = 1279.616821\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 30: Training loss = 1294.626099\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 3ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 31: Training loss = 1308.366333\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 32: Training loss = 1320.929321\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 33: Training loss = 1332.402954\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 34: Training loss = 1342.871216\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 35: Training loss = 1352.414062\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 36: Training loss = 1361.106934\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 37: Training loss = 1369.017212\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 38: Training loss = 1376.212280\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 39: Training loss = 1382.755493\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 40: Training loss = 1388.697754\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 41: Training loss = 1394.096191\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 42: Training loss = 1398.997070\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 43: Training loss = 1403.443359\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 44: Training loss = 1407.476807\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 45: Training loss = 1411.133667\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 46: Training loss = 1414.449463\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 47: Training loss = 1417.453979\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 48: Training loss = 1420.178223\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 49: Training loss = 1422.645752\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 3ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 50: Training loss = 1424.881226\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 51: Training loss = 1426.906982\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 52: Training loss = 1428.739624\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 53: Training loss = 1430.398682\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 54: Training loss = 1431.902466\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 55: Training loss = 1433.263062\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 56: Training loss = 1434.493652\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 3ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 57: Training loss = 1435.608032\n","Learning rate dropped below 1e-6 after iteration 56\n","41/41 [==============================] - 0s 3ms/step\n","41/41 [==============================] - 0s 1ms/step\n","Test loss = 204.840836\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Create a new figure object with a larger size\n","fig = plt.figure(figsize=(12, 8))\n","\n","# Create your plot within the new figure object\n","plt.plot(test_predictions_denormalized , color = 'red')\n","plt.plot(test_output, color = 'blue')\n","\n","# Display the plot\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"0LlbJIk6VWWP","executionInfo":{"status":"ok","timestamp":1682357713270,"user_tz":240,"elapsed":1351,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"598949f8-0f50-48b5-df35-aa34f847de53"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x800 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, TimeDistributed\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow_probability as tfp\n","\n","def split_dataset(data):\n","  # split into standard weeks\n","  train, test = data[0:-6047], data[-432:]\n","  #train, test = data[:-5817], data[-5817:-57] 6048\n","  # restructure into windows of weekly data\n","  train = np.array(np.split(train, len(train)/144))\n","  test = np.array(np.split( test , len(test )/144))\n","  return train, test\n","\n","def to_supervised(train, n_input):\n","    # Flatten data\n","    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n","    X, y = list(), list()\n","    in_start = 0\n","    # Step over the entire history one time step at a time\n","    for _ in range(len(data)):\n","        # Define the end of the input sequence\n","        in_end = in_start + n_input\n","        out_end = in_end + 1\n","        # Ensure we have enough data for this instance\n","        if out_end < len(data):\n","            X.append(data[in_start:in_end, :])\n","            y.append(data[in_end, 0])  # Modify this line to only include the first future time step\n","        # Move along one time step\n","        in_start += 1\n","    return np.array(X), np.array(y)\n","\n","\n","train, test = split_dataset(df.values)\n","\n","\n","# Define the input and output dimensions\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 3\n","\n","# Define the sizes of the hidden layers for each expert\n","expert_hidden_sizes = [16, 32, 64]\n","\n","# Define the sizes of the output layers for each expert\n","expert_output_sizes = [144,144,144]\n","\n","# Define the sizes of the gating network hidden layers\n","gating_hidden_sizes = [16, 8]\n","\n","# Define the size of the output layer of the gating network\n","gating_output_size = num_experts\n","\n","# Define the number of training iterations for the EM algorithm\n","num_iterations = 100\n","\n","# Define the learning rate for the optimization algorithm\n","learning_rate = 0.0001\n","\n","#Train test split\n","train, test = split_dataset(df.values)\n","\n","# Input output\n","out, _ = to_supervised(train, 144)\n","\n","# Load the training data\n","#train_data = np.array(df.head(17199))\n","\n","# Reshape train_data so that the last column represents the output sequence\n","train_input = train.reshape(train.shape[0]*train.shape[1], train.shape[2])[:-145,:]\n","train_output = out[:,:,1]\n","\n","\n","def build_moe_model_with_autoencoder(input_dim, output_dim, expert_hidden_sizes, expert_output_sizes,\n","                                     gating_hidden_sizes, num_experts=3, learning_rate=0.0001,\n","                                     num_iterations=100):\n","    \n","    # Define the experts\n","    experts = []\n","    for i in range(num_experts):\n","        if i == 0:  # Replace first expert with an autoencoder\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            encoded = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(encoded)\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_hidden)\n","            experts.append(Model(inputs=expert_input, outputs=encoded))  # Return encoded representation\n","        else:\n","            expert_input = Input(shape=(input_dim,))\n","            expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","            expert_hidden = Dropout(0.2)(expert_hidden)\n","            expert_output = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","            expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_output)\n","            experts.append(Model(inputs=expert_input, outputs=expert_output))\n","\n","    # Define the gating network\n","    gating_input = Input(shape=(input_dim,))\n","    gating_hidden = gating_input\n","    for i in range(len(gating_hidden_sizes)):\n","        gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","    gating_output = Dense(num_experts + num_experts * 2, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","    logits = gating_output[:, :num_experts]\n","    params = gating_output[:, num_experts:]\n","    params = tf.reshape(params, [-1, num_experts, 2])\n","\n","    gating_distribution = tfp.distributions.MixtureSameFamily(\n","        mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","        components_distribution=tfp.distributions.Normal(\n","            loc=params[..., 0],\n","            scale=tf.math.softplus(params[..., 1])\n","        )\n","    )\n","\n","    gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","    # Define the MoE model\n","    inputs = Input(shape=(input_dim,))\n","    outputs = []\n","    for i in range(num_experts):\n","        expert_output = experts[i](inputs)\n","        if i == 0:  # For the autoencoder expert, append encoded representation to outputs list\n","            outputs.append(expert_output)\n","        else:\n","            outputs.append(experts[i](inputs))\n","\n","    gating_output = gating_model(inputs)\n","    weighted_outputs = [tf.expand_dims(gating_output[:, i], axis=-1) * expert_output for i, expert_output in enumerate(outputs)]\n","\n","    outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","    moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","    return moe_model, experts, gating_model\n","\n","\n","# Normalize input data\n","train_input = (train_input - np.mean(train_input, axis=0)) / np.std(train_input, axis=0)\n","\n","# Pad output sequences to the same length\n","\n","# train_output = pad_sequences(train_output, maxlen=max(expert_output_sizes), padding='post', dtype='float32')\n","\n","\n","moe_model, experts, gating_model = build_moe_model(input_dim, output_dim, expert_hidden_sizes,\n","                                                   expert_output_sizes, gating_hidden_sizes)\n","\n","# Define the loss function\n","def moe_loss(y_true, y_pred, gating_output):\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","    expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","    \n","    # Apply softmax to the logits to get probabilities\n","    gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","    \n","    # Multiply expert_losses with the gating probabilities instead of logits\n","    gating_losses = tf.reduce_sum(tf.multiply(expert_losses, gating_probabilities), axis=-1)\n","    return tf.reduce_mean(gating_losses)\n","\n","\n","\n","# Define the optimization algorithm\n","optimizer = Adam(learning_rate=learning_rate)\n","\n","# Learning rate scheduler\n","def scheduler(epoch, lr):\n","    if epoch < 10:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","\n","lr_scheduler = LearningRateScheduler(scheduler)\n","\n","# Train the MoE model with the EM algorithm\n","# Train the MoE model with the EM algorithm\n","iteration = 0\n","while iteration < num_iterations:\n","\n","    # E step: Compute the responsibilities of each expert for each data point\n","    gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","    gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","    # M step: Update the parameters of each expert and the gating network\n","    for i in range(num_experts):\n","        expert_input = train_input\n","        expert_output = experts[i](expert_input)\n","        expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        with tf.GradientTape() as tape:\n","            # Watch the trainable variables of the expert model\n","            tape.watch(experts[i].trainable_variables)\n","\n","            # Define the expert model and calculate the expert_loss\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        # Compute the gradients\n","        expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","        # Clip gradients for expert models\n","        expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","        # Update the variables\n","        optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","    \n","    current_learning_rate = scheduler(iteration, optimizer.learning_rate.numpy())\n","    optimizer.learning_rate.assign(current_learning_rate)\n","\n","    gating_input = train_input\n","\n","    with tf.GradientTape() as tape:\n","        # Watch the trainable variables of the gating model\n","        tape.watch(gating_model.trainable_variables)\n","\n","        # Define the gating model and calculate the gating_loss\n","        gating_output = gating_model(gating_input)\n","        gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(train_input), gating_output)\n","\n","\n","\n","\n","\n","    # Compute the gradients\n","    gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","    # Clip gradients for the gating model\n","    gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","\n","    # Update the variables\n","    optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","    # Evaluate the performance of the MoE model on the training set\n","    train_loss = moe_loss(train_output, moe_model.predict(train_input), gating_model.predict(train_input))\n","\n","\n","    print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","\n","    # Stop training if the learning rate becomes too small\n","    if current_learning_rate < 1e-6:\n","        print('Learning rate dropped below 1e-6 after iteration %d' % iteration)\n","        break\n","\n","    iteration += 1\n","\n","# Make predictions on the test set using the MoE model\n","# test_data = np.array(df[-144:])\n","# test_input = test_data[:, :]\n","# test_output = test_data[:, -1]\n","# test_output = [[int(x)] for x in test_output]\n","\n","# Input output\n","out_test, _ = to_supervised(test, 144)\n","\n","# Load the training data\n","#train_data = np.array(df.head(17199))\n","\n","# Reshape train_data so that the last column represents the output sequence\n","test_input = test.reshape(test.shape[0]*test.shape[1], test.shape[2])[:-145,:]\n","test_output = out_test[:,:,1]\n","\n","# Normalize test input data\n","test_input = (test_input - np.mean(test_input, axis=0)) / np.std(test_input, axis=0)\n","\n","# # Pad test output sequences to the same length\n","# test_output_padded = []\n","# for seq in test_output:\n","#     padded_seq = seq[:1] + [seq[0]] * (max_output_len - 1)\n","#     test_output_padded.append(padded_seq)\n","# test_output = np.array(test_output_padded)\n","\n","# Make predictions on the test set using the MoE model\n","test_predictions = moe_model.predict(test_input)\n","\n","test_loss = moe_loss(test_output, test_predictions, gating_model.predict(test_input))\n","\n","print('Test loss = %.6f' % test_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7df24812-30ab-4781-cc41-e83bd1ea8773","id":"VC2iZrrspqXG"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 1: Training loss = 214.329041\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 2: Training loss = 212.905899\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 2s 4ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 3: Training loss = 211.360413\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 4: Training loss = 209.667877\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 5: Training loss = 207.825867\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 6: Training loss = 205.839417\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 7: Training loss = 203.717682\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 8: Training loss = 201.471634\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 9: Training loss = 199.114120\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 10: Training loss = 196.658615\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 11: Training loss = 194.239990\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 12: Training loss = 191.988480\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 13: Training loss = 189.901779\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 14: Training loss = 187.974121\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 2s 4ms/step\n","Iteration 15: Training loss = 186.198822\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 16: Training loss = 184.568192\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 17: Training loss = 183.073761\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 18: Training loss = 181.706711\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 19: Training loss = 180.457703\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 20: Training loss = 179.317398\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 21: Training loss = 178.278351\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 22: Training loss = 177.333054\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 23: Training loss = 176.473557\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 24: Training loss = 175.692703\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 25: Training loss = 174.983734\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 26: Training loss = 174.340240\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 27: Training loss = 173.756546\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 28: Training loss = 173.227173\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 29: Training loss = 172.747375\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 30: Training loss = 172.312576\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 31: Training loss = 171.918716\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 32: Training loss = 171.561951\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 33: Training loss = 171.238876\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 34: Training loss = 170.946365\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 1ms/step\n","Iteration 35: Training loss = 170.681564\n","563/563 [==============================] - 1s 1ms/step\n","563/563 [==============================] - 1s 2ms/step\n","563/563 [==============================] - 1s 2ms/step\n","Iteration 36: Training loss = 170.441971\n","563/563 [==============================] - 2s 4ms/step\n","563/563 [==============================] - 2s 4ms/step\n","563/563 [==============================] - 2s 3ms/step\n","Iteration 37: Training loss = 170.225082\n","177/563 [========>.....................] - ETA: 0s"]}]},{"cell_type":"code","source":["pip install optuna"],"metadata":{"id":"lgrL_At6pYwW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import optuna"],"metadata":{"id":"bzxFpVcNpb9J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def objective(trial):\n","    # Define the input and output dimensions\n","    input_dim = 1\n","    output_dim = 1\n","\n","    # Suggest hyperparameters using Optuna\n","    num_experts = trial.suggest_int(\"num_experts\", 2, 5)\n","    expert_hidden_sizes = [\n","        trial.suggest_int(f\"expert_hidden_size_{i}\", 16, 64) for i in range(num_experts)\n","    ]\n","    expert_output_sizes = [\n","        trial.suggest_int(f\"expert_output_size_{i}\", 16, 64) for i in range(num_experts)\n","    ]\n","    gating_hidden_sizes = [\n","        trial.suggest_int(f\"gating_hidden_size_{i}\", 8, 32) for i in range(2)\n","    ]\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n","    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n","\n","    # Load the training data\n","    train_data = np.array(df.head(1000))\n","\n","    # Split the training data into input and output sequences\n","    train_input = train_data[:, :-1]\n","    print('train_input shape', train_input.shape)\n","    train_output = train_data[:, -1:]\n","    print('train_output shape', train_output.shape)\n","\n","    # Define the experts\n","    experts = []\n","    for i in range(num_experts):\n","        expert_input = Input(shape=(input_dim,))\n","        expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","        expert_hidden = Dropout(0.2)(expert_hidden)\n","        expert_output = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","        expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_output)  # Add this line\n","        experts.append(Model(inputs=expert_input, outputs=expert_output))\n","\n","    # Define the gating network\n","    gating_input = Input(shape=(input_dim,))\n","    gating_hidden = gating_input\n","    for i in range(len(gating_hidden_sizes)):\n","        gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","    gating_output = Dense(num_experts + num_experts * 2, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","    logits = gating_output[:, :num_experts]\n","    params = gating_output[:, num_experts:]\n","    params = tf.reshape(params, [-1, num_experts, 2])\n","\n","    gating_distribution = tfp.distributions.MixtureSameFamily(\n","        mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","        components_distribution=tfp.distributions.Normal(\n","            loc=params[..., 0],\n","            scale=tf.math.softplus(params[..., 1])\n","        )\n","    )\n","\n","    gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","    # Define the MoE model\n","    inputs = Input(shape=(input_dim,))\n","    outputs = []\n","    for i in range(num_experts):\n","        expert_output = experts[i](inputs)\n","        outputs.append(expert_output)\n","\n","    gating_output = gating_model(inputs)\n","    weighted_outputs = [tf.expand_dims(gating_output[:, i], axis=-1) * expert_output for i, expert_output in enumerate(outputs)]\n","\n","    outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","    moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","    # Define the loss function\n","    def moe_loss(y_true, y_pred):\n","        y_true = tf.cast(y_true, y_pred.dtype)\n","        expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","        expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","        \n","        # Calculate the gating output using the provided inputs\n","        gating_output = gating_model(y_pred)\n","        \n","        # Apply softmax to the logits to get probabilities\n","        gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","        \n","        print(\"y_true.shape: \", y_true.shape)\n","        print(\"y_pred.shape: \", y_pred.shape)\n","        print(\"expert_losses.shape: \", expert_losses.shape)\n","        print(\"gating_probabilities.shape: \", gating_probabilities.shape)\n","        \n","        # Multiply expert_losses with the gating probabilities instead of logits\n","        gating_losses = tf.reduce_sum(tf.multiply(expert_losses, gating_probabilities), axis=-1)\n","        return tf.reduce_mean(gating_losses)\n","\n","\n","    # Define the optimization algorithm\n","    optimizer = Adam(lr=learning_rate)\n","\n","    # Train the MoE model with the EM algorithm\n","    for iteration in range(num_iterations):\n","        # E step: Compute the responsibilities of each expert for each data point\n","        gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","        gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","\n","        # M step: Update the parameters of each expert and the gating network\n","        for i in range(num_experts):\n","            expert_input = train_input\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","            \n","            with tf.GradientTape() as tape:\n","                # Watch the trainable variables of the expert model\n","                tape.watch(experts[i].trainable_variables)\n","\n","                # Define the expert model and calculate the expert_loss\n","                expert_output = experts[i](expert_input)\n","                expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","            # Compute the gradients\n","            expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","            # Clip gradients for expert models\n","            expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","            # Update the variables\n","            for var, grad in zip(experts[i].trainable_variables, expert_gradient):\n","                var.assign_sub(learning_rate * grad)\n","\n","        gating_input = train_input\n","        \n","        with tf.GradientTape() as tape:\n","          # Watch the trainable variables of the gating model\n","          tape.watch(gating_model.trainable_variables)\n","\n","          # Define the gating model and calculate the gating_loss\n","          gating_output = gating_model(gating_input)\n","          gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(gating_input))\n","\n","        # Compute the gradients\n","        gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","        # Clip gradients for the gating model\n","        gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","        \n","        # Update the variables\n","        for var, grad in zip(gating_model.trainable_variables, gating_gradient):\n","          var.assign_sub(learning_rate * grad)\n","\n","        # Evaluate the performance of the MoE model on the training set\n","        train_loss = moe_loss(train_output, moe_model.predict(train_input))\n","        print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","\n","    # Make predictions on the test set using the MoE model\n","    test_data = np.array(df[-1000:])\n","    test_input = test_data[:, :-1]\n","    test_output = test_data[:, -1:]\n","    test_predictions = moe_model.predict(test_input)\n","\n","    test_loss = moe_loss(test_output, test_predictions)\n","    print('Test loss = %.6f' % test_loss)\n","\n","    return test_loss  # Return the test loss to be minimized"],"metadata":{"id":"w9tPi2VMQXzg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)  # Set the number of trials you want to run\n","\n","# Print the best hyperparameters found\n","print(\"Best trial:\")\n","trial = study.best_trial\n","print(f\"Value: {trial.value}\")\n","print(\"Params: \")\n","for key, value in trial.params.items():\n","    print(f\"    {key}: {value}\")"],"metadata":{"id":"i4tMFuzNpUem"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWdBowZ4QAmZ"},"outputs":[],"source":["import numpy as np\n","from tensorflow import keras\n","from keras import layers\n","from sklearn.mixture import GaussianMixture\n","\n","# Generate example time series data\n","df = dataset[['S2_Top_VWC_Avg']]\n","data = np.array(df)\n","\n","# Define segment length\n","segment_length = 50\n","\n","# Segment the time series data\n","segments = np.array([data[i:i+segment_length] for i in range(0, len(data)-segment_length)])\n","\n","# Define the deep learning models\n","models = []\n","models.append(keras.Sequential([\n","    layers.Input(shape=(segment_length, 1)),\n","    layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n","    layers.MaxPooling1D(pool_size=2),\n","    layers.Flatten(),\n","    layers.Dense(units=128, activation='relu'),\n","    layers.Dense(units=1, activation='linear')\n","]))\n","models.append(keras.Sequential([\n","    layers.Input(shape=(segment_length, 1)),\n","    layers.LSTM(units=64, return_sequences=True),\n","    layers.LSTM(units=32),\n","    layers.Dense(units=1, activation='linear')\n","]))\n","\n","# Compile the models\n","for model in models:\n","    model.compile(loss='mse', optimizer='adam')\n","\n","# Fit each model to each segment\n","for model in models:\n","    for i, segment in enumerate(segments):\n","        X = segment[:-1].reshape(-1, segment_length-1, 1)\n","        y = segment[1:].reshape(-1, 1)\n","        model.fit(X, y, epochs=10, batch_size=32, verbose=0)\n","\n","# Fit a Gaussian mixture model to learn segment weights\n","gmm = GaussianMixture(n_components=len(segments), covariance_type='full')\n","gmm.fit(segments)\n","\n","# Use the segment weights to combine the predictions of the models\n","def predict(x):\n","    segment_index = gmm.predict(x.reshape(1, -1))[0]\n","    segment = segments[segment_index]\n","    model = models[segment_index % len(models)]\n","    X = segment[:-1].reshape(-1, segment_length-1, 1)\n","    y = segment[1:].reshape(-1, 1)\n","    model.fit(X, y, epochs=10, batch_size=32, verbose=0)\n","    return model.predict(x.reshape(1, -1, 1))[0][0]\n","\n","# Make a forecast using the mixture of experts model\n","forecast = [predict(data[i:i+segment_length]) for i in range(len(data)-segment_length)]\n"]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, LSTM\n","from keras.optimizers import Adam\n","import tensorflow_probability as tfp\n","from xgboost import XGBRegressor\n","\n","tf.config.experimental_run_functions_eagerly(True)\n","\n","# Define the input and output dimensions\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 5\n","\n","# Define the sizes of the hidden layers for each expert\n","expert_hidden_sizes = [16, 32, 64, 128]\n","\n","# Define the sizes of the output layers for each expert\n","expert_output_sizes = [32, 32, 32, 128]\n","\n","# Define the sizes of the gating network hidden layers\n","gating_hidden_sizes = [16, 8]\n","\n","# Define the size of the output layer of the gating network\n","gating_output_size = num_experts\n","\n","# Define the number of training iterations for the EM algorithm\n","num_iterations = 100\n","\n","# Define the learning rate for the optimization algorithm\n","learning_rate = 0.0001\n","\n","# Load the training data\n","train_data = np.array(df.head(1000))\n","\n","# Split the training data into input and output sequences\n","train_input = train_data[:, :]\n","print('train_input shape', train_input.shape)\n","train_output = train_data[:, -1:]\n","print('train_output shape', train_output.shape)\n","\n","# Reshape the training input for the LSTM expert\n","train_input_lstm = np.reshape(train_input, (train_input.shape[0], train_input.shape[1], 1))\n","\n","# Define the experts\n","experts = []\n","for i in range(4):\n","    expert_input = Input(shape=(input_dim,))\n","    expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","    expert_hidden = Dropout(0.2)(expert_hidden)\n","    expert_output = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","    expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_output)  # Add this line\n","    experts.append(Model(inputs=expert_input, outputs=expert_output))\n","\n","# Define the LSTM expert\n","lstm_expert_input = Input(shape=(input_dim, 1))\n","lstm_expert_hidden = LSTM(64, activation='relu', return_sequences=True)(lstm_expert_input)\n","lstm_expert_hidden = LSTM(32, activation='relu', return_sequences=False)(lstm_expert_hidden)\n","lstm_expert_output = Dense(output_dim, activation='linear')(lstm_expert_hidden)\n","lstm_expert = Model(inputs=lstm_expert_input, outputs=lstm_expert_output)\n","\n","# Add the LSTM expert to the list of experts\n","experts.append(lstm_expert)\n","\n","# Define the gating network\n","gating_input = Input(shape=(input_dim,))\n","gating_hidden = gating_input\n","for i in range(len(gating_hidden_sizes)):\n","    gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","gating_output = Dense(num_experts + num_experts * 2, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","logits = gating_output[:, :num_experts]\n","params = gating_output[:, num_experts:]\n","params = tf.reshape(params, [-1, num_experts, 2])\n","\n","gating_distribution = tfp.distributions.MixtureSameFamily(\n","    mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","    components_distribution=tfp.distributions.Normal(\n","        loc=params[..., 0],\n","        scale=tf.math.softplus(params[..., 1])\n","    )\n",")\n","\n","gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","# Define the MoE model\n","inputs = Input(shape=(input_dim,))\n","outputs = []\n","for i in range(4):\n","    expert_output = experts[i](inputs)\n","    outputs.append(expert_output)\n","\n","# Add LSTM expert output to the list of outputs\n","lstm_outputs = experts[4](tf.expand_dims(inputs, axis=-1))\n","outputs.append(lstm_outputs)\n","\n","gating_output = gating_model(inputs)\n","weighted_outputs = [tf.expand_dims(gating_output[:, i], axis=-1) * expert_output for i, expert_output in enumerate(outputs)]\n","\n","outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","# Define the loss function\n","def moe_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","    expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","    \n","    # Apply softmax to the logits to get probabilities\n","    gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","    \n","    # Multiply expert_losses with the gating probabilities instead of logits\n","    gating_losses = tf.reduce_sum(tf.multiply(expert_losses, gating_probabilities), axis=-1)\n","    return tf.reduce_mean(gating_losses)\n","\n","\n","# Define the optimization algorithm\n","optimizer = Adam(lr=learning_rate)\n","\n","# Train the MoE model with the EM algorithm\n","for iteration in range(num_iterations):\n","    # E step: Compute the responsibilities of each expert for each data point\n","    gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","    gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","\n","    # M step: Update the parameters of each expert and the gating network\n","    for i in range(num_experts):\n","        expert_input = train_input\n","        expert_output = experts[i](expert_input)\n","        expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","        \n","        with tf.GradientTape() as tape:\n","            # Watch the trainable variables of the expert model\n","            tape.watch(experts[i].trainable_variables)\n","\n","            # Define the expert model and calculate the expert_loss\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        # Compute the gradients\n","        expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","        # Clip gradients for expert models\n","        expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","        # Update the variables\n","        optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","\n","\n","    gating_input = train_input\n","    \n","    with tf.GradientTape() as tape:\n","      # Watch the trainable variables of the gating model\n","      tape.watch(gating_model.trainable_variables)\n","\n","      # Define the gating model and calculate the gating_loss\n","      gating_output = gating_model(gating_input)\n","      gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(gating_input))\n","\n","    # Compute the gradients\n","    gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","    # Clip gradients for the gating model\n","    gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","    \n","    # Update the variables\n","    optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","\n","    # Evaluate the performance of the MoE model on the training set\n","    train_loss = moe_loss(train_output, moe_model.predict(train_input))\n","    print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","\n","# Make predictions on the test set using the MoE model\n","test_data = np.array(df[-1000:])\n","test_input = test_data[:, :]\n","test_output = test_data[:, -1:]\n","test_predictions = moe_model.predict(test_input)\n","\n","test_loss = moe_loss(test_output, test_predictions)\n","print('Test loss = %.6f' % test_loss)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682204717619,"user_tz":240,"elapsed":260336,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"a495d22a-ebf6-4704-f47a-f2b830bb5fe1","id":"paHkGxxIJxQ1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_input shape (1000, 2)\n","train_output shape (1000, 1)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 0s 4ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n","/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 1s 43ms/step\n","Iteration 1: Training loss = 1024112.062500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 2: Training loss = 980264.187500\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 2s 62ms/step\n","Iteration 3: Training loss = 930691.437500\n","32/32 [==============================] - 1s 17ms/step\n","32/32 [==============================] - 3s 96ms/step\n","Iteration 4: Training loss = 875062.937500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 39ms/step\n","Iteration 5: Training loss = 813989.375000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 6: Training loss = 748527.312500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 57ms/step\n","Iteration 7: Training loss = 679969.250000\n","32/32 [==============================] - 0s 6ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 8: Training loss = 609678.375000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 9: Training loss = 539045.750000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 10: Training loss = 469404.281250\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 11: Training loss = 401968.562500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 53ms/step\n","Iteration 12: Training loss = 337772.031250\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 2s 57ms/step\n","Iteration 13: Training loss = 277764.031250\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 14: Training loss = 222766.562500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 15: Training loss = 173481.484375\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 16: Training loss = 130603.507812\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 40ms/step\n","Iteration 17: Training loss = 94822.679688\n","32/32 [==============================] - 0s 6ms/step\n","32/32 [==============================] - 2s 57ms/step\n","Iteration 18: Training loss = 66542.148438\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 19: Training loss = 45171.640625\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 20: Training loss = 30356.953125\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 21: Training loss = 21764.251953\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 43ms/step\n","Iteration 22: Training loss = 19079.000000\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 2s 58ms/step\n","Iteration 23: Training loss = 21863.746094\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 24: Training loss = 28502.658203\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 25: Training loss = 37294.433594\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 26: Training loss = 47002.812500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 27: Training loss = 56760.972656\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 48ms/step\n","Iteration 28: Training loss = 65996.820312\n","32/32 [==============================] - 0s 6ms/step\n","32/32 [==============================] - 2s 59ms/step\n","Iteration 29: Training loss = 74345.421875\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 30: Training loss = 81762.531250\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 31: Training loss = 88373.507812\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 32: Training loss = 94216.554688\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 45ms/step\n","Iteration 33: Training loss = 99322.210938\n","32/32 [==============================] - 0s 6ms/step\n","32/32 [==============================] - 2s 48ms/step\n","Iteration 34: Training loss = 103790.265625\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 40ms/step\n","Iteration 35: Training loss = 107724.421875\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 36: Training loss = 111166.734375\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 37: Training loss = 114314.101562\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 46ms/step\n","Iteration 38: Training loss = 120561.882812\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 2s 48ms/step\n","Iteration 39: Training loss = 129907.101562\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 40: Training loss = 142355.843750\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 54ms/step\n","Iteration 41: Training loss = 157981.718750\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 40ms/step\n","Iteration 42: Training loss = 176796.421875\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 43: Training loss = 198692.890625\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 44: Training loss = 223484.828125\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 43ms/step\n","Iteration 45: Training loss = 251206.515625\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 57ms/step\n","Iteration 46: Training loss = 281830.468750\n","32/32 [==============================] - 0s 6ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 47: Training loss = 314641.343750\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 48: Training loss = 344112.093750\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 49: Training loss = 370420.250000\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 50: Training loss = 393557.406250\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 59ms/step\n","Iteration 51: Training loss = 413923.156250\n","32/32 [==============================] - 0s 6ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 52: Training loss = 431701.250000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 43ms/step\n","Iteration 53: Training loss = 446982.625000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 54: Training loss = 459797.093750\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 55: Training loss = 477646.281250\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 59ms/step\n","Iteration 56: Training loss = 500599.812500\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 57: Training loss = 528569.062500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 43ms/step\n","Iteration 58: Training loss = 561273.500000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 59: Training loss = 598034.562500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 60: Training loss = 638444.375000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 58ms/step\n","Iteration 61: Training loss = 671649.500000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 62: Training loss = 696332.312500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 63: Training loss = 713020.187500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 64: Training loss = 722645.500000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 65: Training loss = 731869.375000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 59ms/step\n","Iteration 66: Training loss = 744463.500000\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 2s 48ms/step\n","Iteration 67: Training loss = 760432.250000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 68: Training loss = 779455.437500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 69: Training loss = 791865.875000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 70: Training loss = 798040.500000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 71: Training loss = 798590.312500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 54ms/step\n","Iteration 72: Training loss = 803730.437500\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 73: Training loss = 812694.375000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 40ms/step\n","Iteration 74: Training loss = 824935.062500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 75: Training loss = 830545.812500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 76: Training loss = 831970.937500\n","32/32 [==============================] - 0s 6ms/step\n","32/32 [==============================] - 2s 58ms/step\n","Iteration 77: Training loss = 831095.812500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 43ms/step\n","Iteration 78: Training loss = 837793.000000\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 79: Training loss = 851598.937500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 80: Training loss = 871987.437500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 43ms/step\n","Iteration 81: Training loss = 888730.875000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 49ms/step\n","Iteration 82: Training loss = 902087.062500\n","32/32 [==============================] - 0s 6ms/step\n","32/32 [==============================] - 2s 46ms/step\n","Iteration 83: Training loss = 912195.812500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 84: Training loss = 928205.812500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 85: Training loss = 949504.375000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 86: Training loss = 973860.562500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 87: Training loss = 989970.937500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 57ms/step\n","Iteration 88: Training loss = 998500.875000\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 2s 51ms/step\n","Iteration 89: Training loss = 1000430.812500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 90: Training loss = 1006408.875000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 91: Training loss = 1016196.375000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 42ms/step\n","Iteration 92: Training loss = 1029536.375000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 93: Training loss = 1037321.437500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 2s 49ms/step\n","Iteration 94: Training loss = 1039736.312500\n","32/32 [==============================] - 0s 5ms/step\n","32/32 [==============================] - 2s 57ms/step\n","Iteration 95: Training loss = 1035748.187500\n","32/32 [==============================] - 0s 6ms/step\n","32/32 [==============================] - 1s 43ms/step\n","Iteration 96: Training loss = 1035381.937500\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 97: Training loss = 1038211.625000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 40ms/step\n","Iteration 98: Training loss = 1043935.625000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 99: Training loss = 1041796.250000\n","32/32 [==============================] - 0s 4ms/step\n","32/32 [==============================] - 1s 41ms/step\n","Iteration 100: Training loss = 1031088.687500\n","32/32 [==============================] - 2s 56ms/step\n","Test loss = 692051.125000\n"]}]},{"cell_type":"code","source":["def create_lstm_encoder_decoder(n_input, n_timesteps, n_features, n_outputs, n_nodes):\n","    inputs = Input(shape=(n_timesteps, n_features))\n","\n","    # encoder layers\n","    encoder = tf.keras.layers.LSTM(n_nodes)(inputs)\n","    encoder = tf.keras.layers.RepeatVector(n_outputs)(encoder)\n","\n","    # decoder layers\n","    decoder = tf.keras.layers.LSTM(n_nodes, return_sequences=True)(encoder)\n","    decoder = tf.keras.layers.TimeDistributed(Dense(n_nodes // 2))(decoder)\n","    decoder = tf.keras.layers.TimeDistributed(Dense(1))(decoder)\n","\n","    model = Model(inputs=inputs, outputs=decoder)\n","    model.compile(loss='mae', optimizer='adam')\n","\n","    return model"],"metadata":{"id":"094aF8pPH1D8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout\n","from keras.optimizers import Adam\n","import tensorflow_probability as tfp\n","\n","tf.config.experimental_run_functions_eagerly(True)\n","\n","# Define the input and output dimensions\n","input_dim = df.shape[1]\n","output_dim = 1\n","\n","# Define the number of experts\n","num_experts = 3\n","\n","# Define the sizes of the hidden layers for each expert\n","expert_hidden_sizes = [16, 32, 64]\n","\n","# Define the sizes of the output layers for each expert\n","expert_output_sizes = [32, 32, 32]\n","\n","# Define the sizes of the gating network hidden layers\n","gating_hidden_sizes = [16, 8]\n","\n","# Define the size of the output layer of the gating network\n","gating_output_size = num_experts\n","\n","# Define the number of training iterations for the EM algorithm\n","num_iterations = 100\n","\n","# Define the learning rate for the optimization algorithm\n","learning_rate = 0.0001\n","\n","# Load the training data\n","train_data = np.array(df.head(1000))\n","\n","# Split the training data into input and output sequences\n","train_input = train_data[:, :]\n","print('train_input shape', train_input.shape)\n","train_output = train_data[:, -1:]\n","print('train_output shape', train_output.shape)\n","\n","# Define the experts\n","experts = []\n","for i in range(num_experts):\n","    if i != 1:  # Replace the second expert with the LSTM encoder-decoder\n","        expert_input = Input(shape=(input_dim,))\n","        expert_hidden = Dense(expert_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_input)\n","        expert_hidden = Dropout(0.2)(expert_hidden)\n","        expert_output = Dense(expert_output_sizes[i], activation='relu', kernel_initializer='he_normal')(expert_hidden)\n","        expert_output = Dense(output_dim, activation='linear', kernel_initializer='he_normal')(expert_output)\n","        experts.append(Model(inputs=expert_input, outputs=expert_output))\n","    else:\n","        n_input = input_dim  # Modify this value according to the input dimension of your LSTM encoder-decoder\n","        n_timesteps = 1  # Modify this value according to the number of timesteps of your LSTM encoder-decoder\n","        n_features = input_dim  # Modify this value according to the number of features of your LSTM encoder-decoder\n","        n_outputs = 1  # Modify this value according to the number of outputs of your LSTM encoder-decoder\n","        n_nodes = 32  # Modify this value according to the number of nodes of your LSTM encoder-decoder\n","        lstm_expert = create_lstm_encoder_decoder(n_input, n_timesteps, n_features, n_outputs, n_nodes)\n","        experts.append(lstm_expert)\n","\n","# Define the gating network\n","gating_input = Input(shape=(input_dim,))\n","gating_hidden = gating_input\n","for i in range(len(gating_hidden_sizes)):\n","    gating_hidden = Dense(gating_hidden_sizes[i], activation='relu', kernel_initializer='he_normal')(gating_hidden)\n","\n","gating_output = Dense(num_experts + num_experts * 2, activation=None, kernel_initializer='he_normal')(gating_hidden)\n","logits = gating_output[:, :num_experts]\n","params = gating_output[:, num_experts:]\n","params = tf.reshape(params, [-1, num_experts, 2])\n","\n","gating_distribution = tfp.distributions.MixtureSameFamily(\n","    mixture_distribution=tfp.distributions.Categorical(logits=logits),\n","    components_distribution=tfp.distributions.Normal(\n","        loc=params[..., 0],\n","        scale=tf.math.softplus(params[..., 1])\n","    )\n",")\n","\n","gating_model = Model(inputs=gating_input, outputs=logits)\n","\n","# Define the MoE model\n","inputs = Input(shape=(input_dim,))\n","outputs = []\n","for i in range(num_experts):\n","    expert_output = experts[i](inputs)\n","    outputs.append(expert_output)\n","\n","gating_output = gating_model(inputs)\n","weighted_outputs = [tf.expand_dims(gating_output[:, i], axis=-1) * expert_output for i, expert_output in enumerate(outputs)]\n","\n","outputs = tf.reduce_sum(weighted_outputs, axis=0)\n","\n","moe_model = Model(inputs=inputs, outputs=outputs)\n","\n","# Define the loss function\n","def moe_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    expert_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n","    expert_losses = tf.expand_dims(expert_losses, axis=-1)\n","    \n","    # Apply softmax to the logits to get probabilities\n","    gating_probabilities = tf.nn.softmax(gating_output, axis=-1)\n","    \n","    # Multiply expert_losses with the gating probabilities instead of logits\n","    gating_losses = tf.reduce_sum(tf.multiply(expert_losses, gating_probabilities), axis=-1)\n","    return tf.reduce_mean(gating_losses)\n","\n","\n","\n","# Define the optimization algorithm\n","optimizer = Adam(lr=learning_rate)\n","\n","# Train the MoE model with the EM algorithm\n","for iteration in range(num_iterations):\n","    # E step: Compute the responsibilities of each expert for each data point\n","    gating_output = tf.constant(gating_model.predict(train_input), dtype=tf.float64)\n","    gating_output /= tf.reduce_sum(gating_output, axis=-1, keepdims=True) + 1e-8  # Add a small epsilon value\n","\n","\n","    # M step: Update the parameters of each expert and the gating network\n","    for i in range(num_experts):\n","        expert_input = train_input\n","        expert_output = experts[i](expert_input)\n","        expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","        \n","        with tf.GradientTape() as tape:\n","            # Watch the trainable variables of the expert model\n","            tape.watch(experts[i].trainable_variables)\n","\n","            # Define the expert model and calculate the expert_loss\n","            expert_output = experts[i](expert_input)\n","            expert_loss = tf.reduce_mean(tf.square(train_output - expert_output), axis=-1)\n","\n","        # Compute the gradients\n","        expert_gradient = tape.gradient(expert_loss, experts[i].trainable_variables)\n","        # Clip gradients for expert models\n","        expert_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in expert_gradient]\n","\n","        # Update the variables\n","        optimizer.apply_gradients(zip(expert_gradient, experts[i].trainable_variables))\n","\n","\n","    gating_input = train_input\n","    \n","    with tf.GradientTape() as tape:\n","      # Watch the trainable variables of the gating model\n","      tape.watch(gating_model.trainable_variables)\n","\n","      # Define the gating model and calculate the gating_loss\n","      gating_output = gating_model(gating_input)\n","      gating_loss = moe_loss(tf.constant(train_output, dtype=tf.float32), moe_model(gating_input))\n","\n","    # Compute the gradients\n","    gating_gradient = tape.gradient(gating_loss, gating_model.trainable_variables)\n","    # Clip gradients for the gating model\n","    gating_gradient = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gating_gradient]\n","    \n","    # Update the variables\n","    optimizer.apply_gradients(zip(gating_gradient, gating_model.trainable_variables))\n","\n","\n","    # Evaluate the performance of the MoE model on the training set\n","    train_loss = moe_loss(train_output, moe_model.predict(train_input))\n","    print('Iteration %d: Training loss = %.6f' % (iteration + 1, train_loss))\n","\n","# Make predictions on the test set using the MoE model\n","test_data = np.array(df[-1000:])\n","test_input = test_data[:, :]\n","test_output = test_data[:, -1:]\n","test_predictions = moe_model.predict(test_input)\n","\n","test_loss = moe_loss(test_output, test_predictions)\n","print('Test loss = %.6f' % test_loss)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":556},"executionInfo":{"status":"error","timestamp":1682203453019,"user_tz":240,"elapsed":820,"user":{"displayName":"eduart andres murcia botache","userId":"18281886472792106858"}},"outputId":"9661e79a-3706-469b-d59c-0ea91a449254","id":"e3pnxlAgH-Bp"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_input shape (1000, 2)\n","train_output shape (1000, 1)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-5828667c9109>\u001b[0m in \u001b[0;36m<cell line: 87>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_experts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mexpert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpert_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    236\u001b[0m                     \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                     \u001b[0;34m\"is incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"model_51\" (type Functional).\n\nInput 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 2)\n\nCall arguments received by layer \"model_51\" (type Functional):\n   inputs=tf.Tensor(shape=(None, 2), dtype=float32)\n   training=None\n   mask=None"]}]}]}